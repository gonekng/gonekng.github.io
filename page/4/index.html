<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Jiwon&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jiwon&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jiwon&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Jiwon&#039;s Blog"><meta property="og:url" content="http://gonekng.github.io/"><meta property="og:site_name" content="Jiwon&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://gonekng.github.io/img/og_image.png"><meta property="article:author" content="Jiwon Kang"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://gonekng.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://gonekng.github.io"},"headline":"Jiwon's Blog","image":["http://gonekng.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Jiwon Kang"},"publisher":{"@type":"Organization","name":"Jiwon's Blog","logo":{"@type":"ImageObject","url":"http://gonekng.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Jiwon&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-30T06:10:20.000Z" title="2022. 3. 30. 오후 3:10:20">2022-03-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.983Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">5 minutes read (About 818 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/30/Python/ML/ML_ch_5_1/">ML Practice 5_1</a></h1><div class="content"><h1 id="Prepare-Data"><a href="#Prepare-Data" class="headerlink" title="Prepare Data"></a>Prepare Data</h1><ul>
<li>Import wine data set<ul>
<li>class 0: red wine</li>
<li>class 1: white wine</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&quot;https://bit.ly/wine_csv_data&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.head())</span><br></pre></td></tr></table></figure>

<pre><code>   alcohol  sugar    pH  class
0      9.4    1.9  3.51    0.0
1      9.8    2.6  3.20    0.0
2      9.8    2.3  3.26    0.0
3      9.8    1.9  3.16    0.0
4      9.4    1.9  3.51    0.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># checking missing value and types of variable</span></span><br><span class="line">wine.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 6497 entries, 0 to 6496
Data columns (total 4 columns):
 #   Column   Non-Null Count  Dtype  
---  ------   --------------  -----  
 0   alcohol  6497 non-null   float64
 1   sugar    6497 non-null   float64
 2   pH       6497 non-null   float64
 3   class    6497 non-null   float64
dtypes: float64(4)
memory usage: 203.2 KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(wine.describe()) <span class="comment"># vary in scale of variables, in need of standardization</span></span><br></pre></td></tr></table></figure>

<pre><code>           alcohol        sugar           pH        class
count  6497.000000  6497.000000  6497.000000  6497.000000
mean     10.491801     5.443235     3.218501     0.753886
std       1.192712     4.757804     0.160787     0.430779
min       8.000000     0.600000     2.720000     0.000000
25%       9.500000     1.800000     3.110000     1.000000
50%      10.300000     3.000000     3.210000     1.000000
75%      11.300000     8.100000     3.320000     1.000000
max      14.900000    65.800000     4.010000     1.000000
</code></pre>
<ul>
<li>Split data into training sets and test sets</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5197, 3) (1300, 3)
</code></pre>
<ul>
<li>Standardize Data</li>
<li>Decision tree does not require standardized preprocessing,<br/> but it is recommended to perform standardization basically.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h1 id="Logistic-Regression-Model"><a href="#Logistic-Regression-Model" class="headerlink" title="Logistic Regression Model"></a>Logistic Regression Model</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.7808350971714451
0.7776923076923077
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict_proba(train_scaled[:<span class="number">5</span>]))</span><br><span class="line"><span class="built_in">print</span>(lr.predict(train_scaled[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[[0.06189333 0.93810667]
 [0.21742616 0.78257384]
 [0.40703571 0.59296429]
 [0.45226659 0.54773341]
 [0.00530794 0.99469206]]
[1. 1. 1. 1. 1.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]
</code></pre>
<h1 id="Decision-Tree-Model"><a href="#Decision-Tree-Model" class="headerlink" title="Decision Tree Model"></a>Decision Tree Model</h1><h4 id="a-non-parametric-supervised-learning-method-used-for-classification-and-regression"><a href="#a-non-parametric-supervised-learning-method-used-for-classification-and-regression" class="headerlink" title=": a non-parametric supervised learning method used for classification and regression"></a>: a non-parametric supervised learning method used for classification and regression</h4><ul>
<li>to predict the value of a target variable by learning simple decision rules inferred from the data features</li>
<li>Simple to understand and to interpret</li>
<li>More likely to be overfitting the training set.</li>
<li>New Algorithm Using Decision Tree Algorithms<ul>
<li>XGBoost, LightGBM, CatBoost, etc</li>
<li>In particular, LightGBM is now widely used in practice.</li>
</ul>
</li>
</ul>
<h3 id="DecisionTreeClassifier"><a href="#DecisionTreeClassifier" class="headerlink" title="DecisionTreeClassifier"></a>DecisionTreeClassifier</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt = DecisionTreeClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target)) <span class="comment"># appear to be overfitting</span></span><br></pre></td></tr></table></figure>

<pre><code>0.996921300750433
0.8592307692307692
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">18</span>,<span class="number">10</span>))</span><br><span class="line">plot_tree(dt, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># - conditions for testing : sugar</span></span><br><span class="line"><span class="comment"># - impurity : gini</span></span><br><span class="line"><span class="comment"># - samples : total number of samples</span></span><br><span class="line"><span class="comment"># - value : number of samples by class</span></span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_5_1_1.png"></p>
<h2 id="Impurity-불순도"><a href="#Impurity-불순도" class="headerlink" title="Impurity(불순도)"></a>Impurity(불순도)</h2><ul>
<li>parameter criterion; default ‘gini’</li>
<li>gini &#x3D; 1 - (negative_prop^2 + positive_prop^2)<ul>
<li>best : 0 (pure node)</li>
<li>worst : 0.5 (exactly half and half)</li>
</ul>
</li>
<li>entropy &#x3D; - negative_prop * log_2(negative_prop) - positive_prop * log_2(positive_prop)</li>
<li>Information gain(정보 이득) : impurity differences between parent node and child node<ul>
<li>Decision tree splits nodes to maximize information gain using impurity criteria.</li>
</ul>
</li>
</ul>
<h2 id="Pruning-가지치기"><a href="#Pruning-가지치기" class="headerlink" title="Pruning(가지치기)"></a>Pruning(가지치기)</h2><ul>
<li>In order to prevent overfitting the training set</li>
<li>By specifying the maximum depth of a tree that can grow</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target)) <span class="comment"># successful in reducing overfitting</span></span><br></pre></td></tr></table></figure>

<pre><code>0.8454877814123533
0.8415384615384616
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">18</span>,<span class="number">10</span>))</span><br><span class="line">plot_tree(dt, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_5_1_2.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tree Plot Image Download</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"></span><br><span class="line">dot_data = tree.export_graphviz(</span><br><span class="line">    dt, out_file=<span class="literal">None</span>, feature_names = [<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>], filled=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">graph = graphviz.Source(dot_data, <span class="built_in">format</span>=<span class="string">&quot;png&quot;</span>) </span><br><span class="line">graph</span><br></pre></td></tr></table></figure>




<p><img src="/images/Python/ML/ML_ch_5_1.svg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph.render(<span class="string">&quot;decision_tree_graphivz&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&#39;decision_tree_graphivz.png&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Customize color of nodes</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap, to_rgb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">15</span>))</span><br><span class="line">artists = plot_tree(dt, filled = <span class="literal">True</span>, feature_names = [<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line"></span><br><span class="line">colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> artist, impurity, value <span class="keyword">in</span> <span class="built_in">zip</span>(artists, dt.tree_.impurity, dt.tree_.value):</span><br><span class="line">    r, g, b = to_rgb(colors[np.argmax(value)])</span><br><span class="line">    f = impurity * <span class="number">2</span></span><br><span class="line">    artist.get_bbox_patch().set_facecolor((f + (<span class="number">1</span>-f)*r, f + (<span class="number">1</span>-f)*g, f + (<span class="number">1</span>-f)*b))</span><br><span class="line">    artist.get_bbox_patch().set_edgecolor(<span class="string">&#x27;black&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_5_1_3.png"></p>
<ul>
<li>parameter min_impurity_decrease; default 0.0<ul>
<li>Split nodes if this split induces a decrease of the impurity greater than or equal to this value.</li>
</ul>
<ul>
<li>More likely to be asymmetric tree</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier(min_impurity_decrease=<span class="number">0.0005</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled, test_target))</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">18</span>, <span class="number">10</span>))</span><br><span class="line">plot_tree(dt, filled=<span class="literal">True</span>, feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>0.8874350586877044
0.8615384615384616
</code></pre>
<p><img src="/images/Python/ML/ML_ch_5_1_4.png"></p>
<h2 id="Feature-importance"><a href="#Feature-importance" class="headerlink" title="Feature importance"></a>Feature importance</h2><p>: an indicator of the degree to which each feature contributed to reducing impurities</p>
<ul>
<li>Multiply the information gain and the ratio of the total sample by each node, and add it up by feature.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(dt.feature_importances_) <span class="comment"># Sugar is the most important feature.</span></span><br></pre></td></tr></table></figure>

<pre><code>[0.12345626 0.86862934 0.0079144 ]
</code></pre>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-29T07:10:25.000Z" title="2022. 3. 29. 오후 4:10:25">2022-03-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.900Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">5 minutes read (About 696 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/29/Python/ML/ML_ch_4_2/">ML Practice 4_2</a></h1><div class="content"><h1 id="Gradient-Descent-경사-하강법"><a href="#Gradient-Descent-경사-하강법" class="headerlink" title="Gradient Descent(경사 하강법)"></a>Gradient Descent(경사 하강법)</h1><h4 id="Algorithm-for-finding-the-minimum-value-of-a-loss-function-using-a-sample-of-a-training-set"><a href="#Algorithm-for-finding-the-minimum-value-of-a-loss-function-using-a-sample-of-a-training-set" class="headerlink" title=": Algorithm for finding the minimum value of a loss function using a sample of a training set"></a>: Algorithm for finding the minimum value of a loss function using a sample of a training set</h4><ol>
<li>stochastic gradient descent(확률적 경사 하강법; SGD)<ul>
<li>method of randomly selecting <strong>one</strong> sample from a training set</li>
</ul>
</li>
<li>minibatch gradient descent(미니배치 경사 하강법)<ul>
<li>method of randomly selecting <strong>several</strong> samples from a training set</li>
</ul>
</li>
<li>batch gradient descent(배치 경사 하강법)<ul>
<li>method of selecting <strong>all</strong> the samples from a training set at once</li>
</ul>
</li>
</ol>
<ul>
<li>Sampling method is different from the existing model. (more detailed approach)</li>
<li>It aims to correct errors by reducing the slope of the loss function</li>
<li>SGDClassifier : Create a classification model using SGD.</li>
<li>SGDRegressor : Create a regression model using SGD.</li>
<li>Epoch : process of using the entire training set once</li>
</ul>
<h4 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h4><ul>
<li>Deep learning algorithm (especially, image and text)</li>
<li>Tree algorithm + Gradient Descent &#x3D; Boosting<ul>
<li>ex) LightGBM, Xgboost, Catboost</li>
</ul>
</li>
</ul>
<h2 id="Loss-function-손실-함수"><a href="#Loss-function-손실-함수" class="headerlink" title="Loss function(손실 함수)"></a>Loss function(손실 함수)</h2><ul>
<li>Cost function 비용 함수)</li>
<li>Loss is the difference between the predicted value and the actual value of the model (equivalent to error)</li>
<li>Loss function is a function that expresses loss of the model<ul>
<li>an indicator of how poorly a model processes data</li>
</ul>
</li>
<li>Loss function must be differentiable.</li>
</ul>
<hr>
<h1 id="Prepare-Data"><a href="#Prepare-Data" class="headerlink" title="Prepare Data"></a>Prepare Data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;https://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>, <span class="string">&#x27;Length&#x27;</span>, <span class="string">&#x27;Diagonal&#x27;</span>, <span class="string">&#x27;Height&#x27;</span>, <span class="string">&#x27;Width&#x27;</span>]].to_numpy()</span><br><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Split</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((119, 5), (40, 5), (119,), (40,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Normalize</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<p>※ To prevent data leakage, make sure to convert the test set to the statistics learned from the training set.<br>※ Data leakage : containing the information you want to predict in the data used for model training </p>
<hr>
<h1 id="SGD-Classifier"><a href="#SGD-Classifier" class="headerlink" title="SGD Classifier"></a>SGD Classifier</h1><h2 id="Fitting-model"><a href="#Fitting-model" class="headerlink" title="Fitting model"></a>Fitting model</h2><ul>
<li>set 2 parameter in SGD Classifier<ul>
<li>loss : specifying the type of loss function</li>
<li>max_iter : specifying the number of epochs to be executed</li>
</ul>
</li>
<li>In the case of a multi-classification model,<br/> if loss is set as ‘log’, a binary classification model is created for each class.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"></span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">10</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.773109243697479
0.775


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># partial_fit() : continue training one epoch per call</span></span><br><span class="line">sc.partial_fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8151260504201681
0.85
</code></pre>
<h2 id="Finding-appropriate-epoch"><a href="#Finding-appropriate-epoch" class="headerlink" title="Finding appropriate epoch"></a>Finding appropriate epoch</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">300</span>): <span class="comment"># _ : temporal variable</span></span><br><span class="line">  sc.partial_fit(train_scaled, train_target, classes=classes)</span><br><span class="line">  train_score.append(sc.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(train_score)</span><br><span class="line">ax.plot(test_score)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;epoch&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;accuracy&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_4_2.png"></p>
<ul>
<li>In the early stages of epoch, the scores of training sets and test sets are low because they are underfitting.</li>
<li>After epoch 100, the score difference between the training set and the test set gradually increases.</li>
<li>Epoch 100 appears to be the most appropriate number of iterations.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SGD classifier stops by itself, if performance does not improve during a certain epoch.</span></span><br><span class="line"><span class="comment"># tol = None : to repeat unconditionally untill max_iter</span></span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>, max_iter=<span class="number">100</span>, tol=<span class="literal">None</span>, random_state=<span class="number">42</span>)</span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.957983193277311
0.925
</code></pre>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-29T03:50:45.000Z" title="2022. 3. 29. 오후 12:50:45">2022-03-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.815Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">6 minutes read (About 856 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/29/Python/ML/ML_ch_4_1/">ML Practice 4_1</a></h1><div class="content"><h1 id="Prepare-Data"><a href="#Prepare-Data" class="headerlink" title="Prepare Data"></a>Prepare Data</h1><h2 id="Import-data-set"><a href="#Import-data-set" class="headerlink" title="Import data set"></a>Import data set</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">fish = pd.read_csv(<span class="string">&#x27;https://bit.ly/fish_csv_data&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(fish.head())</span><br></pre></td></tr></table></figure>

<pre><code>  Species  Weight  Length  Diagonal   Height   Width
0   Bream   242.0    25.4      30.0  11.5200  4.0200
1   Bream   290.0    26.3      31.2  12.4800  4.3056
2   Bream   340.0    26.5      31.1  12.3778  4.6961
3   Bream   363.0    29.0      33.5  12.7300  4.4555
4   Bream   430.0    29.0      34.0  12.4440  5.1340
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pd.unique(fish[<span class="string">&#x27;Species&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Roach&#39; &#39;Whitefish&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Smelt&#39;]
</code></pre>
<h2 id="Convert-to-Numpy-array"><a href="#Convert-to-Numpy-array" class="headerlink" title="Convert to Numpy array"></a>Convert to Numpy array</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>,<span class="string">&#x27;Length&#x27;</span>,<span class="string">&#x27;Diagonal&#x27;</span>,<span class="string">&#x27;Height&#x27;</span>,<span class="string">&#x27;Width&#x27;</span>]].to_numpy()</span><br><span class="line"><span class="built_in">print</span>(fish_input.shape)</span><br><span class="line"><span class="built_in">print</span>(fish_input[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<pre><code>(159, 5)
[[242.      25.4     30.      11.52     4.02  ]
 [290.      26.3     31.2     12.48     4.3056]
 [340.      26.5     31.1     12.3778   4.6961]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br><span class="line"><span class="built_in">print</span>(fish_target.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(159,)
</code></pre>
<h2 id="Split-and-Standardize"><a href="#Split-and-Standardize" class="headerlink" title="Split and Standardize"></a>Split and Standardize</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state=<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input[:<span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(train_scaled[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[720.      35.      40.6     16.3618   6.09  ]
 [500.      45.      48.       6.96     4.896 ]
 [  7.5     10.5     11.6      1.972    1.16  ]]
[[ 0.91965782  0.60943175  0.81041221  1.85194896  1.00075672]
 [ 0.30041219  1.54653445  1.45316551 -0.46981663  0.27291745]
 [-1.0858536  -1.68646987 -1.70848587 -1.70159849 -2.0044758 ]
 [-0.79734143 -0.60880176 -0.67486907 -0.82480589 -0.27631471]
 [-0.71289885 -0.73062511 -0.70092664 -0.0802298  -0.7033869 ]]
[[-0.88741352 -0.91804565 -1.03098914 -0.90464451 -0.80762518]
 [-1.06924656 -1.50842035 -1.54345461 -1.58849582 -1.93803151]
 [-0.54401367  0.35641402  0.30663259 -0.8135697  -0.65388895]
 [-0.34698097 -0.23396068 -0.22320459 -0.11905019 -0.12233464]
 [-0.68475132 -0.51509149 -0.58801052 -0.8998784  -0.50124996]]
</code></pre>
<hr>
<h1 id="KNN-Classifier"><a href="#KNN-Classifier" class="headerlink" title="KNN Classifier"></a>KNN Classifier</h1><h2 id="Model-fitting"><a href="#Model-fitting" class="headerlink" title="Model fitting"></a>Model fitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">kn = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">kn.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(kn.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(kn.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8907563025210085
0.85
</code></pre>
<h2 id="Multi-class-Classfication"><a href="#Multi-class-Classfication" class="headerlink" title="Multi-class Classfication"></a>Multi-class Classfication</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">proba = kn.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(kn.classes_)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">4</span>))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
[[0.     0.     1.     0.     0.     0.     0.    ]
 [0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     1.     0.     0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">distances, indexes = kn.kneighbors(test_scaled[<span class="number">3</span>:<span class="number">4</span>]) <span class="comment"># Two-dimensional array must be input</span></span><br><span class="line"><span class="built_in">print</span>(train_target[indexes])</span><br></pre></td></tr></table></figure>

<pre><code>[[&#39;Roach&#39; &#39;Perch&#39; &#39;Perch&#39;]]
</code></pre>
<ul>
<li>The probability calculated by the model is the ratio of the nearest neighbor.<ul>
<li>In this model(k&#x3D;3), the probability values are 0, 1&#x2F;3, 2&#x2F;3, and 1.</li>
<li>If k is set as 5, the probability values may be 0, 0.2, 0.4, 0.6, 0.8 and 1.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">kn.fit(train_scaled, train_target)</span><br><span class="line">proba = kn.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(kn.classes_)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(kn.predict(test_scaled[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
[[0.  0.  0.6 0.  0.4 0.  0. ]
 [0.  0.  0.  0.  0.  1.  0. ]
 [0.  0.  0.2 0.8 0.  0.  0. ]
 [0.  0.  0.8 0.  0.2 0.  0. ]
 [0.  0.  0.8 0.  0.2 0.  0. ]]
[&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Perch&#39; &#39;Perch&#39;]
</code></pre>
<hr>
<h1 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h1><h3 id="Estimating-a-model-with-a-regression-equation-for-categorical-dependent-variables"><a href="#Estimating-a-model-with-a-regression-equation-for-categorical-dependent-variables" class="headerlink" title=": Estimating a model with a regression equation for categorical dependent variables."></a>: Estimating a model with a regression equation for categorical dependent variables.</h3><ul>
<li>Despite its name, a classification model rather than regression model</li>
<li>Highly important model<ul>
<li>used as basic statistics (especially medical statistics)</li>
<li>the basis of the machine learning classification model.</li>
<li>early model of deep learning</li>
</ul>
</li>
<li>To overcome the linearity assumption problem of general regression equation<ul>
<li>Logit transformation : the log of the odds ratio</li>
<li>Using the logit of Y as the dependent variable of the regression</li>
</ul>
</li>
</ul>
<h2 id="Sigmoid-function"><a href="#Sigmoid-function" class="headerlink" title="Sigmoid function"></a>Sigmoid function</h2><ul>
<li>also called a logistic function</li>
<li>Convert the value z calculated by linear regression to a probability value between 0 and 1<ul>
<li>z &lt; 0: the function approaches 0</li>
<li>z &gt; 0: the function approaches 1</li>
<li>z &#x3D; 0: the function value is 0.5</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">z = np.arange(-<span class="number">5</span>, <span class="number">5</span>, <span class="number">0.1</span>)</span><br><span class="line">phi = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z)) <span class="comment"># sigmoid function</span></span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(z, phi)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;z&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;phi&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">ax.set_title(<span class="string">&quot;Sigmoid Function for Logistic Regression&quot;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_4_1.png"></p>
<h2 id="Binary-classification"><a href="#Binary-classification" class="headerlink" title="Binary classification"></a>Binary classification</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Boolean Indexing: using a boolean vector to filter the data. </span></span><br><span class="line"><span class="comment"># Choose only Bream and Smelt from the training set.</span></span><br><span class="line">bream_smelt_indexes = (train_target == <span class="string">&#x27;Bream&#x27;</span>) | (train_target == <span class="string">&#x27;Smelt&#x27;</span>)</span><br><span class="line">train_bream_smelt = train_scaled[bream_smelt_indexes]</span><br><span class="line">target_bream_smelt = train_target[bream_smelt_indexes]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_bream_smelt, target_bream_smelt)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr.classes_) <span class="comment"># 0: Bream / 1: Smelt</span></span><br><span class="line">proba = lr.predict_proba(train_bream_smelt[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">3</span>)) <span class="comment"># 5 rows, 2 columns</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict(train_bream_smelt[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39;]
[[0.998 0.002]
 [0.027 0.973]
 [0.995 0.005]
 [0.986 0.014]
 [0.998 0.002]]
[&#39;Bream&#39; &#39;Smelt&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]
</code></pre>
<blockquote>
<p> <em>z &#x3D; - 0.404 * Weight - 0. 576 * Length - 0.663 * Diagonal - 1.013 * Height - 0.732 * Width - 2.162</em></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decisions = lr.decision_function(train_bream_smelt[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(decisions) <span class="comment"># original z-value of positive class(Smelt)</span></span><br></pre></td></tr></table></figure>

<pre><code>[-6.02927744  3.57123907 -5.26568906 -4.24321775 -6.0607117 ]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"><span class="built_in">print</span>(expit(decisions)) <span class="comment"># probability value through sigmoid function</span></span><br></pre></td></tr></table></figure>

<pre><code>[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
</code></pre>
<h2 id="Multi-class-classification"><a href="#Multi-class-classification" class="headerlink" title="Multi-class classification"></a>Multi-class classification</h2><ul>
<li>basically use iterative algorithms (max_iter, default 100)<ul>
<li>in this model, set max_iter as 1000 (for sufficient training)</li>
</ul>
</li>
</ul>
<h4 id="L2-Regularization"><a href="#L2-Regularization" class="headerlink" title="L2 Regularization"></a>L2 Regularization</h4><ul>
<li>based on the square value of the coefficient such as ridge regression</li>
<li>hyperparameter; C ( default 1)<ul>
<li>the smaller the value, the greater the regulation.</li>
<li>in this model, set C as 20 (in order to ease regulations a little)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(C=<span class="number">20</span>, max_iter=<span class="number">1000</span>)</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9327731092436975
0.925
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.classes_)</span><br><span class="line">proba = lr.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">3</span>)) <span class="comment"># 5 rows, 7 columns</span></span><br><span class="line"><span class="built_in">print</span>(lr.predict(test_scaled[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
[&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Perch&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_.shape, lr.intercept_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(7, 5) (7,)
[[-1.49002087 -1.02912886  2.59345551  7.70357682 -1.2007011 ]
 [ 0.19618235 -2.01068181 -3.77976834  6.50491489 -1.99482722]
 [ 3.56279745  6.34357182 -8.48971143 -5.75757348  3.79307308]
 [-0.10458098  3.60319431  3.93067812 -3.61736674 -1.75069691]
 [-1.40061442 -6.07503434  5.25969314 -0.87220069  1.86043659]
 [-1.38526214  1.49214574  1.39226167 -5.67734118 -4.40097523]
 [ 0.62149861 -2.32406685 -0.90660867  1.71599038  3.6936908 ]]
[-0.09205179 -0.26290885  3.25101327 -0.14742956  2.65498283 -6.78782948
  1.38422358]
</code></pre>
<ul>
<li>The z value is calculated one by one for each class and classified into the class that outputs the highest value.</li>
</ul>
<h2 id="Softmax-function"><a href="#Softmax-function" class="headerlink" title="Softmax function"></a>Softmax function</h2><ul>
<li>also called a normalized exponential function (because of using exponential functions)</li>
<li>The outputs of several linear equations are compressed from 0 to 1, and the total sum is 1.<blockquote>
<p><em>e_sum &#x3D; e^z1 + e^z2 + … + e^z7</em></p>
</blockquote>
<blockquote>
<p><em>s1 &#x3D; e^z1&#x2F;e_sum, s2 &#x3D; e^z2&#x2F;e_sum, … , s7 &#x3D; e^z7&#x2F;e_sum</em></p>
</blockquote>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decision = lr.decision_function(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(decision, decimals=<span class="number">3</span>)) <span class="comment"># original z value</span></span><br></pre></td></tr></table></figure>

<pre><code>[[ -6.498   1.032   5.164  -2.729   3.339   0.327  -0.634]
 [-10.859   1.927   4.771  -2.398   2.978   7.841  -4.26 ]
 [ -4.335  -6.233   3.174   6.487   2.358   2.421  -3.872]
 [ -0.683   0.453   2.647  -1.187   3.265  -5.753   1.259]
 [ -6.397  -1.993   5.816  -0.11    3.503  -0.112  -0.707]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> softmax</span><br><span class="line">proba = softmax(decision, axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals=<span class="number">3</span>)) <span class="comment"># probability value through softmax function</span></span><br></pre></td></tr></table></figure>

<pre><code>[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
</code></pre>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-28T15:34:50.000Z" title="2022. 3. 29. 오전 12:34:50">2022-03-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.733Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">7 minutes read (About 1020 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/29/Python/ML/ML_ch_3_3/">ML Practice 3_3</a></h1><div class="content"><h1 id="Prepare-Data"><a href="#Prepare-Data" class="headerlink" title="Prepare Data"></a>Prepare Data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;https://bit.ly/perch_csv_data&#x27;</span>)</span><br><span class="line">perch_full = df.to_numpy() <span class="comment"># Convert Pandas DataFrame to Numpy Array</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">perch_weight = np.array([<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, <span class="number">110.0</span>,</span><br><span class="line">       <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, <span class="number">130.0</span>,</span><br><span class="line">       <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, <span class="number">197.0</span>,</span><br><span class="line">       <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, <span class="number">514.0</span>,</span><br><span class="line">       <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, <span class="number">820.0</span>,</span><br><span class="line">       <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>,</span><br><span class="line">       <span class="number">1000.0</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_full, perch_weight, random_state=<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>



<hr>
<h1 id="Transform-Data"><a href="#Transform-Data" class="headerlink" title="Transform Data"></a>Transform Data</h1><h3 id="※-Scikit-Learn-Class"><a href="#※-Scikit-Learn-Class" class="headerlink" title="※ Scikit-Learn Class"></a>※ Scikit-Learn Class</h3><ul>
<li>Estimator(추정기; model class) : Fitting and predicting<ul>
<li>KNeighborsClassifier, LinearRegression, etc.</li>
<li>common method : fit(), score(), predict()</li>
</ul>
</li>
<li>Transformer(변환기) and Pre-processors : transforming or imputing data<ul>
<li>PolynomialFeatures, StandardScaler, etc</li>
<li>common method : fit(), transform()</li>
</ul>
</li>
</ul>
<h3 id="※-Feature-engineering-특성-공학"><a href="#※-Feature-engineering-특성-공학" class="headerlink" title="※ Feature engineering(특성 공학)"></a>※ Feature engineering(특성 공학)</h3><ul>
<li>extracting new features using existing features</li>
<li>existing features, square features of each, and features multiplied by each other.</li>
</ul>
<h2 id="Import-transformer"><a href="#Import-transformer" class="headerlink" title="Import transformer"></a>Import transformer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br></pre></td></tr></table></figure>

<h2 id="Transform-sample-data"><a href="#Transform-sample-data" class="headerlink" title="Transform sample data"></a>Transform sample data</h2><ul>
<li>case 1: Including a bias</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures()</span><br><span class="line">poly.fit([[<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>,<span class="number">3</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[[1. 2. 3. 4. 6. 9.]]


      &gt; existing features : 2, 3
      &gt; new features : 1(for intercept), 4(2^2), 6(2*3), 9(3^2)
</code></pre>
<ul>
<li>case 2: Not including a bias (recommended)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit([[<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"><span class="built_in">print</span>(poly.transform([[<span class="number">2</span>,<span class="number">3</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[[2. 3. 4. 6. 9.]]


      &gt; existing features : 2, 3
      &gt; new features : 4(2^2), 6(2*3), 9(3^2)
</code></pre>
<h2 id="Transform-perch-data"><a href="#Transform-perch-data" class="headerlink" title="Transform perch data"></a>Transform perch data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit(train_input)</span><br><span class="line">train_poly = poly.transform(train_input)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape) <span class="comment"># have 3 features</span></span><br><span class="line"><span class="built_in">print</span>(train_poly.shape) <span class="comment"># have 9 features</span></span><br><span class="line"><span class="built_in">print</span>(poly.get_feature_names_out())</span><br></pre></td></tr></table></figure>

<pre><code>(42, 3)
(42, 9)
[&#39;x0&#39; &#39;x1&#39; &#39;x2&#39; &#39;x0^2&#39; &#39;x0 x1&#39; &#39;x0 x2&#39; &#39;x1^2&#39; &#39;x1 x2&#39; &#39;x2^2&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_poly = poly.transform(test_input)</span><br><span class="line"><span class="built_in">print</span>(test_input.shape) <span class="comment"># have 3 features</span></span><br><span class="line"><span class="built_in">print</span>(test_poly.shape) <span class="comment"># have 9 features</span></span><br></pre></td></tr></table></figure>

<pre><code>(14, 3)
(14, 9)
</code></pre>
<hr>
<h1 id="Mutiple-Regression"><a href="#Mutiple-Regression" class="headerlink" title="Mutiple Regression"></a>Mutiple Regression</h1><ul>
<li>same process as training a linear regression model</li>
<li>linear regression using multiple features</li>
</ul>
<h4 id="degree-2"><a href="#degree-2" class="headerlink" title="degree 2"></a>degree 2</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9903183436982124
0.9714559911594134
</code></pre>
<ul>
<li>Multiple regression solves the linear model’s underfitting problem.</li>
<li>The score for the training set is very high.</li>
</ul>
<h4 id="degree-5"><a href="#degree-5" class="headerlink" title="degree 5"></a>degree 5</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">poly = PolynomialFeatures(degree=<span class="number">5</span>, include_bias=<span class="literal">False</span>)</span><br><span class="line">poly.fit(train_input)</span><br><span class="line">train_poly = poly.transform(train_input)</span><br><span class="line">test_poly = poly.transform(test_input)</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br><span class="line"><span class="built_in">print</span>(test_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 55)
(14, 55)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_poly, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_poly, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9999999999991097
-144.40579242684848
</code></pre>
<ul>
<li>The score for the training set is almost perfect.</li>
<li>But the score for the testing set is extremely negative.<ul>
<li>The model appears to be too overfitting to the training set.</li>
</ul>
</li>
</ul>
<hr>
<h1 id="Regularization-규제"><a href="#Regularization-규제" class="headerlink" title="Regularization(규제)"></a>Regularization(규제)</h1><ul>
<li>preventing the model from overfitting the training set</li>
<li>linear regression model : reducing the size of the coefficient multiplied by the feature.</li>
</ul>
<h2 id="hyperparameter-alpha"><a href="#hyperparameter-alpha" class="headerlink" title="hyperparameter: alpha"></a>hyperparameter: alpha</h2><ul>
<li>parameter which has to be set in advance<ul>
<li>increase&#x2F;decrease in regulatory intensity</li>
<li>adjusted to increase the performance of the model</li>
</ul>
</li>
<li>Conceptual understanding is important, but it doesn’t mean much in practice.<ul>
<li>No guarantee of performance compared to working hours.</li>
<li>More than 100 libraries in scikit-learn, and the types and numbers of hyperparameters vary.</li>
</ul>
</li>
<li>Better to use the existing hyperparameters, for unfamiliar models.</li>
</ul>
<h2 id="Normalize-feature-scales"><a href="#Normalize-feature-scales" class="headerlink" title="Normalize feature scales"></a>Normalize feature scales</h2><ul>
<li>using StandardScaler class in scikit-learn</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_poly)</span><br><span class="line">train_scaled = ss.transform(train_poly)</span><br><span class="line">test_scaled = ss.transform(test_poly)</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape)</span><br><span class="line"><span class="built_in">print</span>(test_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 55)
(14, 55)
</code></pre>
<h2 id="Ridge-regression"><a href="#Ridge-regression" class="headerlink" title="Ridge regression"></a>Ridge regression</h2><ul>
<li>based on the square value of the coefficient</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Ridge</span><br><span class="line">ridge = Ridge()</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9896101671037343
0.9790693977615397
</code></pre>
<ul>
<li>Many features are used, but they’re not overfitting the training set and perform well on the test set.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">  ridge = Ridge(alpha=alpha)</span><br><span class="line">  ridge.fit(train_scaled, train_target)</span><br><span class="line">  train_score.append(ridge.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(np.log10(alpha_list), train_score)</span><br><span class="line">ax.plot(np.log10(alpha_list), test_score)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;log10(alpha)&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;R^2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_3_1.png"></p>
<ul>
<li>left side : overfitting</li>
<li>right side : underfitting</li>
<li>appropriate alpha : 0.1</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ridge = Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">ridge.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(ridge.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(ridge.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9903815817570366
0.9827976465386926
</code></pre>
<h2 id="Lasso-regression"><a href="#Lasso-regression" class="headerlink" title="Lasso regression"></a>Lasso regression</h2><ul>
<li>based on the absolute value of the coefficient</li>
<li>The coefficient can be completely zero.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line">lasso = Lasso()</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.989789897208096
0.9800593698421883
</code></pre>
<ul>
<li>Many features are used, but they’re not overfitting the training set and perform well on the test set.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_score = []</span><br><span class="line">test_score = []</span><br><span class="line"></span><br><span class="line">alpha_list = [<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="keyword">for</span> alpha <span class="keyword">in</span> alpha_list:</span><br><span class="line">  lasso = Lasso(alpha=alpha, max_iter=<span class="number">10000</span>)</span><br><span class="line">  lasso.fit(train_scaled, train_target)</span><br><span class="line">  train_score.append(lasso.score(train_scaled, train_target))</span><br><span class="line">  test_score.append(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(np.log10(alpha_list), train_score)</span><br><span class="line">ax.plot(np.log10(alpha_list), test_score)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;log10(alpha)&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;R^2&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_3_2.png"></p>
<ul>
<li>left side : overfitting</li>
<li>right side : underfitting</li>
<li>appropriate alpha : 10</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lasso = Lasso(alpha=<span class="number">10</span>)</span><br><span class="line">lasso.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lasso.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lasso.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9888067471131867
0.9824470598706695
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(lasso.coef_==<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<pre><code>40
</code></pre>
<ul>
<li>40 coefficients became zero</li>
<li>Of the 55 features, only 15 were finally used.</li>
</ul>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-28T08:34:00.000Z" title="2022. 3. 28. 오후 5:34:00">2022-03-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.607Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">4 minutes read (About 653 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/28/Python/ML/ML_ch_3_2/">ML Practice 3_2</a></h1><div class="content"><h1 id="Data-Set"><a href="#Data-Set" class="headerlink" title="Data Set"></a>Data Set</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = train_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
</code></pre>
<h1 id="KNN-Regression"><a href="#KNN-Regression" class="headerlink" title="KNN Regression"></a>KNN Regression</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knr = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line">knr.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>0.9746459963987609
</code></pre>
<h2 id="Predict-a-data-1"><a href="#Predict-a-data-1" class="headerlink" title="Predict a data 1"></a>Predict a data 1</h2><ul>
<li>the weight of a 50-centimeter-long perch</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">50</span>]])</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&quot;D&quot;</span>) <span class="comment"># 3 neighbors</span></span><br><span class="line">ax.scatter(<span class="number">50</span>, knr.predict([[<span class="number">50</span>]]), marker=<span class="string">&#x27;^&#x27;</span>) <span class="comment"># new data</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_2_1.png"></p>
<h2 id="Predict-a-data-2"><a href="#Predict-a-data-2" class="headerlink" title="Predict a data 2"></a>Predict a data 2</h2><ul>
<li>the weight of a 100-centimeter-long perch</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">100</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">distances, indexes = knr.kneighbors([[<span class="number">100</span>]])</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&quot;D&quot;</span>) <span class="comment"># 3 neighbors</span></span><br><span class="line">ax.scatter(<span class="number">100</span>, knr.predict([[<span class="number">100</span>]]), marker=<span class="string">&#x27;^&#x27;</span>) <span class="comment"># new data</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_2_2.png"></p>
<ul>
<li><p>Beyond the scope of the new training set, incorrect values can be predicted.</p>
</li>
<li><p>No matter how big the length is, the weight doesn’t increase anymore.</p>
</li>
</ul>
<p>※ Machine learning models must be trained periodically.</p>
<blockquote>
<p>MLOps (Machine Learning &amp; Opearations)</p>
</blockquote>
<ul>
<li>the essential skill for data scientist, ML engineer.</li>
</ul>
<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><ul>
<li>in statistics:<ul>
<li>The process of finding causal relationships is more important.</li>
<li>4 assumptions (linearity, normality, independence, equal variance)</li>
</ul>
</li>
<li>in ML:<ul>
<li>Predicting results is more important.</li>
<li>R-squared, MAE, RMSE, etc</li>
</ul>
</li>
</ul>
<h2 id="Predict-a-data"><a href="#Predict-a-data" class="headerlink" title="Predict a data"></a>Predict a data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr = LinearRegression()</span><br><span class="line"></span><br><span class="line">lr.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1241.83860323]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes], marker=<span class="string">&quot;D&quot;</span>) <span class="comment"># 3 neighbors</span></span><br><span class="line">ax.scatter(<span class="number">50</span>, lr.predict([[<span class="number">50</span>]]), marker=<span class="string">&#x27;^&#x27;</span>) <span class="comment"># new data</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_2_3.png"></p>
<h2 id="Regression-equation"><a href="#Regression-equation" class="headerlink" title="Regression equation"></a>Regression equation</h2><ul>
<li>coef_ : regression coefficient(weight)</li>
<li>intercept_ : regression intercept<blockquote>
<p>$y &#x3D; a + bx$</p>
</blockquote>
</li>
<li>coefficient &amp; intercept : model parameter<ul>
<li>Linear Regression is a model-based learning.</li>
<li>KNN Regression is a case-based learning.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[39.01714496] -709.0186449535477
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line"></span><br><span class="line"><span class="comment"># scatter plot of training set</span></span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># linear equation from 0 to 50</span></span><br><span class="line">ax.plot([<span class="number">0</span>,<span class="number">50</span>], [<span class="number">0</span>*lr.coef_+lr.intercept_, <span class="number">50</span>*lr.coef_+lr.intercept_])</span><br><span class="line"></span><br><span class="line">ax.scatter(<span class="number">50</span>, lr.predict([[<span class="number">50</span>]]), marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.set_label(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_label(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_2_4.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_input, test_target)) <span class="comment"># Underfitting</span></span><br></pre></td></tr></table></figure>

<pre><code>0.939846333997604
0.8247503123313558
</code></pre>
<ul>
<li>The model is so simple that it is underfit overall.<ul>
<li>It seems that polynomial regression is needed.</li>
</ul>
</li>
</ul>
<h1 id="Polynomial-Regression"><a href="#Polynomial-Regression" class="headerlink" title="Polynomial Regression"></a>Polynomial Regression</h1><ul>
<li>coef_ : regression coefficients(weights)</li>
<li>intercept_ : regression intercept<blockquote>
<p>$y &#x3D; a + b_1x_1 + b_2x_2 + … + b_nx_n$</p>
</blockquote>
</li>
</ul>
<h2 id="Predict-a-data-1"><a href="#Predict-a-data-1" class="headerlink" title="Predict a data"></a>Predict a data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Broadcasting in Numpy</span></span><br><span class="line">train_poly = np.column_stack((train_input ** <span class="number">2</span>, train_input))</span><br><span class="line">test_poly = np.column_stack((test_input ** <span class="number">2</span>, test_input))</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape, test_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 2) (14, 2)
</code></pre>
<p>※ Broadcasting in Numpy</p>
<ul>
<li>tutorial : <a target="_blank" rel="noopener" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">https://numpy.org/doc/stable/user/basics.broadcasting.html</a></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr2 = LinearRegression()</span><br><span class="line">lr2.fit(train_poly, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr2.predict([[<span class="number">50</span>**<span class="number">2</span>, <span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1573.98423528]
</code></pre>
<h2 id="Regression-equation-1"><a href="#Regression-equation-1" class="headerlink" title="Regression equation"></a>Regression equation</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr2.coef_, lr2.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[  1.01433211 -21.55792498] 116.0502107827827
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">point = np.arange(<span class="number">15</span>,<span class="number">50</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line">ax.plot(point,  lr2.coef_[<span class="number">0</span>]*point**<span class="number">2</span> + lr2.coef_[<span class="number">1</span>]*point + lr2.intercept_)</span><br><span class="line">ax.scatter(<span class="number">50</span>, lr2.predict([[<span class="number">50</span>**<span class="number">2</span>, <span class="number">50</span>]]), marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_2_5.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr2.score(train_poly, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr2.score(test_poly, test_target)) <span class="comment"># Underfitting</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9706807451768623
0.9775935108325122
</code></pre>
<ul>
<li>The model has improved a lot, but it is still underfit.<ul>
<li>It seems that a more complex model is needed.</li>
</ul>
</li>
</ul>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-28T08:33:50.000Z" title="2022. 3. 28. 오후 5:33:50">2022-03-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.462Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">2 minutes read (About 342 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/28/Python/ML/ML_ch_3_1/">ML Practice 3_1</a></h1><div class="content"><h1 id="Prepare-Data"><a href="#Prepare-Data" class="headerlink" title="Prepare Data"></a>Prepare Data</h1><h2 id="Data-Set"><a href="#Data-Set" class="headerlink" title="Data Set"></a>Data Set</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>

<h2 id="Visualize-Data"><a href="#Visualize-Data" class="headerlink" title="Visualize Data"></a>Visualize Data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># object orientation</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(perch_length, perch_weight)</span><br><span class="line">ax.set_label(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_label(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_3_1.png"></p>
<h1 id="KNN-Regression"><a href="#KNN-Regression" class="headerlink" title="KNN Regression"></a>KNN Regression</h1><ul>
<li>low importance</li>
</ul>
<h2 id="Split-Data"><a href="#Split-Data" class="headerlink" title="Split Data"></a>Split Data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((42,), (14,), (42,), (14,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># change data set to two-dimensional array</span></span><br><span class="line">train_input = train_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
</code></pre>
<h2 id="Model-fitting"><a href="#Model-fitting" class="headerlink" title="Model fitting"></a>Model fitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line">knr = KNeighborsRegressor()</span><br><span class="line"></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line">knr.score(test_input, test_target) <span class="comment"># Coefficient of Determination (R-squared)</span></span><br></pre></td></tr></table></figure>




<pre><code>0.992809406101064
</code></pre>
<h2 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h2><ul>
<li>Returns the average of absolute value errors between targets and predictions.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line">test_prediction = knr.predict(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae) <span class="comment"># On average, about 19.2 grams different from the target.</span></span><br></pre></td></tr></table></figure>

<pre><code>19.157142857142862
</code></pre>
<h2 id="Overfitting-vs-Underfitting"><a href="#Overfitting-vs-Underfitting" class="headerlink" title="Overfitting vs. Underfitting"></a>Overfitting vs. Underfitting</h2><ul>
<li>Overfitting:<ul>
<li>Good prediction from training data and poor prediction from testing data</li>
<li>difficulty in finding and solving</li>
</ul>
</li>
<li>Underfitting:<ul>
<li>Poor prediction from training data and good prediction from testing data</li>
<li>Or, poor prediction on both sides</li>
<li>The amount of data is small or the model is too simple.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(knr.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9698823289099254
0.992809406101064
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the number of neighbors to 3.</span></span><br><span class="line">knr.n_neighbors = <span class="number">3</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(knr.score(train_input, train_target))</span><br><span class="line"><span class="built_in">print</span>(knr.score(test_input, test_target))</span><br><span class="line"></span><br><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line">mae = mean_absolute_error(test_target, test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae) <span class="comment"># On average, about 35.4 grams different from the target.</span></span><br></pre></td></tr></table></figure>

<pre><code>0.9804899950518966
0.9746459963987609
35.42380952380951
</code></pre>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ol>
<li>k&#x3D;5 : R^2&#x3D; 0.99, MAE&#x3D;19.2</li>
<li>k&#x3D;3 : R^2&#x3D; 0.97, MAE&#x3D;35.4</li>
</ol>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-28T08:32:34.000Z" title="2022. 3. 28. 오후 5:32:34">2022-03-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.304Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">3 minutes read (About 475 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/28/Python/ML/ML_ch_2_2/">ML Practice 2_2</a></h1><div class="content"><h1 id="Prepare-data-with-Numpy"><a href="#Prepare-data-with-Numpy" class="headerlink" title="Prepare data with Numpy"></a>Prepare data with Numpy</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fish_length = [<span class="number">25.4</span>, <span class="number">26.3</span>, <span class="number">26.5</span>, <span class="number">29.0</span>, <span class="number">29.0</span>, <span class="number">29.7</span>, <span class="number">29.7</span>, <span class="number">30.0</span>, <span class="number">30.0</span>, <span class="number">30.7</span>, <span class="number">31.0</span>, <span class="number">31.0</span>, </span><br><span class="line">                <span class="number">31.5</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">33.0</span>, <span class="number">33.0</span>, <span class="number">33.5</span>, <span class="number">33.5</span>, <span class="number">34.0</span>, <span class="number">34.0</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">                <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">36.0</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">38.5</span>, <span class="number">38.5</span>, <span class="number">39.5</span>, <span class="number">41.0</span>, <span class="number">41.0</span>, <span class="number">9.8</span>, </span><br><span class="line">                <span class="number">10.5</span>, <span class="number">10.6</span>, <span class="number">11.0</span>, <span class="number">11.2</span>, <span class="number">11.3</span>, <span class="number">11.8</span>, <span class="number">11.8</span>, <span class="number">12.0</span>, <span class="number">12.2</span>, <span class="number">12.4</span>, <span class="number">13.0</span>, <span class="number">14.3</span>, <span class="number">15.0</span>]</span><br><span class="line">fish_weight = [<span class="number">242.0</span>, <span class="number">290.0</span>, <span class="number">340.0</span>, <span class="number">363.0</span>, <span class="number">430.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">390.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">475.0</span>, <span class="number">500.0</span>, </span><br><span class="line">                <span class="number">500.0</span>, <span class="number">340.0</span>, <span class="number">600.0</span>, <span class="number">600.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">610.0</span>, <span class="number">650.0</span>, <span class="number">575.0</span>, <span class="number">685.0</span>, <span class="number">620.0</span>, <span class="number">680.0</span>, </span><br><span class="line">                <span class="number">700.0</span>, <span class="number">725.0</span>, <span class="number">720.0</span>, <span class="number">714.0</span>, <span class="number">850.0</span>, <span class="number">1000.0</span>, <span class="number">920.0</span>, <span class="number">955.0</span>, <span class="number">925.0</span>, <span class="number">975.0</span>, <span class="number">950.0</span>, <span class="number">6.7</span>, </span><br><span class="line">                <span class="number">7.5</span>, <span class="number">7.0</span>, <span class="number">9.7</span>, <span class="number">9.8</span>, <span class="number">8.7</span>, <span class="number">10.0</span>, <span class="number">9.9</span>, <span class="number">9.8</span>, <span class="number">12.2</span>, <span class="number">13.4</span>, <span class="number">12.2</span>, <span class="number">19.7</span>, <span class="number">19.9</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">fish_data = np.column_stack((fish_length, fish_weight))</span><br><span class="line"><span class="built_in">print</span>(fish_data[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[ 25.4 242. ]
 [ 26.3 290. ]
 [ 26.5 340. ]
 [ 29.  363. ]
 [ 29.  430. ]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_target = np.concatenate((np.ones(<span class="number">35</span>), np.zeros(<span class="number">14</span>)))</span><br><span class="line"><span class="built_in">print</span>(fish_target)</span><br></pre></td></tr></table></figure>

<pre><code>[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0.]
</code></pre>
<h1 id="Split-data-with-Scikit-learn"><a href="#Split-data-with-Scikit-learn" class="headerlink" title="Split data with Scikit-learn"></a>Split data with Scikit-learn</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># stratify: spliting data according to class proportions</span></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, stratify=fish_target, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br><span class="line"><span class="built_in">print</span>(train_target.shape, test_target.shape)</span><br><span class="line"><span class="built_in">print</span>(test_target)</span><br></pre></td></tr></table></figure>

<pre><code>(36, 2) (13, 2)
(36,) (13,)
[0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]
</code></pre>
<h1 id="KNN-1"><a href="#KNN-1" class="headerlink" title="KNN 1"></a>KNN 1</h1><h2 id="KNN-fitting"><a href="#KNN-fitting" class="headerlink" title="KNN fitting"></a>KNN fitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">kn = KNeighborsClassifier()</span><br><span class="line">kn.fit(train_input, train_target)</span><br><span class="line">kn.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<h2 id="Predicting-new-data"><a href="#Predicting-new-data" class="headerlink" title="Predicting new data"></a>Predicting new data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.predict([[<span class="number">25</span>,<span class="number">150</span>]])) <span class="comment"># the actual data is a bream, but predicted to be smelt.</span></span><br></pre></td></tr></table></figure>

<pre><code>[0.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatter plot with new data</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input[:,<span class="number">0</span>], train_input[:,<span class="number">1</span>])</span><br><span class="line">ax.scatter(<span class="number">25</span>, <span class="number">150</span>, marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_2_2_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">distances, indexes = kn.kneighbors([[<span class="number">25</span>,<span class="number">150</span>]]) <span class="comment"># the nearest neighbors (default: 5)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatter plot with 5 nearest neighbors</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input[:,<span class="number">0</span>], train_input[:,<span class="number">1</span>])</span><br><span class="line">ax.scatter(<span class="number">25</span>, <span class="number">150</span>, marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.scatter(train_input[indexes,<span class="number">0</span>], train_input[indexes,<span class="number">1</span>], marker=<span class="string">&#x27;D&#x27;</span>) <span class="comment"># rhombus marker</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_2_2_2.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scatter plot on the same scale</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input[:,<span class="number">0</span>], train_input[:,<span class="number">1</span>])</span><br><span class="line">ax.scatter(<span class="number">25</span>, <span class="number">150</span>, marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.scatter(train_input[indexes,<span class="number">0</span>], train_input[indexes,<span class="number">1</span>], marker=<span class="string">&#x27;D&#x27;</span>) <span class="comment"># rhombus marker</span></span><br><span class="line">ax.set_xlim((<span class="number">0</span>,<span class="number">1000</span>)) <span class="comment"># change the x scale</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_2_2_3.png"></p>
<h1 id="KNN-2"><a href="#KNN-2" class="headerlink" title="KNN 2"></a>KNN 2</h1><h2 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># standard score</span></span><br><span class="line">mean = np.mean(train_input, axis=<span class="number">0</span>) <span class="comment"># axis=0 : for each feature</span></span><br><span class="line">std = np.std(train_input, axis=<span class="number">0</span>)</span><br><span class="line">train_scaled = (train_input - mean) / std <span class="comment"># broadcasting in numpy</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Scatter plot with standard score</span></span><br><span class="line">new = ([<span class="number">25</span>, <span class="number">150</span>] - mean ) / std</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_scaled[:,<span class="number">0</span>], train_scaled[:,<span class="number">1</span>])</span><br><span class="line">ax.scatter(new[<span class="number">0</span>], new[<span class="number">1</span>], marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_2_2_4.png"></p>
<h2 id="KNN-fitting-1"><a href="#KNN-fitting-1" class="headerlink" title="KNN fitting"></a>KNN fitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_scaled = (test_input - mean) / std</span><br><span class="line">kn.fit(train_scaled, train_target)</span><br><span class="line">kn.score(test_scaled, test_target) <span class="comment"># </span></span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<h2 id="Predicting-new-data-1"><a href="#Predicting-new-data-1" class="headerlink" title="Predicting new data"></a>Predicting new data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.predict([new])) <span class="comment"># the actual data is a bream, and predicted to be bream.</span></span><br></pre></td></tr></table></figure>

<pre><code>[1.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">distances, indexes = kn.kneighbors([new])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Scatter plot with 5 nearest neighbors</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_scaled[:,<span class="number">0</span>], train_scaled[:,<span class="number">1</span>])</span><br><span class="line">ax.scatter(new[<span class="number">0</span>], new[<span class="number">1</span>], marker=<span class="string">&quot;^&quot;</span>)</span><br><span class="line">ax.scatter(train_scaled[indexes,<span class="number">0</span>], train_scaled[indexes,<span class="number">1</span>], marker=<span class="string">&#x27;D&#x27;</span>) <span class="comment"># rhombus marker</span></span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_2_2_5.png"></p>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-28T08:31:35.000Z" title="2022. 3. 28. 오후 5:31:35">2022-03-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.167Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">2 minutes read (About 298 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/28/Python/ML/ML_ch_2_1/">ML Practice 2_1</a></h1><div class="content"><h1 id="ML-Algorithm"><a href="#ML-Algorithm" class="headerlink" title="ML Algorithm"></a>ML Algorithm</h1><h2 id="Supervised-Learning-지도-학습"><a href="#Supervised-Learning-지도-학습" class="headerlink" title="Supervised Learning(지도 학습)"></a>Supervised Learning(지도 학습)</h2><ul>
<li>Input(입력; independent variable) &amp; Target(타깃; dependent variable)</li>
<li>Question with a correct answer<ul>
<li>Type 1: Classification(분류)</li>
<li>Type 2: Regression(예측)</li>
</ul>
</li>
<li>Feature(특성) &#x3D; independent variable(column)</li>
</ul>
<h2 id="Unspervised-Learning-비지도-학습"><a href="#Unspervised-Learning-비지도-학습" class="headerlink" title="Unspervised Learning(비지도 학습)"></a>Unspervised Learning(비지도 학습)</h2><ul>
<li>only Input, not Target</li>
<li>Question without an answer</li>
<li>algorithm automatically categorizes</li>
</ul>
<h1 id="Data-set"><a href="#Data-set" class="headerlink" title="Data set"></a>Data set</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fish_length = [<span class="number">25.4</span>, <span class="number">26.3</span>, <span class="number">26.5</span>, <span class="number">29.0</span>, <span class="number">29.0</span>, <span class="number">29.7</span>, <span class="number">29.7</span>, <span class="number">30.0</span>, <span class="number">30.0</span>, <span class="number">30.7</span>, <span class="number">31.0</span>, <span class="number">31.0</span>, </span><br><span class="line">                <span class="number">31.5</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">33.0</span>, <span class="number">33.0</span>, <span class="number">33.5</span>, <span class="number">33.5</span>, <span class="number">34.0</span>, <span class="number">34.0</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">                <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">36.0</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">38.5</span>, <span class="number">38.5</span>, <span class="number">39.5</span>, <span class="number">41.0</span>, <span class="number">41.0</span>, <span class="number">9.8</span>, </span><br><span class="line">                <span class="number">10.5</span>, <span class="number">10.6</span>, <span class="number">11.0</span>, <span class="number">11.2</span>, <span class="number">11.3</span>, <span class="number">11.8</span>, <span class="number">11.8</span>, <span class="number">12.0</span>, <span class="number">12.2</span>, <span class="number">12.4</span>, <span class="number">13.0</span>, <span class="number">14.3</span>, <span class="number">15.0</span>]</span><br><span class="line">fish_weight = [<span class="number">242.0</span>, <span class="number">290.0</span>, <span class="number">340.0</span>, <span class="number">363.0</span>, <span class="number">430.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">390.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">475.0</span>, <span class="number">500.0</span>, </span><br><span class="line">                <span class="number">500.0</span>, <span class="number">340.0</span>, <span class="number">600.0</span>, <span class="number">600.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">610.0</span>, <span class="number">650.0</span>, <span class="number">575.0</span>, <span class="number">685.0</span>, <span class="number">620.0</span>, <span class="number">680.0</span>, </span><br><span class="line">                <span class="number">700.0</span>, <span class="number">725.0</span>, <span class="number">720.0</span>, <span class="number">714.0</span>, <span class="number">850.0</span>, <span class="number">1000.0</span>, <span class="number">920.0</span>, <span class="number">955.0</span>, <span class="number">925.0</span>, <span class="number">975.0</span>, <span class="number">950.0</span>, <span class="number">6.7</span>, </span><br><span class="line">                <span class="number">7.5</span>, <span class="number">7.0</span>, <span class="number">9.7</span>, <span class="number">9.8</span>, <span class="number">8.7</span>, <span class="number">10.0</span>, <span class="number">9.9</span>, <span class="number">9.8</span>, <span class="number">12.2</span>, <span class="number">13.4</span>, <span class="number">12.2</span>, <span class="number">19.7</span>, <span class="number">19.9</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_data = [[l,w] <span class="keyword">for</span> l, w <span class="keyword">in</span> <span class="built_in">zip</span>(fish_length, fish_weight)]</span><br><span class="line">fish_target = [<span class="number">1</span>]*<span class="number">35</span> + [<span class="number">0</span>]*<span class="number">14</span> <span class="comment"># 1: bream, 0: smelt</span></span><br></pre></td></tr></table></figure>

<h1 id="KNN-1"><a href="#KNN-1" class="headerlink" title="KNN 1"></a>KNN 1</h1><h2 id="Create-KNN"><a href="#Create-KNN" class="headerlink" title="Create KNN"></a>Create KNN</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">kn = KNeighborsClassifier()</span><br></pre></td></tr></table></figure>

<h2 id="Data-Split"><a href="#Data-Split" class="headerlink" title="Data Split"></a>Data Split</h2><ul>
<li>train set &amp; test set</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = fish_data[:<span class="number">35</span>]</span><br><span class="line">train_target = fish_target[:<span class="number">35</span>]</span><br><span class="line">test_input = fish_data[<span class="number">35</span>:]</span><br><span class="line">test_target = fish_target[<span class="number">35</span>:]</span><br></pre></td></tr></table></figure>

<h2 id="Model-fitting"><a href="#Model-fitting" class="headerlink" title="Model fitting"></a>Model fitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kn = kn.fit(train_input, train_target)</span><br><span class="line">kn.score(test_input, test_target) <span class="comment"># Sampling bias</span></span><br></pre></td></tr></table></figure>




<pre><code>0.0
</code></pre>
<h1 id="KNN-2"><a href="#KNN-2" class="headerlink" title="KNN 2"></a>KNN 2</h1><h2 id="Numpy-array"><a href="#Numpy-array" class="headerlink" title="Numpy array"></a>Numpy array</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">input_arr = np.array(fish_data)</span><br><span class="line">target_arr = np.array(fish_target)</span><br><span class="line"></span><br><span class="line">input_arr.shape, target_arr.shape</span><br></pre></td></tr></table></figure>




<pre><code>((49, 2), (49,))
</code></pre>
<h2 id="Data-Shuffle-and-Split"><a href="#Data-Shuffle-and-Split" class="headerlink" title="Data Shuffle and Split"></a>Data Shuffle and Split</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">index = np.arange(<span class="number">49</span>)</span><br><span class="line"><span class="built_in">print</span>(index)</span><br><span class="line">np.random.shuffle(index)</span><br><span class="line"><span class="built_in">print</span>(index)</span><br></pre></td></tr></table></figure>

<pre><code>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48]
[13 45 47 44 17 27 26 25 31 19 12  4 34  8  3  6 40 41 46 15  9 16 24 33
 30  0 43 32  5 29 11 36  1 21  2 37 35 23 39 10 22 18 48 20  7 42 14 28
 38]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = input_arr[index[:<span class="number">35</span>]]</span><br><span class="line">train_target = target_arr[index[:<span class="number">35</span>]]</span><br><span class="line">test_input = input_arr[index[<span class="number">35</span>:]]</span><br><span class="line">test_target = target_arr[index[<span class="number">35</span>:]]</span><br></pre></td></tr></table></figure>

<h2 id="Scatter-Plot"><a href="#Scatter-Plot" class="headerlink" title="Scatter Plot"></a>Scatter Plot</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input[:,<span class="number">0</span>],train_input[:,<span class="number">1</span>])</span><br><span class="line">ax.scatter(test_input[:,<span class="number">0</span>],test_input[:,<span class="number">1</span>])</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_2_1.png"></p>
<h2 id="Model-fitting-1"><a href="#Model-fitting-1" class="headerlink" title="Model fitting"></a>Model fitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kn = kn.fit(train_input, train_target)</span><br><span class="line">kn.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.predict(test_input) == test_target)</span><br></pre></td></tr></table></figure>

<pre><code>[ True  True  True  True  True  True  True  True  True  True  True  True
  True  True]
</code></pre>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-26T06:38:35.000Z" title="2022. 3. 26. 오후 3:38:35">2022-03-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:52.024Z" title="2022. 10. 5. 오후 2:39:52">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/ML/">ML</a></span><span class="level-item">a minute read (About 204 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/26/Python/ML/ML_ch_1_3/">ML Practice 1_3</a></h1><div class="content"><h1 id="Market-and-Machine-Learning"><a href="#Market-and-Machine-Learning" class="headerlink" title="Market and Machine Learning"></a>Market and Machine Learning</h1><h2 id="Classify-Bream-and-Smelt"><a href="#Classify-Bream-and-Smelt" class="headerlink" title="Classify Bream and Smelt"></a>Classify Bream and Smelt</h2><h3 id="Bream-Data"><a href="#Bream-Data" class="headerlink" title="Bream Data"></a>Bream Data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bream_length = [<span class="number">25.4</span>, <span class="number">26.3</span>, <span class="number">26.5</span>, <span class="number">29.0</span>, <span class="number">29.0</span>, <span class="number">29.7</span>, <span class="number">29.7</span>, <span class="number">30.0</span>, <span class="number">30.0</span>, <span class="number">30.7</span>, <span class="number">31.0</span>, <span class="number">31.0</span>, </span><br><span class="line">                <span class="number">31.5</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">33.0</span>, <span class="number">33.0</span>, <span class="number">33.5</span>, <span class="number">33.5</span>, <span class="number">34.0</span>, <span class="number">34.0</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">                <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">36.0</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">38.5</span>, <span class="number">38.5</span>, <span class="number">39.5</span>, <span class="number">41.0</span>, <span class="number">41.0</span>]</span><br><span class="line">bream_weight = [<span class="number">242.0</span>, <span class="number">290.0</span>, <span class="number">340.0</span>, <span class="number">363.0</span>, <span class="number">430.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">390.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">475.0</span>, <span class="number">500.0</span>, </span><br><span class="line">                <span class="number">500.0</span>, <span class="number">340.0</span>, <span class="number">600.0</span>, <span class="number">600.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">610.0</span>, <span class="number">650.0</span>, <span class="number">575.0</span>, <span class="number">685.0</span>, <span class="number">620.0</span>, <span class="number">680.0</span>, </span><br><span class="line">                <span class="number">700.0</span>, <span class="number">725.0</span>, <span class="number">720.0</span>, <span class="number">714.0</span>, <span class="number">850.0</span>, <span class="number">1000.0</span>, <span class="number">920.0</span>, <span class="number">955.0</span>, <span class="number">925.0</span>, <span class="number">975.0</span>, <span class="number">950.0</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.scatter(bream_length, bream_weight)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_1_3_1.png"></p>
<h3 id="Smelt-Data"><a href="#Smelt-Data" class="headerlink" title="Smelt Data"></a>Smelt Data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">smelt_length = [<span class="number">9.8</span>, <span class="number">10.5</span>, <span class="number">10.6</span>, <span class="number">11.0</span>, <span class="number">11.2</span>, <span class="number">11.3</span>, <span class="number">11.8</span>, <span class="number">11.8</span>, <span class="number">12.0</span>, <span class="number">12.2</span>, <span class="number">12.4</span>, <span class="number">13.0</span>, <span class="number">14.3</span>, <span class="number">15.0</span>]</span><br><span class="line">smelt_weight = [<span class="number">6.7</span>, <span class="number">7.5</span>, <span class="number">7.0</span>, <span class="number">9.7</span>, <span class="number">9.8</span>, <span class="number">8.7</span>, <span class="number">10.0</span>, <span class="number">9.9</span>, <span class="number">9.8</span>, <span class="number">12.2</span>, <span class="number">13.4</span>, <span class="number">12.2</span>, <span class="number">19.7</span>, <span class="number">19.9</span>]</span><br><span class="line"></span><br><span class="line">plt.scatter(bream_length, bream_weight)</span><br><span class="line">plt.scatter(smelt_length, smelt_weight)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/ML/ML_ch_1_3_2.png"></p>
<h2 id="1st-ML-Program"><a href="#1st-ML-Program" class="headerlink" title="1st ML Program"></a>1st ML Program</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">length = bream_length + smelt_length</span><br><span class="line">weight = bream_weight + smelt_weight</span><br><span class="line"></span><br><span class="line">fish_data = [[l,w] <span class="keyword">for</span> l, w <span class="keyword">in</span> <span class="built_in">zip</span>(length, weight)]</span><br><span class="line"><span class="built_in">print</span>(fish_data)</span><br></pre></td></tr></table></figure>

<pre><code>[[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0], [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7], [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_target = [<span class="number">1</span>]*<span class="number">35</span> + [<span class="number">0</span>]*<span class="number">14</span></span><br><span class="line"><span class="built_in">print</span>(fish_target)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
</code></pre>
<h3 id="K-Nearest-Neighbor"><a href="#K-Nearest-Neighbor" class="headerlink" title="K-Nearest Neighbor"></a>K-Nearest Neighbor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line">kn = KNeighborsClassifier()</span><br><span class="line">kn.fit(fish_data, fish_target)</span><br><span class="line">kn.score(fish_data, fish_target)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kn.predict([[<span class="number">30</span>,<span class="number">600</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>array([1])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn._fit_X)</span><br><span class="line"><span class="built_in">print</span>(kn._y)</span><br></pre></td></tr></table></figure>

<pre><code>[[  25.4  242. ]
 [  26.3  290. ]
 [  26.5  340. ]
 [  29.   363. ]
 [  29.   430. ]
 [  29.7  450. ]
 [  29.7  500. ]
 [  30.   390. ]
 [  30.   450. ]
 [  30.7  500. ]
 [  31.   475. ]
 [  31.   500. ]
 [  31.5  500. ]
 [  32.   340. ]
 [  32.   600. ]
 [  32.   600. ]
 [  33.   700. ]
 [  33.   700. ]
 [  33.5  610. ]
 [  33.5  650. ]
 [  34.   575. ]
 [  34.   685. ]
 [  34.5  620. ]
 [  35.   680. ]
 [  35.   700. ]
 [  35.   725. ]
 [  35.   720. ]
 [  36.   714. ]
 [  36.   850. ]
 [  37.  1000. ]
 [  38.5  920. ]
 [  38.5  955. ]
 [  39.5  925. ]
 [  41.   975. ]
 [  41.   950. ]
 [   9.8    6.7]
 [  10.5    7.5]
 [  10.6    7. ]
 [  11.     9.7]
 [  11.2    9.8]
 [  11.3    8.7]
 [  11.8   10. ]
 [  11.8    9.9]
 [  12.     9.8]
 [  12.2   12.2]
 [  12.4   13.4]
 [  13.    12.2]
 [  14.3   19.7]
 [  15.    19.9]]
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kn49 = KNeighborsClassifier(n_neighbors=<span class="number">49</span>)</span><br><span class="line">kn49.fit(fish_data, fish_target)</span><br><span class="line">kn49.score(fish_data, fish_target)</span><br></pre></td></tr></table></figure>




<pre><code>0.7142857142857143
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>, <span class="number">50</span>):</span><br><span class="line">  kn.n_neighbors = n</span><br><span class="line">  score = kn.score(fish_data, fish_target)</span><br><span class="line">  <span class="keyword">if</span> score &lt; <span class="number">1</span>:</span><br><span class="line">    <span class="built_in">print</span>(n, score)</span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<pre><code>18 0.9795918367346939
</code></pre>
<p><em>Ref.) <u> 혼자 공부하는 머신러닝+딥러닝 (박해선, 한빛미디어) <u/></em></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-03-24T02:58:50.000Z" title="2022. 3. 24. 오전 11:58:50">2022-03-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-10-05T05:39:54.854Z" title="2022. 10. 5. 오후 2:39:54">2022-10-05</time></span><span class="level-item"> Jiwon Kang </span><span class="level-item"><a class="link-muted" href="/categories/python/">python</a><span> / </span><a class="link-muted" href="/categories/python/tutorial/">tutorial</a></span><span class="level-item">11 minutes read (About 1685 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/03/24/Python/Tutorial/visual_tutorial_01/">Visualization tutorial</a></h1><div class="content"><h1 id="데이터-시각화의-기본-조건"><a href="#데이터-시각화의-기본-조건" class="headerlink" title="데이터 시각화의 기본 조건"></a>데이터 시각화의 기본 조건</h1><ul>
<li>목적에 맞는 그래프 선정<ul>
<li>선형 그래프, 막대 그래프, 산점도, 박스플롯 등등</li>
</ul>
</li>
<li>환경에 맞는 도구 선택<ul>
<li>코드 기반 : R, Python</li>
<li>프로그램 기반 : Excel, PowerBI, Tableau 등등</li>
</ul>
</li>
<li>문맥(도메인)에 맞는 색과 도형 사용</li>
</ul>
<h1 id="파이썬-시각화-라이브러리"><a href="#파이썬-시각화-라이브러리" class="headerlink" title="파이썬 시각화 라이브러리"></a>파이썬 시각화 라이브러리</h1><h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><ul>
<li>정형 데이터  &#x2F; 이미지 데이터</li>
<li>Pyplot API : Pyplot 모듈에 있는 함수를 각각 불러와서 구현<ul>
<li>사용하기 편리하나, 세부 옵션 조정이 어려움</li>
</ul>
</li>
<li>객체지향 API : Matplotlib에 구현된 객체지향 라이브러리를 직접 활용<ul>
<li>라이브러리가 늘어나고, 코드가 복잡함</li>
<li>그래프의 디테일한 세부 옵션 조정이 용이함</li>
</ul>
</li>
<li>일반적으로 두 API를 혼합하여 사용</li>
</ul>
<h2 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h2><ul>
<li>Matplotlib에 종속된 라이브러리</li>
<li>Matplotlib에 비해 코드가 간결함</li>
<li>통계 그래프 구현이 보다 용이</li>
<li>세부적인 옵션은 Matplotlib에서 조정</li>
</ul>
<h1 id="라이브러리-불러오기"><a href="#라이브러리-불러오기" class="headerlink" title="라이브러리 불러오기"></a>라이브러리 불러오기</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;matplotlib ver :&quot;</span>, matplotlib.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;seaborn ver :&quot;</span>, sns.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>matplotlib ver : 3.2.2
seaborn ver : 0.11.2
</code></pre>
<h1 id="시각화-테스트"><a href="#시각화-테스트" class="headerlink" title="시각화 테스트"></a>시각화 테스트</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">dates = [</span><br><span class="line">    <span class="string">&#x27;2021-01-01&#x27;</span>, <span class="string">&#x27;2021-01-02&#x27;</span>, <span class="string">&#x27;2021-01-03&#x27;</span>, <span class="string">&#x27;2021-01-04&#x27;</span>, <span class="string">&#x27;2021-01-05&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;2021-01-06&#x27;</span>, <span class="string">&#x27;2021-01-07&#x27;</span>, <span class="string">&#x27;2021-01-08&#x27;</span>, <span class="string">&#x27;2021-01-09&#x27;</span>, <span class="string">&#x27;2021-01-10&#x27;</span></span><br><span class="line">]</span><br><span class="line">min_temperature = [<span class="number">20.7</span>, <span class="number">17.9</span>, <span class="number">18.8</span>, <span class="number">14.6</span>, <span class="number">15.8</span>, <span class="number">15.8</span>, <span class="number">15.8</span>, <span class="number">17.4</span>, <span class="number">21.8</span>, <span class="number">20.0</span>]</span><br><span class="line">max_temperature = [<span class="number">34.7</span>, <span class="number">28.9</span>, <span class="number">31.8</span>, <span class="number">25.6</span>, <span class="number">28.8</span>, <span class="number">21.8</span>, <span class="number">22.8</span>, <span class="number">28.4</span>, <span class="number">30.8</span>, <span class="number">32.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 파이썬 시각화 수행 전 기본 설정 (숫자는 변경 가능)</span></span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">1</span>, figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">ax.plot(dates, min_temperature, label = <span class="string">&quot;Min Temp.&quot;</span>)</span><br><span class="line">ax.plot(dates, max_temperature, label = <span class="string">&quot;Max Temp.&quot;</span>)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_1.png"></p>
<h1 id="주식-데이터-예제"><a href="#주식-데이터-예제" class="headerlink" title="주식 데이터 예제"></a>주식 데이터 예제</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install yfinance --upgrade --no-cache-<span class="built_in">dir</span></span><br></pre></td></tr></table></figure>

<pre><code>Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70)
Requirement already satisfied: numpy&gt;=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)
Requirement already satisfied: pandas&gt;=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)
Requirement already satisfied: multitasking&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)
Requirement already satisfied: lxml&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0)
Requirement already satisfied: requests&gt;=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2018.9)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24.0-&gt;yfinance) (1.15.0)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2.0.12)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2021.10.8)
Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (1.24.3)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> yfinance <span class="keyword">as</span> yf</span><br><span class="line">data = yf.download(<span class="string">&quot;AAPL&quot;</span>, start=<span class="string">&quot;2019-08-01&quot;</span>, end=<span class="string">&quot;2022-03-23&quot;</span>)</span><br><span class="line">ts = data[<span class="string">&#x27;Open&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(ts.head())</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(ts))</span><br></pre></td></tr></table></figure>

<pre><code>[*********************100%***********************]  1 of 1 completed
Date
2019-08-01    53.474998
2019-08-02    51.382500
2019-08-05    49.497501
2019-08-06    49.077499
2019-08-07    48.852501
Name: Open, dtype: float64
&lt;class &#39;pandas.core.series.Series&#39;&gt;
</code></pre>
<h2 id="pyplot-모듈"><a href="#pyplot-모듈" class="headerlink" title="pyplot 모듈"></a>pyplot 모듈</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.plot(ts)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;Stock Market of AAPL&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Date&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Open Price&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_2.png"></p>
<h2 id="객체지향-라이브러리"><a href="#객체지향-라이브러리" class="headerlink" title="객체지향 라이브러리"></a>객체지향 라이브러리</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(ts)</span><br><span class="line"></span><br><span class="line">ax.set_title(<span class="string">&quot;Stock Market of AAPL&quot;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;Date&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Open Price&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_3.png"></p>
<h1 id="막대-그래프"><a href="#막대-그래프" class="headerlink" title="막대 그래프"></a>막대 그래프</h1><h2 id="Matplotlib-1"><a href="#Matplotlib-1" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> calendar</span><br><span class="line"></span><br><span class="line">month_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]</span><br><span class="line">sold_list = [<span class="number">300</span>, <span class="number">400</span>, <span class="number">550</span>, <span class="number">900</span>, <span class="number">600</span>, <span class="number">960</span>, <span class="number">900</span>, <span class="number">910</span>, <span class="number">800</span>, <span class="number">700</span>, <span class="number">550</span>, <span class="number">450</span>]</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">barplots = ax.bar(month_list, sold_list)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;barplots :&quot;</span>, barplots) <span class="comment"># artists 레이어에 12개의 막대가 저장됨</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> plot <span class="keyword">in</span> barplots:</span><br><span class="line">  <span class="built_in">print</span>(plot)</span><br><span class="line">  <span class="comment"># print(plot.get_x())</span></span><br><span class="line">  <span class="comment"># print(plot.get_y())</span></span><br><span class="line">  <span class="comment"># print(plot.get_width())</span></span><br><span class="line">  <span class="comment"># print(&quot;height:&quot;, plot.get_height())</span></span><br><span class="line">  height = plot.get_height()</span><br><span class="line">  ax.text(plot.get_x() + plot.get_width()/<span class="number">2</span>, height, height, ha = <span class="string">&#x27;center&#x27;</span>, va = <span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(month_list, calendar.month_name[<span class="number">1</span>:<span class="number">13</span>], rotation=<span class="number">30</span>) <span class="comment"># x축</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>barplots : &lt;BarContainer object of 12 artists&gt;
Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0)
Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0)
Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0)
Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0)
Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0)
Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0)
Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0)
Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0)
Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0)
Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0)
Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0)
Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0)
</code></pre>
<p><img src="/images/Python/Tutorial/visual_tutorial_01_4.png"></p>
<h2 id="Seaborn-1"><a href="#Seaborn-1" class="headerlink" title="Seaborn"></a>Seaborn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">sns.countplot(x=<span class="string">&quot;day&quot;</span>, data=tips)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_5.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tips[<span class="string">&#x27;day&#x27;</span>].value_counts().index)</span><br><span class="line"><span class="built_in">print</span>(tips[<span class="string">&#x27;day&#x27;</span>].value_counts().values)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(tips[<span class="string">&#x27;day&#x27;</span>].value_counts(ascending=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>

<pre><code>CategoricalIndex([&#39;Sat&#39;, &#39;Sun&#39;, &#39;Thur&#39;, &#39;Fri&#39;], categories=[&#39;Thur&#39;, &#39;Fri&#39;, &#39;Sat&#39;, &#39;Sun&#39;], ordered=False, dtype=&#39;category&#39;)
[87 76 62 19]

Fri     19
Thur    62
Sun     76
Sat     87
Name: day, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax = sns.countplot(x=<span class="string">&quot;day&quot;</span>, data=tips, order=tips[<span class="string">&#x27;day&#x27;</span>].value_counts().index, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> plot <span class="keyword">in</span> ax.patches:</span><br><span class="line">  <span class="built_in">print</span>(plot)</span><br><span class="line">  height = plot.get_height()</span><br><span class="line">  ax.text(plot.get_x() + plot.get_width()/<span class="number">2</span>, height, height, ha = <span class="string">&#x27;center&#x27;</span>, va = <span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.set_ylim(-<span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>Rectangle(xy=(-0.4, 0), width=0.8, height=87, angle=0)
Rectangle(xy=(0.6, 0), width=0.8, height=76, angle=0)
Rectangle(xy=(1.6, 0), width=0.8, height=62, angle=0)
Rectangle(xy=(2.6, 0), width=0.8, height=19, angle=0)
</code></pre>
<p><img src="/images/Python/Tutorial/visual_tutorial_01_6.png"></p>
<h1 id="산점도"><a href="#산점도" class="headerlink" title="산점도"></a>산점도</h1><h2 id="Matplotlib-2"><a href="#Matplotlib-2" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">tips = sns.load_dataset(<span class="string">&quot;tips&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(tips.info())</span><br><span class="line"></span><br><span class="line">x = tips[<span class="string">&#x27;total_bill&#x27;</span>]</span><br><span class="line">y = tips[<span class="string">&#x27;tip&#x27;</span>]</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">ax.scatter(x,y)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Scatter of tips&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;Total Bill&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;Tip&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 244 entries, 0 to 243
Data columns (total 7 columns):
 #   Column      Non-Null Count  Dtype   
---  ------      --------------  -----   
 0   total_bill  244 non-null    float64 
 1   tip         244 non-null    float64 
 2   sex         244 non-null    category
 3   smoker      244 non-null    category
 4   day         244 non-null    category
 5   time        244 non-null    category
 6   size        244 non-null    int64   
dtypes: category(4), float64(2), int64(1)
memory usage: 7.4 KB
None
</code></pre>
<p><img src="/images/Python/Tutorial/visual_tutorial_01_7.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tips[<span class="string">&#x27;sex_color&#x27;</span>] = tips[<span class="string">&#x27;sex&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;Male&#x27;</span>:<span class="string">&#x27;#4663F5&#x27;</span>, <span class="string">&#x27;Female&#x27;</span>:<span class="string">&#x27;#FF5F2E&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> label, data <span class="keyword">in</span> tips.groupby(<span class="string">&#x27;sex&#x27;</span>):</span><br><span class="line">  ax.scatter(data[<span class="string">&#x27;total_bill&#x27;</span>], data[<span class="string">&#x27;tip&#x27;</span>], label=label, color=data[<span class="string">&#x27;sex_color&#x27;</span>], alpha=<span class="number">0.5</span>)</span><br><span class="line">  ax.set_xlabel(<span class="string">&#x27;Total Bill&#x27;</span>)</span><br><span class="line">  ax.set_ylabel(<span class="string">&#x27;Tip&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_8.png"></p>
<h2 id="Seaborn-2"><a href="#Seaborn-2" class="headerlink" title="Seaborn"></a>Seaborn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">tips = sns.load_dataset(<span class="string">&quot;tips&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(tips.info())</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, hue=<span class="string">&#x27;sex&#x27;</span>, data=tips)</span><br><span class="line">ax.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 244 entries, 0 to 243
Data columns (total 7 columns):
 #   Column      Non-Null Count  Dtype   
---  ------      --------------  -----   
 0   total_bill  244 non-null    float64 
 1   tip         244 non-null    float64 
 2   sex         244 non-null    category
 3   smoker      244 non-null    category
 4   day         244 non-null    category
 5   time        244 non-null    category
 6   size        244 non-null    int64   
dtypes: category(4), float64(2), int64(1)
memory usage: 7.4 KB
None
</code></pre>
<p><img src="/images/Python/Tutorial/visual_tutorial_01_9.png"></p>
<h1 id="두-개의-그래프를-동시에-표현"><a href="#두-개의-그래프를-동시에-표현" class="headerlink" title="두 개의 그래프를 동시에 표현"></a>두 개의 그래프를 동시에 표현</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">15</span>,<span class="number">5</span>))</span><br><span class="line">sns.regplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, data=tips, ax=ax[<span class="number">0</span>], fit_reg=<span class="literal">True</span>)</span><br><span class="line">ax[<span class="number">0</span>].set_title(<span class="string">&quot;Scatterplot with Regression Line&quot;</span>)</span><br><span class="line">sns.regplot(x=<span class="string">&#x27;total_bill&#x27;</span>, y=<span class="string">&#x27;tip&#x27;</span>, data=tips, ax=ax[<span class="number">1</span>], fit_reg=<span class="literal">False</span>)</span><br><span class="line">ax[<span class="number">1</span>].set_title(<span class="string">&quot;Scatterplot without Regression Line&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_10.png"></p>
<h1 id="종합-예제"><a href="#종합-예제" class="headerlink" title="종합 예제"></a>종합 예제</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> (MultipleLocator, AutoMinorLocator, FuncFormatter)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">major_formatter</span>(<span class="params">x, pos</span>):</span><br><span class="line">  <span class="keyword">return</span> <span class="string">&quot;$ %.2f&quot;</span> % x</span><br><span class="line"></span><br><span class="line">formatter = FuncFormatter(major_formatter)</span><br><span class="line"></span><br><span class="line">tips = sns.load_dataset(<span class="string">&quot;tips&quot;</span>)</span><br><span class="line">fig, ax = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">20</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">### 왼쪽 막대 그래프</span></span><br><span class="line">ax0 = sns.barplot(x=<span class="string">&quot;day&quot;</span>, y=<span class="string">&#x27;total_bill&#x27;</span>, data=tips, ax=ax[<span class="number">0</span>],</span><br><span class="line">                  ci=<span class="literal">None</span>, alpha=<span class="number">0.85</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 텍스트 입력</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> ax0.patches:</span><br><span class="line">  height = np.<span class="built_in">round</span>(p.get_height(), <span class="number">2</span>)</span><br><span class="line">  ax0.text(p.get_x() + p.get_width()/<span class="number">2.</span>, height+<span class="number">1</span>, height, ha = <span class="string">&#x27;center&#x27;</span>, size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 축 범위 및 제목 수정</span></span><br><span class="line">ax0.set_ylim(-<span class="number">3</span>, <span class="number">30</span>)</span><br><span class="line">ax0.set_title(<span class="string">&quot;Basic Bar Graph&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 왼쪽 막대 그래프</span></span><br><span class="line">ax1 = sns.barplot(x=<span class="string">&quot;day&quot;</span>, y=<span class="string">&quot;total_bill&quot;</span>, data=tips, ax=ax[<span class="number">1</span>],</span><br><span class="line">                  ci=<span class="literal">None</span>, color=<span class="string">&#x27;lightgray&#x27;</span>, alpha=<span class="number">0.85</span>, zorder=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># total_bill 평균이 가장 큰 요일</span></span><br><span class="line">group_mean = tips.groupby([<span class="string">&#x27;day&#x27;</span>])[<span class="string">&#x27;total_bill&#x27;</span>].agg(<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">h_day = group_mean.sort_values(ascending=<span class="literal">False</span>).index[<span class="number">0</span>] <span class="comment"># sunday</span></span><br><span class="line">h_mean = group_mean.sort_values(ascending=<span class="literal">False</span>).values[<span class="number">0</span>] <span class="comment"># 21.41</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 막대별 옵션 설정</span></span><br><span class="line"><span class="keyword">for</span> plot <span class="keyword">in</span> ax1.patches:</span><br><span class="line">  height = np.<span class="built_in">round</span>(plot.get_height(), <span class="number">2</span>)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 기본 설정</span></span><br><span class="line">  fontweight = <span class="string">&quot;normal&quot;</span></span><br><span class="line">  color = <span class="string">&quot;k&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 조건 설정</span></span><br><span class="line">  <span class="keyword">if</span> h_mean == height:</span><br><span class="line">    fontweight = <span class="string">&quot;bold&quot;</span></span><br><span class="line">    color = <span class="string">&quot;darkred&quot;</span></span><br><span class="line">    plot.set_facecolor(color)</span><br><span class="line">    plot.set_edgecolor(<span class="string">&quot;black&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 텍스트 입력</span></span><br><span class="line">  ax1.text(plot.get_x() + plot.get_width()/<span class="number">2.</span>, height+<span class="number">1</span>, height,</span><br><span class="line">           ha =<span class="string">&#x27;center&#x27;</span>, size=<span class="number">12</span>, fontweight=fontweight, color=color)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># spines 제거</span></span><br><span class="line">ax1.spines[<span class="string">&#x27;top&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">ax1.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&quot;outward&quot;</span>, <span class="number">20</span>))</span><br><span class="line">ax1.spines[<span class="string">&#x27;left&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">ax1.spines[<span class="string">&#x27;right&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line">ax1.spines[<span class="string">&#x27;bottom&#x27;</span>].set_visible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 축 범위 및 제목 수정</span></span><br><span class="line">ax1.set_ylim(-<span class="number">1</span>, <span class="number">30</span>)</span><br><span class="line">ax1.set_title(<span class="string">&quot;Ideal Bar Graph&quot;</span>, size=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">ax1.yaxis.set_major_locator(MultipleLocator(<span class="number">10</span>))</span><br><span class="line">ax1.yaxis.set_major_formatter(formatter)</span><br><span class="line">ax1.yaxis.set_minor_locator(MultipleLocator(<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 축 레이블 수정</span></span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Avg. Total Bill($)&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&quot;Weekday&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 그리드</span></span><br><span class="line">ax1.grid(axis=<span class="string">&quot;y&quot;</span>, which=<span class="string">&quot;major&quot;</span>, color=<span class="string">&quot;lightgray&quot;</span>)</span><br><span class="line">ax1.grid(axis=<span class="string">&quot;y&quot;</span>, which=<span class="string">&quot;minor&quot;</span>, ls=<span class="string">&quot;:&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 축 범주 수정</span></span><br><span class="line"><span class="keyword">for</span> xtick <span class="keyword">in</span> ax1.get_xticklabels():</span><br><span class="line">  <span class="keyword">if</span> xtick.get_text() == h_day:</span><br><span class="line">    xtick.set_color(<span class="string">&quot;darkred&quot;</span>)</span><br><span class="line">    xtick.set_fontweight(<span class="string">&quot;demibold&quot;</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_xticklabels([<span class="string">&#x27;Thursday&#x27;</span>, <span class="string">&#x27;Friday&#x27;</span>, <span class="string">&#x27;Saturday&#x27;</span>, <span class="string">&#x27;Sunday&#x27;</span>], size=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/Python/Tutorial/visual_tutorial_01_11.png"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/3/">Previous</a></div><div class="pagination-next"><a href="/page/5/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link is-current" href="/page/4/">4</a></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link" href="/page/6/">6</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/images/profile.png" alt="Jiwon Kang"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jiwon Kang</p><p class="is-size-6 is-block">Data Scientist</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, South Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">51</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">27</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/gonekng" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/gonekng"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://instagram.com/gone_kng"><i class="fab fa-instagram"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Naver Blog" href="https://blog.naver.com/donumm"><i class="fas fa-blog"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/hexo/"><span class="level-start"><span class="level-item">hexo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/python/"><span class="level-start"><span class="level-item">python</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/python/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li><li><a class="level is-mobile" href="/categories/python/crawling/"><span class="level-start"><span class="level-item">crawling</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/python/tutorial/"><span class="level-start"><span class="level-item">tutorial</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/r/"><span class="level-start"><span class="level-item">r</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/"><span class="level-start"><span class="level-item">setting</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/setting/data-engineering/"><span class="level-start"><span class="level-item">data engineering</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/setting/development/"><span class="level-start"><span class="level-item">development</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/sql/"><span class="level-start"><span class="level-item">sql</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/sql/Oracle/"><span class="level-start"><span class="level-item">Oracle</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-03T06:53:01.000Z">2022-05-03</time></p><p class="title"><a href="/2022/05/03/Setting/Setting%20VS%20Code%20for%20Web%20Development/">Setting VS Code for Web Development</a></p><p class="categories"><a href="/categories/setting/">setting</a> / <a href="/categories/setting/development/">development</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-02T03:08:45.000Z">2022-05-02</time></p><p class="title"><a href="/2022/05/02/SQL/SQL%20TEST%206-7/">SQL TEST 6-7</a></p><p class="categories"><a href="/categories/sql/">sql</a> / <a href="/categories/sql/Oracle/">Oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-02T00:32:11.000Z">2022-05-02</time></p><p class="title"><a href="/2022/05/02/SQL/SQL%20EXERCISE%206-7/">SQL EXERCISE 6-7</a></p><p class="categories"><a href="/categories/sql/">sql</a> / <a href="/categories/sql/Oracle/">Oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-26T07:02:41.000Z">2022-04-26</time></p><p class="title"><a href="/2022/04/26/SQL/Conneting%20SQL%20Developer%20with%20Github/">Conneting SQL Developer with Github</a></p><p class="categories"><a href="/categories/sql/">sql</a> / <a href="/categories/sql/Oracle/">Oracle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-25T08:27:10.000Z">2022-04-25</time></p><p class="title"><a href="/2022/04/25/SQL/Oracle%2019c%20Installation%20in%20Windows11/">Oracle 19c Installation in Windows11</a></p><p class="categories"><a href="/categories/sql/">sql</a> / <a href="/categories/sql/Oracle/">Oracle</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">May 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">April 2022</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/03/"><span class="level-start"><span class="level-item">March 2022</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/BeautifulSoup/"><span class="tag">BeautifulSoup</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Oracle/"><span class="tag">Oracle</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/airflow/"><span class="tag">airflow</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/apache/"><span class="tag">apache</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/crawling/"><span class="tag">crawling</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-engineering/"><span class="tag">data engineering</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/development/"><span class="tag">development</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/elasticsearch/"><span class="tag">elasticsearch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/google-colab/"><span class="tag">google colab</span><span class="tag">33</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kibana/"><span class="tag">kibana</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine learning</span><span class="tag">24</span></a></div><div class="control"><a class="tags has-addons" href="/tags/matplotlib/"><span class="tag">matplotlib</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pandas/"><span class="tag">pandas</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pipeline/"><span class="tag">pipeline</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">36</span></a></div><div class="control"><a class="tags has-addons" href="/tags/r/"><span class="tag">r</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/seaborn/"><span class="tag">seaborn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/setting/"><span class="tag">setting</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sql/"><span class="tag">sql</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/statistic/"><span class="tag">statistic</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/visualization/"><span class="tag">visualization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vscode/"><span class="tag">vscode</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/wsl2/"><span class="tag">wsl2</span><span class="tag">6</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Jiwon&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 Jiwon Kang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>