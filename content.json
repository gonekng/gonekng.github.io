{"meta":{"title":"Jiwon's Blog","subtitle":"","description":"","author":"Jiwon Kang","url":"http://gonekng.github.io","root":"/"},"pages":[{"title":"","date":"2022-10-05T05:40:07.922Z","updated":"2022-10-05T05:40:07.922Z","comments":true,"path":"images/R/R_sample.html","permalink":"http://gonekng.github.io/images/R/R_sample.html","excerpt":"","text":"Sample // Pandoc 2.9 adds attributes on both header and div. We remove the former (to // be compatible with the behavior of Pandoc < 2.8). document.addEventListener('DOMContentLoaded', function(e) { var hs = document.querySelectorAll(\"div.section[class*='level'] > :first-child\"); var i, h, a; for (i = 0; i < hs.length; i++) { h = hs[i]; if (!/^h[1-6]$/i.test(h.tagName)) continue; // it should be a header h1-h6 a = h.attributes; while (a.length > 0) h.removeAttribute(a[0].name); } }); /*! jQuery v3.6.0 | (c) OpenJS Foundation and other contributors | jquery.org/license */ !function(e,t){\"use strict\";\"object\"==typeof module&&\"object\"==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(\"jQuery requires a window with a document\");return t(e)}:t(e)}(\"undefined\"!=typeof window?window:this,function(C,e){\"use strict\";var t=[],r=Object.getPrototypeOf,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},u=t.push,i=t.indexOf,n={},o=n.toString,v=n.hasOwnProperty,a=v.toString,l=a.call(Object),y={},m=function(e){return\"function\"==typeof e&&\"number\"!=typeof e.nodeType&&\"function\"!=typeof e.item},x=function(e){return null!=e&&e===e.window},E=C.document,c={type:!0,src:!0,nonce:!0,noModule:!0};function b(e,t,n){var r,i,o=(n=n||E).createElement(\"script\");if(o.text=e,t)for(r in c)(i=t[r]||t.getAttribute&&t.getAttribute(r))&&o.setAttribute(r,i);n.head.appendChild(o).parentNode.removeChild(o)}function w(e){return null==e?e+\"\":\"object\"==typeof e||\"function\"==typeof e?n[o.call(e)]||\"object\":typeof e}var f=\"3.6.0\",S=function(e,t){return new S.fn.init(e,t)};function p(e){var t=!!e&&\"length\"in e&&e.length,n=w(e);return!m(e)&&!x(e)&&(\"array\"===n||0===t||\"number\"==typeof t&&0"},{"title":"","date":"2022-10-05T05:40:07.195Z","updated":"2022-10-05T05:40:07.195Z","comments":true,"path":"images/R/R_basic_stat.html","permalink":"http://gonekng.github.io/images/R/R_basic_stat.html","excerpt":"","text":"R_basic_statistics // Pandoc 2.9 adds attributes on both header and div. We remove the former (to // be compatible with the behavior of Pandoc < 2.8). document.addEventListener('DOMContentLoaded', function(e) { var hs = document.querySelectorAll(\"div.section[class*='level'] > :first-child\"); var i, h, a; for (i = 0; i < hs.length; i++) { h = hs[i]; if (!/^h[1-6]$/i.test(h.tagName)) continue; // it should be a header h1-h6 a = h.attributes; while (a.length > 0) h.removeAttribute(a[0].name); } }); /*! jQuery v3.6.0 | (c) OpenJS Foundation and other contributors | jquery.org/license */ !function(e,t){\"use strict\";\"object\"==typeof module&&\"object\"==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error(\"jQuery requires a window with a document\");return t(e)}:t(e)}(\"undefined\"!=typeof window?window:this,function(C,e){\"use strict\";var t=[],r=Object.getPrototypeOf,s=t.slice,g=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},u=t.push,i=t.indexOf,n={},o=n.toString,v=n.hasOwnProperty,a=v.toString,l=a.call(Object),y={},m=function(e){return\"function\"==typeof e&&\"number\"!=typeof e.nodeType&&\"function\"!=typeof e.item},x=function(e){return null!=e&&e===e.window},E=C.document,c={type:!0,src:!0,nonce:!0,noModule:!0};function b(e,t,n){var r,i,o=(n=n||E).createElement(\"script\");if(o.text=e,t)for(r in c)(i=t[r]||t.getAttribute&&t.getAttribute(r))&&o.setAttribute(r,i);n.head.appendChild(o).parentNode.removeChild(o)}function w(e){return null==e?e+\"\":\"object\"==typeof e||\"function\"==typeof e?n[o.call(e)]||\"object\":typeof e}var f=\"3.6.0\",S=function(e,t){return new S.fn.init(e,t)};function p(e){var t=!!e&&\"length\"in e&&e.length,n=w(e);return!m(e)&&!x(e)&&(\"array\"===n||0===t||\"number\"==typeof t&&0"}],"posts":[{"title":"Django ì›¹ê°œë°œ íŠœí† ë¦¬ì–¼ (2)","slug":"Python/Django/Django ì›¹ê°œë°œ íŠœí† ë¦¬ì–¼ (2)","date":"2024-02-16T14:23:08.000Z","updated":"2024-02-16T14:46:03.102Z","comments":true,"path":"2024/02/16/Python/Django/Django ì›¹ê°œë°œ íŠœí† ë¦¬ì–¼ (2)/","link":"","permalink":"http://gonekng.github.io/2024/02/16/Python/Django/Django%20%EC%9B%B9%EA%B0%9C%EB%B0%9C%20%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC%20(2)/","excerpt":"","text":"Model ìƒì„± polls&#x2F;model.py ì‘ì„± 12345678910from django.db import modelsclass Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField(&#x27;date published&#x27;)class Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) Question : ì§ˆë¬¸ë‚´ìš©, ë°œí–‰ì¼ì ëª¨ë¸ Choice : ì§ˆë¬¸ë‚´ìš©, ì„ íƒë‚´ìš©, íˆ¬í‘œë²ˆí˜¸ ëª¨ë¸ Questionê³¼ ChoiceëŠ” ì™¸ë˜í‚¤ë¡œ ì—°ê²°ë˜ë©°, Questionì´ ì‚­ì œë˜ë©´ Choiceë„ í•¨ê»˜ ì‚­ì œë˜ë„ë¡ ì„¤ì • CharField : ë¬¸ìì—´ ë°ì´í„° í•„ë“œ DateTimeField : ë‚ ì§œ ë° ì‹œê°„ ë°ì´í„° í•„ë“œ IntegerField : ì •ìˆ˜í˜• ìˆ«ì ë°ì´í„° í•„ë“œ Model í™œì„±í™” í”„ë¡œì íŠ¸ì— Applicationì„ ë„£ì„ ë•Œ, url ì—°ê²° ì™¸ì—ë„ Applicationì˜ ëª¨ë¸ì„ í”„ë¡œì íŠ¸ ëª¨ë¸ ìŠ¤í‚¤ë§ˆì— ì—°ê²°í•´ì•¼ í•˜ëŠ” ì‘ì—… í•„ìš” mysite&#x2F;settings.pyì— ìˆëŠ” INSTALLED_APPS ë¦¬ìŠ¤íŠ¸ì— íˆ¬í‘œ Application ë“±ë¡ íˆ¬í‘œ Applicationì˜ í´ë˜ìŠ¤ ì´ë¦„ì€ polls&#x2F;apps.pyì—ì„œ í™•ì¸ê°€ëŠ¥ â†’ PollsConfig Migration : ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ ëª¨ë¸ì— Application ëª¨ë¸ì„ ì´ì‹ì‹œí‚¤ëŠ” ê³¼ì • makemigrations : python manage.py makemigrations polls ì…ë ¥ polls í´ë” ì•ˆì— migrations í´ë”ì™€ 0001_initial.pyê°€ ìƒì„±ë¨ migrate : python manage.py migrate ì…ë ¥ ### makemigrationsì™€ migrateì˜ ì°¨ì´ migrationì€ sqlë¡œ ì§„í–‰ë¨ â†’ 0001_initial.pyì™€ ê°™ì´ íŒŒì´ì¬ìœ¼ë¡œ í‘œí˜„í•œ ë‹¤ìŒ(makemigrations), ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì‹œ sqlë¡œ ë³€í™˜í•˜ì—¬ í”„ë¡œì íŠ¸ì— ë°˜ì˜í•¨(migrate) makemigrations : applicationì˜ ëª¨ë¸ì— ëŒ€í•œ ë³€í™”ë¥¼ ê¸°ë¡ migrate : makemigrationsì˜ ë³€í™” ê¸°ë¡ì„ ë³´ê³  ì‹¤ì œë¡œ í”„ë¡œì íŠ¸ ëª¨ë¸ ìŠ¤í‚¤ë§ˆì— applicationì˜ ëª¨ë¸ì— ëŒ€í•œ ë³€í™”ë¥¼ ë°˜ì˜ ì´í›„ ëª¨ë¸ë§ì„ ìˆ˜ì •í•˜ê³  migration ì‘ì—…ì„ ì‹¤ì‹œí•˜ë©´ 0002, 0003â€¦ ë“±ì˜ íŒŒì´ì¬ íŒŒì¼ì´ ìŒ“ì´ê²Œ ë¨ ì‹¤ì œ ì´í–‰ë˜ëŠ” sql ì¿¼ë¦¬ í™•ì¸ : python manage.py sqlmigrate polls ë³€ê²½ê¸°ë¡ë²ˆí˜¸ Reference django Documentation : https://docs.djangoproject.com/en/3.2/intro/tutorial01/ ì°¸ê³  ë¸”ë¡œê·¸ : https://lucky516.tistory.com/54","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"django","slug":"python/django","permalink":"http://gonekng.github.io/categories/python/django/"}],"tags":[{"name":"development","slug":"development","permalink":"http://gonekng.github.io/tags/development/"},{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"django","slug":"django","permalink":"http://gonekng.github.io/tags/django/"}],"author":"Jiwon Kang"},{"title":"Django ì›¹ê°œë°œ íŠœí† ë¦¬ì–¼ (1)","slug":"Python/Django/Django ì›¹ê°œë°œ íŠœí† ë¦¬ì–¼ (1)","date":"2024-02-16T13:59:22.000Z","updated":"2024-02-16T14:17:16.074Z","comments":true,"path":"2024/02/16/Python/Django/Django ì›¹ê°œë°œ íŠœí† ë¦¬ì–¼ (1)/","link":"","permalink":"http://gonekng.github.io/2024/02/16/Python/Django/Django%20%EC%9B%B9%EA%B0%9C%EB%B0%9C%20%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC%20(1)/","excerpt":"","text":"Djangoë€? íŒŒì´ì¬ìœ¼ë¡œ ì‘ì„±ëœ ë¬´ë£Œ ì˜¤í”ˆ ì†ŒìŠ¤ ì›¹ í”„ë ˆì„ì›Œí¬ ì›¹ ê°œë°œì„ ë³´ë‹¤ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìœ¼ë©°, ë³´ì•ˆ, í™•ì¥ì„±, ë¹ ë¥¸ ê°œë°œì„ ìœ„í•œ ë‹¤ì–‘í•œ ê¸°ëŠ¥ ì œê³µ Model-View-Template (MVT) ì•„í‚¤í…ì²˜ ê¸°ë°˜ìœ¼ë¡œ ì´ë£¨ì–´ì§ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°(Model), ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤(Template), ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§(View) â†’ ì¼ë°˜ì ì¸ MVC íŒ¨í„´ê³¼ ìš©ì–´ì˜ ì°¨ì´ê°€ ìˆìœ¼ë‚˜ ì›ë¦¬ëŠ” ë™ì¼í•¨ Django ì„¤ì¹˜ ë° ì„œë²„ êµ¬ë™ python ì¸í„°í”„ë¦¬í„°ì—ì„œ django ì„¤ì¹˜ pip install django ì…ë ¥ ì›í•˜ëŠ” ê²½ë¡œì— ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ìƒì„± django-admin startproject mysite ì…ë ¥ ê°œë°œ ì„œë²„ êµ¬ë™ cd mysite &gt; python manage.py makemigrations &gt; python manage.py migrate &gt; python manage.py runserver ì´í›„ http://127.0.0.1:8000/ì— ì ‘ì†í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì´ ëœ¬ë‹¤. íˆ¬í‘œ Application ê°œë°œ DjangoëŠ” Application ë‹¨ìœ„ë¡œ ì›¹í˜ì´ì§€ë¥¼ ê°œë°œí•˜ë„ë¡ ë˜ì–´ ìˆìœ¼ë©°, Applicationì€ í”„ë¡œì íŠ¸ í´ë”ì— ë„£ì—ˆë‹¤ ëºë‹¤ í•  ìˆ˜ ìˆìŒ ìƒˆë¡œìš´ application ìƒì„± python manage.py startapp polls ì…ë ¥ polls í´ë” ì•ˆì— ìƒì„±ëœ views.py ì½”ë“œ ì‘ì„± 12345from django.shortcuts import renderfrom django.http import HttpResponsedef index(request): return HttpResponse(&quot;Hello, World. You&#x27;re at the polls index.&quot;) index() : http ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ response ë©”ì‹œì§€ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ polls í´ë” ì•ˆì— urls.py ìƒì„± 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path(&#x27;&#x27;, views.index, name=&#x27;index&#x27;),] mysite í´ë” ì•ˆì— ìˆëŠ” urls.py ì½”ë“œ ì‘ì„± í”„ë¡œì íŠ¸ì— applicationì„ ë„£ê³  ë¹¼ëŠ” ì‘ì—…ì€ url ì—°ê²°ë¡œ ê°€ëŠ¥í•¨ 1234567from django.contrib import adminfrom django.urls import include, pathurlpatterns = [ path(&#x27;polls/&#x27;, include(&#x27;polls.urls&#x27;)), path(&#x27;admin/&#x27;, admin.site.urls),] http://127.0.0.1:8000/pollsì— ì ‘ì†í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ ì¶œë ¥ Reference django Documentation : https://docs.djangoproject.com/en/3.2/intro/tutorial01/ ì°¸ê³  ë¸”ë¡œê·¸ : https://lucky516.tistory.com/52, https://lucky516.tistory.com/53","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"django","slug":"python/django","permalink":"http://gonekng.github.io/categories/python/django/"}],"tags":[{"name":"development","slug":"development","permalink":"http://gonekng.github.io/tags/development/"},{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"django","slug":"django","permalink":"http://gonekng.github.io/tags/django/"}],"author":"Jiwon Kang"},{"title":"Pandas EX1 : split()ì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ìƒì„±","slug":"Python/Pandas/pandas_exercise1","date":"2024-02-13T13:51:00.000Z","updated":"2024-02-13T14:14:42.455Z","comments":true,"path":"2024/02/13/Python/Pandas/pandas_exercise1/","link":"","permalink":"http://gonekng.github.io/2024/02/13/Python/Pandas/pandas_exercise1/","excerpt":"","text":"ì—°ë„ë³„ ì „êµ­ìë©´ë™_ì¸êµ¬í†µê³„ ë°ì´í„°ë¥¼ Pandasë¥¼ í™œìš©í•˜ì—¬ í†µí•©ì •ë¦¬í•˜ëŠ” ì½”ë“œ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì— split() í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì»¬ëŸ¼ì„ ìƒì„±í•¨ 0 :: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸12345import osimport numpy as npimport pandas as pdimport warningswarnings.filterwarnings(&quot;ignore&quot;) 1 :: íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°123456file_list = [file for file in os.listdir(&quot;ì „êµ­ìë©´ë™_ì¸êµ¬í†µê³„&quot;) if file.endswith(&#x27;csv&#x27;)]for i, file in enumerate(file_list): df = pd.read_csv(&quot;ì „êµ­ìë©´ë™_ì¸êµ¬í†µê³„&quot; + file, encoding=&#x27;cp949&#x27;) df = df.iloc[:,[0,1,5,9,13,17,21,25,29,33,37,41,45]] df[&#x27;í–‰ì •êµ¬ì—­&#x27;] = df[&#x27;í–‰ì •êµ¬ì—­&#x27;].str[:-12].apply(lambda x: x.strip()) df.columns = [&#x27;í–‰ì •êµ¬ì—­&#x27;, &#x27;1ì›”&#x27;,&#x27;2ì›”&#x27;,&#x27;3ì›”&#x27;,&#x27;4ì›”&#x27;,&#x27;5ì›”&#x27;,&#x27;6ì›”&#x27;,&#x27;7ì›”&#x27;,&#x27;8ì›”&#x27;,&#x27;9ì›”&#x27;,&#x27;10ì›”&#x27;,&#x27;11ì›”&#x27;,&#x27;12ì›”&#x27;] â€˜ì „êµ­ìë©´ë™_ì¸êµ¬í†µê³„â€™ í´ë” í•˜ì˜ CSV íŒŒì¼ì„ ì°¨ë¡€ëŒ€ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ì½”ë“œ ì¸êµ¬ìˆ˜_ì „êµ­_2010.csv 2 :: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ SPLIT1234567df[&#x27;í† í°_ê°œìˆ˜&#x27;] = df[&#x27;í–‰ì •êµ¬ì—­&#x27;].apply(lambda x: len(str(x).split()))for tokens in range(1, df[&#x27;í† í°_ê°œìˆ˜&#x27;].max() + 1): df.loc[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == tokens, [f&#x27;í† í°_&#123;i+1&#125;&#x27; for i in range(tokens)]] = df.loc[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == tokens, &#x27;í–‰ì •êµ¬ì—­&#x27;].str.split().tolist()df1 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 1]df2 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 2]df3 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 3]df4 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 4] í–‰ì •êµ¬ì—­ ì»¬ëŸ¼ ê°’ì´ ë‹¨ì¼ê°’ìœ¼ë¡œ ë˜ì–´ìˆìŒ (ex. ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¼ì²­ë™) ë”°ë¼ì„œ split() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„, ì‹œêµ°êµ¬, í–‰ì •ë™ ì»¬ëŸ¼ì„ êµ¬ë¶„í•¨ â†’ í…ìŠ¤íŠ¸ ë¶„í• ì˜ ê²°ê³¼ í† í°ì€ 1~4ê°œë¡œ ë‚˜íƒ€ë‚˜ë©°, ê° ì¼€ì´ìŠ¤ì˜ íŠ¹ì§•ì„ ë°ì´í„°ë¥¼ í†µí•´ í™•ì¸í•˜ì˜€ìŒ 123df1[&#x27;ì‹œë„&#x27;] = df1[&#x27;í† í°_1&#x27;]df1[&#x27;ì‹œêµ°êµ¬&#x27;] = &#x27;ì „ì²´&#x27;df1[&#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; í† í°ì´ 1ê°œì¸ ê²½ìš° ì‹œë„ â†’ ì‹œë„ ì „ì²´ ì „ì²´ ex. ì„œìš¸íŠ¹ë³„ì‹œ â†’ ì„œìš¸íŠ¹ë³„ì‹œ ì „ì²´ ì „ì²´ 1234567df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œë„&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_1&#x27;]df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;] = df2.loc[df2[&#x27;í† í°_2&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_2&#x27;]df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27;df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œë„&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_1&#x27;]df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_1&#x27;]df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í–‰ì •ë™&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_2&#x27;] í† í°ì´ 2ê°œì¸ ê²½ìš° ì‹œë„ ì‹œêµ°êµ¬ â†’ ì‹œë„ ì‹œêµ°êµ¬ ì „ì²´ ex. ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ â†’ ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì „ì²´ ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ í–‰ì •ë™ â†’ ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ í–‰ì •ë™ ex. ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ í•œì†”ë™ â†’ ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ í•œì†”ë™ 1234567df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;]df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_2&#x27;]df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;]df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;]df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;]df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; í† í°ì´ 3ê°œì¸ ê²½ìš° ì‹œë„ ì‹œêµ°êµ¬ í–‰ì •ë™ â†’ ì‹œë„ ì‹œêµ°êµ¬ í–‰ì •ë™ ex. ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¼ì²­ë™ â†’ ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¼ì²­ë™ ì‹œë„ ì‹œë„ ì‹œêµ°êµ¬ â†’ ì‹œë„ ì‹œêµ°êµ¬ ì „ì²´ ex. ì„œìš¸íŠ¹ë³„ì‹œ ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ â†’ ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì „ì²´ 1234567df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;]df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_2&#x27;] + &quot; &quot; + df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;]df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_4&#x27;]df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;]df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;] + &quot; &quot; + df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_4&#x27;]df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; í† í°ì´ 4ê°œì¸ ê²½ìš° ì‹œë„ ì‹œêµ°êµ¬1 ì‹œêµ°êµ¬2 í–‰ì •ë™ â†’ ì‹œë„ ì‹œêµ°êµ¬1+2 í–‰ì •ë™ ex. ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ ì£½ì „ë™ â†’ ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ ì£½ì „ë™ ì‹œë„ ì‹œë„ ì‹œêµ°êµ¬1 ì‹œêµ°êµ¬2 â†’ ì‹œë„ ì‹œêµ°êµ¬1+2 ì „ì²´ ex. ê²½ê¸°ë„ ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ â†’ ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ ì „ì²´ 3 :: í…Œì´ë¸” ì·¨í•© ë° ê°€ê³µ12345678df = pd.concat([df1,df2,df3,df4], sort=True)df = df[[&#x27;ì‹œë„&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;, &#x27;í–‰ì •ë™&#x27;, &#x27;1ì›”&#x27;,&#x27;2ì›”&#x27;,&#x27;3ì›”&#x27;,&#x27;4ì›”&#x27;,&#x27;5ì›”&#x27;,&#x27;6ì›”&#x27;,&#x27;7ì›”&#x27;,&#x27;8ì›”&#x27;,&#x27;9ì›”&#x27;,&#x27;10ì›”&#x27;,&#x27;11ì›”&#x27;,&#x27;12ì›”&#x27;]]df[&#x27;ì—°ë„&#x27;] = file[-8:-4]df = pd.melt(df, id_vars=[&#x27;ì‹œë„&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;, &#x27;í–‰ì •ë™&#x27;, &#x27;ì—°ë„&#x27;], var_name=&#x27;ì›”&#x27;, value_name=&#x27;ì¸êµ¬ìˆ˜&#x27;)df[&#x27;ì›”&#x27;] = df[&#x27;ì›”&#x27;].str[:-1]df.drop_duplicates(inplace=True)df[&#x27;ì¸êµ¬ìˆ˜&#x27;] = pd.to_numeric(df[&#x27;ì¸êµ¬ìˆ˜&#x27;].str.replace(&#x27;,&#x27;, &#x27;&#x27;), errors=&#x27;coerce&#x27;)df = df[df[&#x27;ì¸êµ¬ìˆ˜&#x27;] &gt; 0] concat() í•¨ìˆ˜ë¡œ ê°ê°ì˜ ë°ì´í„°í”„ë ˆì„ì„ í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•¨ 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ì˜ ë°ì´í„°ê°€ ê° ì»¬ëŸ¼ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ìˆì–´, melt() í•¨ìˆ˜ë¡œ ê°ê°ì˜ í–‰ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë°ì´í„° í˜•íƒœë¥¼ ë³€í™˜í•¨ 4 :: CSV íŒŒì¼ í†µí•©ì €ì¥1234if i==0: df.to_csv(&quot;ì¸êµ¬ìˆ˜_ì „ì²´ë°ì´í„°.csv&quot;, mode=&#x27;w&#x27;, index=False, encoding=&#x27;cp949&#x27;)else: df.to_csv(&quot;ì¸êµ¬ìˆ˜_ì „ì²´ë°ì´í„°.csv&quot;, mode=&#x27;a&#x27;, index=False, header=False, encoding=&#x27;cp949&#x27;) forë¬¸ì˜ ì²«ë²ˆì§¸ ë£¨í”„ì—ì„œëŠ” to_csv() í•¨ìˆ˜ì˜ ë®ì–´ì“°ê¸°(write) ëª¨ë“œë¥¼, ì´í›„ì˜ ë£¨í”„ì—ì„œëŠ” ì´ì–´ì“°ê¸°(append) ëª¨ë“œë¥¼ ì ìš©í•¨ ì „ì²´ ì½”ë“œ123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import osimport numpy as npimport pandas as pdimport warningswarnings.filterwarnings(&quot;ignore&quot;)file_list = [file for file in os.listdir(&quot;ì „êµ­ìë©´ë™_ì¸êµ¬í†µê³„&quot;) if file.endswith(&#x27;csv&#x27;)]for i, file in enumerate(file_list): # CSV íŒŒì¼ ì„¸íŒ… df = pd.read_csv(&quot;ì „êµ­ìë©´ë™_ì¸êµ¬í†µê³„&quot; + file, encoding=&#x27;cp949&#x27;) df = df.iloc[:,[0,1,5,9,13,17,21,25,29,33,37,41,45]] df[&#x27;í–‰ì •êµ¬ì—­&#x27;] = df[&#x27;í–‰ì •êµ¬ì—­&#x27;].str[:-12].apply(lambda x: x.strip()) df.columns = [&#x27;í–‰ì •êµ¬ì—­&#x27;, &#x27;1ì›”&#x27;,&#x27;2ì›”&#x27;,&#x27;3ì›”&#x27;,&#x27;4ì›”&#x27;,&#x27;5ì›”&#x27;,&#x27;6ì›”&#x27;,&#x27;7ì›”&#x27;,&#x27;8ì›”&#x27;,&#x27;9ì›”&#x27;,&#x27;10ì›”&#x27;,&#x27;11ì›”&#x27;,&#x27;12ì›”&#x27;] # -- í–‰ì •êµ¬ì—­ ì»¬ëŸ¼ ê°’ì´ ë‹¨ì¼ê°’ìœ¼ë¡œ ë˜ì–´ìˆìŒ (ex. ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¼ì²­ë™) # -- ë”°ë¼ì„œ split í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„, ì‹œêµ°êµ¬, í–‰ì •ë™ ì»¬ëŸ¼ì„ êµ¬ë¶„í•¨ # í† í°ê°œìˆ˜ 1~4 df[&#x27;í† í°_ê°œìˆ˜&#x27;] = df[&#x27;í–‰ì •êµ¬ì—­&#x27;].apply(lambda x: len(str(x).split())) for tokens in range(1, df[&#x27;í† í°_ê°œìˆ˜&#x27;].max() + 1): df.loc[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == tokens, [f&#x27;í† í°_&#123;i+1&#125;&#x27; for i in range(tokens)]] = df.loc[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == tokens, &#x27;í–‰ì •êµ¬ì—­&#x27;].str.split().tolist() df1 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 1] df2 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 2] df3 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 3] df4 = df[df[&#x27;í† í°_ê°œìˆ˜&#x27;] == 4] # --- í† í°ì´ 1ê°œì¸ ê²½ìš° --- # ì‹œë„ -&gt; ì‹œë„ / ì „ì²´ / ì „ì²´ # ex. ì„œìš¸íŠ¹ë³„ì‹œ -&gt; ì„œìš¸íŠ¹ë³„ì‹œ / ì „ì²´ / ì „ì²´ df1[&#x27;ì‹œë„&#x27;] = df1[&#x27;í† í°_1&#x27;] df1[&#x27;ì‹œêµ°êµ¬&#x27;] = &#x27;ì „ì²´&#x27; df1[&#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; # --- í† í°ì´ 2ê°œì¸ ê²½ìš° --- # ì‹œë„ ì‹œêµ°êµ¬ -&gt; ì‹œë„ / ì‹œêµ°êµ¬ / ì „ì²´ # ex. ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ -&gt; ì„œìš¸íŠ¹ë³„ì‹œ / ì¢…ë¡œêµ¬ / ì „ì²´ df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œë„&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_1&#x27;] df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;] = df2.loc[df2[&#x27;í† í°_2&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_2&#x27;] df2.loc[df2[&#x27;í† í°_1&#x27;] != &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; # ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ í–‰ì •ë™ -&gt; ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ / ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ / í–‰ì •ë™ # ex. ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ í•œì†”ë™ -&gt; ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ / ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ / í•œì†”ë™ df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œë„&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_1&#x27;] df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_1&#x27;] df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í–‰ì •ë™&#x27;] = df2.loc[df2[&#x27;í† í°_1&#x27;] == &#x27;ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ&#x27;, &#x27;í† í°_2&#x27;] # --- í† í°ì´ 3ê°œì¸ ê²½ìš° --- # ì‹œë„ ì‹œêµ°êµ¬ í–‰ì •ë™ -&gt; ì‹œë„ / ì‹œêµ°êµ¬ / í–‰ì •ë™ # ex. ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì‚¼ì²­ë™ -&gt; ì„œìš¸íŠ¹ë³„ì‹œ / ì¢…ë¡œêµ¬ / ì‚¼ì²­ë™ df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;] df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_2&#x27;] df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] != df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;] # ì‹œë„ ì‹œë„ ì‹œêµ°êµ¬ -&gt; ì‹œë„ / ì‹œêµ°êµ¬ / ì „ì²´ # ex. ì„œìš¸íŠ¹ë³„ì‹œ ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ -&gt; ì„œìš¸íŠ¹ë³„ì‹œ / ì¢…ë¡œêµ¬ / ì „ì²´ df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;] df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;] df3.loc[df3[&#x27;í† í°_1&#x27;] == df3[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; # --- í† í°ì´ 4ê°œì¸ ê²½ìš° --- # ì‹œë„ ì‹œêµ°êµ¬1 ì‹œêµ°êµ¬2 í–‰ì •ë™ -&gt; ì‹œë„ / ì‹œêµ°êµ¬1+2 / í–‰ì •ë™ # ex. ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ ì£½ì „ë™ -&gt; ê²½ê¸°ë„ / ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ / ì£½ì „ë™ df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;] df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_2&#x27;] + &quot; &quot; + df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;] df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] != df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_4&#x27;] # ì‹œë„ ì‹œë„ ì‹œêµ°êµ¬1 ì‹œêµ°êµ¬2 -&gt; ì‹œë„ / ì‹œêµ°êµ¬1+2 / ì „ì²´ # ex. ê²½ê¸°ë„ ê²½ê¸°ë„ ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ -&gt; ê²½ê¸°ë„ / ìš©ì¸ì‹œ ìˆ˜ì§€êµ¬ / ì „ì²´ df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œë„&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_1&#x27;] df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;ì‹œêµ°êµ¬&#x27;] = df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_3&#x27;] + &quot; &quot; + df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í† í°_4&#x27;] df4.loc[df4[&#x27;í† í°_1&#x27;] == df4[&#x27;í† í°_2&#x27;], &#x27;í–‰ì •ë™&#x27;] = &#x27;ì „ì²´&#x27; # í…Œì´ë¸” ì·¨í•© ë° ê°€ê³µ df = pd.concat([df1,df2,df3,df4], sort=True) df = df[[&#x27;ì‹œë„&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;, &#x27;í–‰ì •ë™&#x27;, &#x27;1ì›”&#x27;,&#x27;2ì›”&#x27;,&#x27;3ì›”&#x27;,&#x27;4ì›”&#x27;,&#x27;5ì›”&#x27;,&#x27;6ì›”&#x27;,&#x27;7ì›”&#x27;,&#x27;8ì›”&#x27;,&#x27;9ì›”&#x27;,&#x27;10ì›”&#x27;,&#x27;11ì›”&#x27;,&#x27;12ì›”&#x27;]] df[&#x27;ì—°ë„&#x27;] = file[-8:-4] df = pd.melt(df, id_vars=[&#x27;ì‹œë„&#x27;, &#x27;ì‹œêµ°êµ¬&#x27;, &#x27;í–‰ì •ë™&#x27;, &#x27;ì—°ë„&#x27;], var_name=&#x27;ì›”&#x27;, value_name=&#x27;ì¸êµ¬ìˆ˜&#x27;) df[&#x27;ì›”&#x27;] = df[&#x27;ì›”&#x27;].str[:-1] df.drop_duplicates(inplace=True) df[&#x27;ì¸êµ¬ìˆ˜&#x27;] = pd.to_numeric(df[&#x27;ì¸êµ¬ìˆ˜&#x27;].str.replace(&#x27;,&#x27;, &#x27;&#x27;), errors=&#x27;coerce&#x27;) df = df[df[&#x27;ì¸êµ¬ìˆ˜&#x27;] &gt; 0] # CSV íŒŒì¼ í†µí•©ì €ì¥ if i==0: df.to_csv(&quot;ì¸êµ¬ìˆ˜_ì „ì²´ë°ì´í„°.csv&quot;, mode=&#x27;w&#x27;, index=False, encoding=&#x27;cp949&#x27;) else: df.to_csv(&quot;ì¸êµ¬ìˆ˜_ì „ì²´ë°ì´í„°.csv&quot;, mode=&#x27;a&#x27;, index=False, header=False, encoding=&#x27;cp949&#x27;)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"pandas","slug":"python/pandas","permalink":"http://gonekng.github.io/categories/python/pandas/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"http://gonekng.github.io/tags/pandas/"}],"author":"Jiwon Kang"},{"title":"Streamlit & Sqlite3 ì—°ë™ ì˜ˆì œ","slug":"Python/Streamlit/streamlit_exersice2","date":"2024-02-08T02:17:52.000Z","updated":"2024-02-13T13:52:45.765Z","comments":true,"path":"2024/02/08/Python/Streamlit/streamlit_exersice2/","link":"","permalink":"http://gonekng.github.io/2024/02/08/Python/Streamlit/streamlit_exersice2/","excerpt":"","text":"Streamlit ê¸°ë°˜ ì›¹ ëŒ€ì‹œë³´ë“œë¥¼ Sqlite DBì™€ ì—°ë™í•˜ëŠ” ì‘ì—… Sqlite : ë³„ë„ì˜ í”„ë¡œê·¸ë¨ ì„¤ì¹˜ ì—†ì´ Python ì½”ë“œë¡œ ì†ì‰½ê²Œ DBë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŒ 0 :: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸123456import time, sys, osimport numpy as npimport pandas as pdimport sqlite3import streamlit as st 1 :: ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ì—°ë™123456789101112131415161718192021222324252627def create_connection(db_file): conn = None try: conn = sqlite3.connect(db_file) except Exception as e: st.write(e) return conndef create_database(): st.write(&quot;# PAGE1 : ë°ì´í„°ë² ì´ìŠ¤ ë§Œë“¤ê¸°&quot;) st.write(&quot;---&quot;) db_filename = st.text_input(&quot;ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.&quot;) create_db = st.button(&#x27;ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±&#x27;) if create_db: if db_filename.endswith(&#x27;.db&#x27;): if db_filename not in [file for file in os.listdir(os.getcwd())]: conn = create_connection(db_filename) st.success(&#x27;ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ.&#x27;) else: st.error(&#x27;ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&#x27;) else: st.error(&#x27;íŒŒì¼ì´ë¦„ì€ .dbë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&#x27;) sqlite3 ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ connect í•¨ìˆ˜ë¥¼ í†µí•´ db_fileì„ ì—°ë™ â€˜ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±â€™ ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ í…ìŠ¤íŠ¸ë¡œ ì…ë ¥ë°›ì€ ì´ë¦„ì˜ .db íŒŒì¼ì„ ìƒì„± íŒŒì¼ì´ë¦„ì€ .dbë¡œ ëë‚˜ì•¼ í•˜ë©°, ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë¦„ì¸ ê²½ìš° ì—ëŸ¬ ë°œìƒ 2 :: CSV íŒŒì¼ ì—…ë¡œë“œ ë° DB ì €ì¥123456789101112131415161718192021222324252627282930313233343536373839def upload_data(): st.write(&quot;# PAGE2 : íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°&quot;) st.write(&quot;---&quot;) sqlite_dbs = [file for file in os.listdir(&#x27;.&#x27;) if file.endswith(&#x27;.db&#x27;)] db_filename = st.selectbox(&#x27;ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.&#x27;, sqlite_dbs) if db_filename is not None: conn = create_connection(db_filename) cursor = conn.cursor() cursor.execute(&quot;SELECT name FROM sqlite_master WHERE type=&#x27;table&#x27;;&quot;) tables = cursor.fetchall() tables = [table[0] for table in tables] table_name = st.text_input(&#x27;í…Œì´ë¸” ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.&#x27;) if len(table_name) &gt; 0: if table_name not in tables: uploaded_file = st.file_uploader(&#x27;ì—…ë¡œë“œí•  íŒŒì¼ì„ ì²¨ë¶€í•˜ì„¸ìš”.&#x27;) if uploaded_file is not None: try: df = pd.read_csv(uploaded_file, encoding=&#x27;cp949&#x27;) st.write(&#x27;**Data loaded successfully. These are the first 3 rows.**&#x27;) st.dataframe(df.head(3), use_container_width=True) col1, col2 = st.columns([8,1]) is_apply = col2.button(&#x27;Upload&#x27;, use_container_width=True) if is_apply: pg_bar = col1.progress(0, text=&quot;â©Progress&quot;) for percent_complete in range(100): time.sleep(0.01) pg_bar.progress(percent_complete + 1, text=&quot;Progress&quot;) df.to_sql(name=table_name, con=conn, if_exists=&#x27;replace&#x27;, index=False) time.sleep(0.1) st.success(&quot;ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.&quot;) except Exception as e: st.write(e) else: st.error(&quot;ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&quot;) else: st.error(&#x27;DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DB íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.&#x27;) í˜„ì¬ ê²½ë¡œì˜ .db íŒŒì¼ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê³ , CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¨ í›„ í…Œì´ë¸”ì— ì €ì¥ í…ìŠ¤íŠ¸ë¡œ ì…ë ¥ë°›ì€ í…Œì´ë¸” ì´ë¦„ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì—ëŸ¬ ë°œìƒ CSV íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¨ í›„ ì²« 3í–‰ ì¶œë ¥ ë‚´ìš©ì„ í™•ì¸í•œ í›„ ì—…ë¡œë“œí•˜ë„ë¡ ì„¤ì • ì—…ë¡œë“œ ë²„íŠ¼ í´ë¦­ ì‹œ ë°”ë¡œ í…Œì´ë¸”ì— ì €ì¥ì´ ë¨ â†’ Progress BarëŠ” ë³´ì—¬ì£¼ê¸°ìš© 3 :: SQL ì¿¼ë¦¬ë¡œ ë°ì´í„° ì¡°ì‘ ë° CSV íŒŒì¼ë¡œ ì €ì¥1234567891011121314151617181920212223242526272829303132def run_query(): st.write(&quot;# PAGE3 : SQL ì¿¼ë¦¬ë¡œ ë°ì´í„° ì¡°ì‘í•˜ê¸°&quot;) st.write(&quot;---&quot;) sqlite_dbs = [file for file in os.listdir(&#x27;.&#x27;) if file.endswith(&#x27;.db&#x27;)] db_filename = st.selectbox(&#x27;DB Filename&#x27;, sqlite_dbs) query = st.text_area(&#x27;SQL Query&#x27;, height=150) if db_filename is not None: if len(query) == 0: is_disabled = True else: is_disabled = False submitted = st.button(&#x27;Run Query&#x27;, disabled=is_disabled) if submitted: conn = create_connection(db_filename) query = conn.execute(query) cols = [column[0] for column in query.description] results_df= pd.DataFrame.from_records( data = query.fetchall(), columns = cols ) st.dataframe(results_df) if st.button(&#x27;Download&#x27;): convert_df(results_df) else: st.error(&#x27;DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DB íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.&#x27;)def convert_df(df): return df.to_csv(index=False).encode(&#x27;cp949&#x27;) í˜„ì¬ ê²½ë¡œì˜ .db íŒŒì¼ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ê³ , SQL ì¿¼ë¦¬ë¥¼ ì…ë ¥í•˜ì—¬ í•´ë‹¹ DBì˜ ë°ì´í„°ë¥¼ ì¡°ì‘(CRUD) SQL ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì•¼ Run Query ë²„íŠ¼ì´ í™œì„±í™”ë˜ë„ë¡ ì„¤ì • convert_df : ì¿¼ë¦¬ ì‹¤í–‰ í›„ì˜ ë°ì´í„° í…Œì´ë¸”ì„ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ 4 :: ê¸°ë³¸ í™”ë©´ êµ¬ì„± ë° ì‚¬ì´ë“œë°” ì„¤ì •123456789101112131415161718192021222324252627282930def main(): # Page Configuration st.set_page_config( page_title=&quot;Sqlite3 DB Connect with Streamlit&quot;, page_icon=&quot;âš’ï¸&quot;, layout=&quot;wide&quot;, initial_sidebar_state=&quot;auto&quot;, menu_items=&#123; &#x27;Get Help&#x27;: &#x27;mailto:donumm64@gmail.com&#x27;, &#x27;About&#x27;: &quot;*Made by gonekng*&quot; &#125; ) # ì‚¬ì´ë“œë°” ì„¤ì • st.sidebar.subheader(&quot;ğŸˆStreamlitìœ¼ë¡œ Sqlite3 DB ì—°ë™í•˜ê¸°&quot;) st.sidebar.write(&quot;---&quot;) page_names_to_funcs = &#123; &quot;Create Database&quot;: create_database, &quot;Upload Data&quot;: upload_data, &quot;Run Query&quot;: run_query, &#125; selected_page = st.sidebar.selectbox(&quot;Select a page&quot;, page_names_to_funcs.keys(), label_visibility=&#x27;collapsed&#x27;) page_names_to_funcs[selected_page]()if __name__ == &quot;__main__&quot;: main() st.set_page_config : ê¸°ë³¸ í˜ì´ì§€ ì„¤ì • page_names_to_funcs : ê° í˜ì´ì§€ë¥¼ êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜ ë§¤ì¹­ Reference Streamlit Documentation : https://docs.streamlit.io/ ì°¸ê³ ë¸”ë¡œê·¸ : https://blog.naver.com/v-world/222009887650 ì „ì²´ ì½”ë“œ123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144import time, sys, osimport numpy as npimport pandas as pdimport sqlite3import streamlit as st# DB ì—°ë™def create_connection(db_file): conn = None try: conn = sqlite3.connect(db_file) except Exception as e: st.write(e) return conn# DB ìƒì„±def create_database(): st.write(&quot;# PAGE1 : ë°ì´í„°ë² ì´ìŠ¤ ë§Œë“¤ê¸°&quot;) st.write(&quot;---&quot;) db_filename = st.text_input(&quot;ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.&quot;) create_db = st.button(&#x27;ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±&#x27;) if create_db: if db_filename.endswith(&#x27;.db&#x27;): if db_filename not in [file for file in os.listdir(os.getcwd())]: conn = create_connection(db_filename) st.success(&#x27;ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ.&#x27;) else: st.error(&#x27;ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&#x27;) else: st.error(&#x27;íŒŒì¼ì´ë¦„ì€ .dbë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&#x27;)# ë°ì´í„° ì—…ë¡œë“œdef upload_data(): st.write(&quot;# PAGE2 : íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°&quot;) st.write(&quot;---&quot;) sqlite_dbs = [file for file in os.listdir(&#x27;.&#x27;) if file.endswith(&#x27;.db&#x27;)] db_filename = st.selectbox(&#x27;ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.&#x27;, sqlite_dbs) if db_filename is not None: conn = create_connection(db_filename) cursor = conn.cursor() cursor.execute(&quot;SELECT name FROM sqlite_master WHERE type=&#x27;table&#x27;;&quot;) tables = cursor.fetchall() tables = [table[0] for table in tables] table_name = st.text_input(&#x27;í…Œì´ë¸” ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.&#x27;) if len(table_name) &gt; 0: if table_name not in tables: uploaded_file = st.file_uploader(&#x27;ì—…ë¡œë“œí•  íŒŒì¼ì„ ì²¨ë¶€í•˜ì„¸ìš”.&#x27;) if uploaded_file is not None: try: df = pd.read_csv(uploaded_file, encoding=&#x27;cp949&#x27;) st.write(&#x27;**Data loaded successfully. These are the first 3 rows.**&#x27;) st.dataframe(df.head(3), use_container_width=True) col1, col2 = st.columns([8,1]) is_apply = col2.button(&#x27;Upload&#x27;, use_container_width=True) if is_apply: pg_bar = col1.progress(0, text=&quot;â©Progress&quot;) for percent_complete in range(100): time.sleep(0.01) pg_bar.progress(percent_complete + 1, text=&quot;Progress&quot;) df.to_sql(name=table_name, con=conn, if_exists=&#x27;replace&#x27;, index=False) time.sleep(0.1) st.success(&quot;ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.&quot;) except Exception as e: st.write(e) else: st.error(&quot;ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í…Œì´ë¸”ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&quot;) else: st.error(&#x27;DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DB íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.&#x27;)# ì¿¼ë¦¬ ì‹¤í–‰def run_query(): st.write(&quot;# PAGE3 : SQL ì¿¼ë¦¬ë¡œ ë°ì´í„° ì¡°ì‘í•˜ê¸°&quot;) st.write(&quot;---&quot;) sqlite_dbs = [file for file in os.listdir(&#x27;.&#x27;) if file.endswith(&#x27;.db&#x27;)] db_filename = st.selectbox(&#x27;DB Filename&#x27;, sqlite_dbs) query = st.text_area(&#x27;SQL Query&#x27;, height=150) if db_filename is not None: if len(query) == 0: is_disabled = True else: is_disabled = False submitted = st.button(&#x27;Run Query&#x27;, disabled=is_disabled) if submitted: conn = create_connection(db_filename) query = conn.execute(query) cols = [column[0] for column in query.description] results_df= pd.DataFrame.from_records( data = query.fetchall(), columns = cols ) st.dataframe(results_df) if st.button(&#x27;Download&#x27;): convert_df(results_df) else: st.error(&#x27;DB íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DB íŒŒì¼ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.&#x27;)def convert_df(df): return df.to_csv(index=False).encode(&#x27;cp949&#x27;)# --------------------- ë©”ì¸ í•¨ìˆ˜ --------------------- #def main(): # Page Configuration st.set_page_config( page_title=&quot;Sqlite3 DB Connect with Streamlit&quot;, page_icon=&quot;âš’ï¸&quot;, layout=&quot;wide&quot;, initial_sidebar_state=&quot;auto&quot;, menu_items=&#123; &#x27;Get Help&#x27;: &#x27;mailto:donumm64@gmail.com&#x27;, &#x27;About&#x27;: &quot;*Made by gonekng*&quot; &#125; ) # ì‚¬ì´ë“œë°” ì„¤ì • st.sidebar.subheader(&quot;ğŸˆStreamlitìœ¼ë¡œ Sqlite3 DB ì—°ë™í•˜ê¸°&quot;) st.sidebar.write(&quot;---&quot;) page_names_to_funcs = &#123; &quot;Create Database&quot;: create_database, &quot;Upload Data&quot;: upload_data, &quot;Run Query&quot;: run_query, &#125; selected_page = st.sidebar.selectbox(&quot;Select a page&quot;, page_names_to_funcs.keys(), label_visibility=&#x27;collapsed&#x27;) page_names_to_funcs[selected_page]()if __name__ == &quot;__main__&quot;: main()","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"streamlit","slug":"python/streamlit","permalink":"http://gonekng.github.io/categories/python/streamlit/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"http://gonekng.github.io/tags/pandas/"},{"name":"streamlit","slug":"streamlit","permalink":"http://gonekng.github.io/tags/streamlit/"},{"name":"sqlite","slug":"sqlite","permalink":"http://gonekng.github.io/tags/sqlite/"}],"author":"Jiwon Kang"},{"title":"Streamlitì„ ì´ìš©í•œ ì§€ë„ ì‹œê°í™” ì˜ˆì œ","slug":"Python/Streamlit/streamlit_exersice1","date":"2023-04-06T13:29:04.000Z","updated":"2023-04-06T14:10:37.222Z","comments":true,"path":"2023/04/06/Python/Streamlit/streamlit_exersice1/","link":"","permalink":"http://gonekng.github.io/2023/04/06/Python/Streamlit/streamlit_exersice1/","excerpt":"","text":"Streamlitì´ë€?Pythonìœ¼ë¡œ ì‘ì„±ëœ ë°ì´í„° ì‹œê°í™” ë° ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œìš© í”„ë ˆì„ì›Œí¬ ì›¹ ì–´í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆê³ , ë°ì´í„° ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì—°ë™í•˜ì—¬ ì§ê´€ì ì¸ ë¶„ì„ì´ ê°€ëŠ¥ ë‹¤ë¥¸ ì›¹ í”„ë ˆì„ì›Œí¬ì— ë¹„í•´ ê³ ê¸‰ ê¸°ëŠ¥ì´ë‚˜ ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“œëŠ” ë°ì—ëŠ” ë‹¤ì†Œ ì œí•œì  Streamlit ì˜ˆì œì´ë²ˆ ì˜ˆì œëŠ” ì§€ì¸ë“¤ê³¼ì˜ ì•½ì† ì¥ì†Œë¥¼ ì •í•˜ë˜ ì¤‘ Streamlitì„ ì´ìš©í•˜ì—¬ í™ëŒ€ì…êµ¬ì—­ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ì•Œì•„ë³´ê¸° ìœ„í•´ ë§Œë“  ê°„ë‹¨í•œ ì›¹ì• í”Œë¦¬ì¼€ì´ì…˜ì´ë‹¤. Folium íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ ì§€ë„ ìƒì— ê° ìœ„ì¹˜ë¥¼ í‘œì‹œí•˜ê³ , Streamlitì—ì„œ ì œê³µí•˜ëŠ” íƒ­ ê¸°ëŠ¥ì„ ì´ìš©í•˜ì—¬ ë°ì´í„°ì™€ ì§€ë„ë¥¼ í•¨ê»˜ ì œê³µí•œë‹¤. ì´ë•Œ Vworldì—ì„œ ì œê³µí•˜ëŠ” APIë¥¼ í†µí•´ ì§€ë„ì— ë°°ê²½ ë ˆì´ì–´ë¥¼ ì‚½ì…í•˜ì—¬ ë³´ê¸° ì‰½ê²Œ ì‹œê°í™”í•˜ì˜€ë‹¤. 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ Import123456import numpy as npimport pandas as pdimport streamlit as stfrom PIL import Imageimport foliumimport vworld_key numpy : ìˆ˜ì¹˜ ê³„ì‚°ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ pandas : ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ streamlit : íŒŒì´ì¬ ê¸°ë°˜ì˜ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ ë„êµ¬ PIL : ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ folium : ì§€ë„ ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ vworld_key : ì§€ë„ APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ API í‚¤ (ë¹„ê³µê°œ) 2. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •1st.set_page_config(page_title=&#x27;Where to meet&#x27;, page_icon=&#x27;ğŸŒ±&#x27;, layout=&quot;wide&quot;) streamlitì—ì„œ ì œê³µí•˜ëŠ” set_page_config() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ ì„¤ì • ê°€ëŠ¥ layout : í˜ì´ì§€ì˜ ë ˆì´ì•„ì›ƒ ì„¤ì • (wide, centered ë“±) theme : í˜ì´ì§€ì˜ í…Œë§ˆ ì„¤ì • (light, dark, colorblind ë“±) 3. ì‚¬ì´ë“œë°” ì»¤ìŠ¤í„°ë§ˆì´ì§•12345678910st.sidebar.image(Image.open(&#x27;streamlit_logo.png&#x27;))st.sidebar.write(&quot;---&quot;)rainbow = [&#x27;red&#x27;, &#x27;orange&#x27;, &#x27;yellow&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;, &#x27;navy&#x27;, &#x27;purple&#x27;]color = [&#x27;black&#x27;, &#x27;black&#x27;, &#x27;black&#x27;, &#x27;white&#x27;, &#x27;white&#x27;, &#x27;white&#x27;, &#x27;white&#x27;]text = &#x27;WELCOME&#x27;for r, c, t in zip(rainbow, color, text): st.sidebar.markdown(f&quot;&lt;h3 style=&#x27;color:&#123;c&#125;; background-color:&#123;r&#125;&#x27;&gt;__&#123;t&#125;:&lt;/h3&gt;&quot;, unsafe_allow_html=True)st.sidebar.write(&quot;---&quot;)st.sidebar.text(&quot;This is Jiwon!\\nNice to meet you!&quot;) st.sidebar í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì´ë“œë°”ë¥¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•  ìˆ˜ ìˆìŒ st.sidebar.image() í•¨ìˆ˜ë¡œ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥ Image ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ open í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ëœ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜´ st.sidebar.write() &#x2F; st.sidebar.markdown() &#x2F; st.sidebar.text() write í•¨ìˆ˜ì— â€œâ€”â€œ ì…ë ¥í•˜ì—¬ í™”ë©´ì— êµ¬ë¶„ì„  ì¶”ê°€ unsafe_allow_html : html íƒœê·¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í—ˆìš©í•˜ëŠ” ê¸°ëŠ¥ 4. ë©”ì¸ í™”ë©´ ì‘ì„±123st.header(&quot;A Letter From Peter&quot;)st.subheader(&#x27;:blue[&quot;Let me know where we will meet on Satuerday, with the dashboard made by streamlit.&quot;]&#x27;)st.write(&quot;---&quot;) st.header() &#x2F; st.subheader() í•¨ìˆ˜ë¡œ ì œëª© ë° ë¶€ì œëª©ì„ ì§€ì • 4-1. ë ˆì´ì•„ì›ƒ (ì»¬ëŸ¼ ë¶„í• )123456col1, col2 = st.columns([1,2])with col1: st.image(Image.open(&#x27;question.jpg&#x27;))with col2: st.subheader(&#x27;:blue[&quot;What about í™ëŒ€ì…êµ¬?&quot;]&#x27;) st.columns() : í™”ë©´ì„ ë¶„í• í•˜ê³ ì í•˜ëŠ” ì»¬ëŸ¼ ê°œìˆ˜ ë° í¬ê¸°ë§Œí¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì…ë ¥ with êµ¬ë¬¸ìœ¼ë¡œ ê° ì»¬ëŸ¼ì—ì„œ ì¶œë ¥í•˜ê³ ì í•˜ëŠ” ë‚´ìš© ì‘ì„± 4-2. ë°ì´í„° Load12345center = [37.5575,126.9245] # í™ëŒ€ì…êµ¬ì—­ ì¢Œí‘œ# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°df = pd.read_csv(&quot;place.csv&quot;, encoding=&#x27;utf-8&#x27;)df[&#x27;to_í™ëŒ€&#x27;] = np.round(np.sqrt(np.power((df[&#x27;Lat&#x27;]-center[0]),2) + np.power((df[&#x27;Lon&#x27;]-center[1]),2)),2) ë³¸ ì˜ˆì œì—ì„œëŠ” ê¸°ì¤€ì ìœ¼ë¡œ ì‚¬ìš©í•  ë°ì´í„°ë¡œ í™ëŒ€ì…êµ¬ì—­ì˜ ì¢Œí‘œë¥¼ ì‚¬ìš©í•¨ csv íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¨ í›„, ê° ì§€ì—­ì— ëŒ€í•˜ì—¬ í™ëŒ€ì…êµ¬ì™€ì˜ ê±°ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” to_í™ëŒ€ ë¼ëŠ” ìƒˆë¡œìš´ ì»¬ëŸ¼ ìƒì„± np.power() : ì²«ë²ˆì§¸ ì¸ìˆ˜ë¥¼ ë‘ë²ˆì§¸ ì¸ìˆ˜ë§Œí¼ ê±°ë“­ì œê³±í•˜ëŠ” í•¨ìˆ˜ np.sqrt() : ì–‘ì˜ ì œê³±ê·¼ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ np.round() : ì²«ë²ˆì§¸ ì¸ìˆ˜ë¥¼ ë‘ë²ˆì§¸ ì¸ìˆ˜ì˜ ìë¦¿ìˆ˜ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ëŠ” í•¨ìˆ˜ 4-3. íƒ­ ê¸°ëŠ¥ ì¶”ê°€1234567tab1, tab2 = st.tabs([&#x27;On Map&#x27;, &#x27;Raw Data&#x27;])with tab2: st.write(df) with tab1: st.write(&quot;---&quot;) st.tabs() : í™”ë©´ì— ì¶œë ¥í•˜ê³ ì í•˜ëŠ” íƒ­ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì…ë ¥ with êµ¬ë¬¸ìœ¼ë¡œ ê° íƒ­ì—ì„œ ì¶œë ¥í•˜ê³ ì í•˜ëŠ” ë‚´ìš© ì‘ì„± 5. ì§€ë„ ì‹œê°í™”5-1. ì§€ë„ ê°ì²´ ìƒì„±1m = folium.Map(location=center, zoom_start=11, min_zoom=9, max_zoom=12) folium ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Map() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ë„ ê°ì²´ë¥¼ ìƒì„± location : ì§€ë„ì˜ ì¤‘ì‹¬ì  ì¢Œí‘œ ì •ë³´ê°€ ë‹´ê¸´ ë³€ìˆ˜ë¥¼ ì „ë‹¬ zoom_start : ì´ˆê¸° í™•ëŒ€&#x2F;ì¶•ì†Œ ìˆ˜ì¤€ì„ ì§€ì •í•©ë‹ˆë‹¤. min_zoom &#x2F; max_zoom : ìµœì†Œ&#x2F;ìµœëŒ€ ì¤Œ ìˆ˜ì¤€ ì§€ì • 5-2. ë°°ê²½ ë ˆì´ì–´ ì‚½ì…(*vworld API)1234567tiles = f&quot;http://api.vworld.kr/req/wmts/1.0.0/&#123;vworld_key.key&#125;/Base/&#123;&#123;z&#125;&#125;/&#123;&#123;y&#125;&#125;/&#123;&#123;x&#125;&#125;.png&quot;folium.TileLayer( tiles=tiles, attr=&quot;Vworld&quot;, overlay=True, control=True).add_to(m) ì§€ë„ì˜ ë°°ê²½ ë ˆì´ì–´ëŠ” ê³µê°„ì •ë³´ ì˜¤í”ˆí”Œë«í¼ ì˜¤í”ˆAPI(https://www.vworld.kr/dev/v4api.do)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚½ì…í•˜ì˜€ìŒ &#123;&#123;z&#125;&#125;, &#123;&#123;y&#125;&#125;, &#123;&#123;x&#125;&#125;ëŠ” foliumì—ì„œ ë™ì ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ë³€ìˆ˜ë¡œ, tiles URLì— ì‚½ì…ë˜ì–´ í•´ë‹¹ ìœ„ì¹˜ì˜ íƒ€ì¼ì„ ìš”ì²­í•¨ folium.TileLayer() : ì§€ë„ ê°ì²´ì˜ ë°°ê²½ ë ˆì´ì–´ë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜ tiles : íƒ€ì¼ ì´ë¯¸ì§€ì˜ URL ë˜ëŠ” íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ ì œê³µí•˜ëŠ” Providerì˜ ì´ë¦„ì„ ì§€ì • attr : íƒ€ì¼ ì œê³µìì˜ ì†ì„± ì •ë³´ë¥¼ ì„¤ì • overlay : íƒ€ì¼ ë ˆì´ì–´ê°€ ì§€ë„ì˜ ì˜¤ë²„ë ˆì´ë¡œ í‘œì‹œë ì§€ ì—¬ë¶€ ì„¤ì • control : íƒ€ì¼ ë ˆì´ì–´ë¥¼ ì§€ë„ì˜ ì»¨íŠ¸ë¡¤ì— í‘œì‹œí• ì§€ ì—¬ë¶€ ì„¤ì • .add_to(m) : ì§€ë„ ê°ì²´ì— ì¶”ê°€í•˜ëŠ” ë©”ì†Œë“œ 5-3. ë§ˆì»¤ ë° ì§ì„  ì‚½ì…1234for idx, row in df.iterrows(): folium.Marker(location = [row[&#x27;Lat&#x27;],row[&#x27;Lon&#x27;]], tooltip=row[&#x27;Name&#x27;], icon=folium.Icon(color=&#x27;gray&#x27;)).add_to(m) folium.PolyLine(locations = [center, [row[&#x27;Lat&#x27;],row[&#x27;Lon&#x27;]]], tooltip=row[&#x27;to_í™ëŒ€&#x27;]).add_to(m) folium.Marker(location = center, tooltip=&#x27;í™ëŒ€ì…êµ¬ì—­&#x27;, icon=folium.Icon(color=&#x27;red&#x27;)).add_to(m) df.iterrows() : ë°ì´í„°í”„ë ˆì„ì˜ ê° í–‰ì„ ì´í„°ë ˆì´í„° ê°ì²´ë¡œ ë³€í™˜ folium.Marker() : ì§€ë„ ê°ì²´ì— ë§ˆì»¤ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ location : ë§ˆì»¤ë¥¼ ì¶”ê°€í•  ì¢Œí‘œ ì§€ì • tooltip : ë§ˆì»¤ ìœ„ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë ¸ì„ ë•Œ ì¶œë ¥í•  ê°’ ì§€ì • icon : ë§ˆì»¤ ì•„ì´ì½˜ ì„¤ì • â†’ folium.Icon() í•¨ìˆ˜ë¥¼ í†µí•´ ë§ˆì»¤ì˜ ìŠ¤íƒ€ì¼ ì„¤ì • folium.PolyLine() : ì§€ë„ ê°ì²´ì— ì§ì„ ì„ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ locations : ì§ì„ ì˜ ì–‘ ë ì¢Œí‘œ ì§€ì • tooltip : ì§ì„  ìœ„ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë ¸ì„ ë•Œ ì¶œë ¥í•  ê°’ ì§€ì • 5-4. ê²½ê³„ì„  ë§ì¶”ê¸°1m.fit_bounds(m.get_bounds()) m.get_bounds() : ì§€ë„ ê°ì²´ì— í¬í•¨ëœ ëª¨ë“  ë§ˆì»¤ì™€ ê²½ë¡œë“¤ì˜ ê²½ê³„ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜ m.fit_bounds() : ì¸ìë¡œ ë°›ì€ ê²½ê³„ê°’ì— ë§ê²Œ ì§€ë„ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì¡°ì • â†’ ì§€ë„ê°€ í˜„ì¬ í‘œì‹œë˜ëŠ” ëª¨ë“  ë°ì´í„°ê°€ ë³´ì¼ ìˆ˜ ìˆë„ë¡ ìë™ìœ¼ë¡œ ì§€ë„ì˜ ì¤‘ì‹¬ê³¼ í™•ëŒ€&#x2F;ì¶•ì†Œ ë ˆë²¨ì„ ì¡°ì •í•˜ëŠ” ì½”ë“œ 5-5. ì§€ë„ ì €ì¥ ë° ì¶œë ¥12m.save(&#x27;map.html&#x27;)st.components.v1.html(open(&quot;map.html&quot;, &quot;rb&quot;).read(), height=600) ì§€ë„ ê°ì²´ë¥¼ HTML íŒŒì¼ë¡œ ì €ì¥í•œ ë‹¤ìŒ, í•´ë‹¹ íŒŒì¼ì„ ë°”ì´íŠ¸ í˜•íƒœë¡œ ë¶ˆëŸ¬ì˜¨ í›„ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” ì½”ë“œ Result Reference Streamlit Documentation : https://docs.streamlit.io/ OpenAPI ë°œê¸‰ ë°©ë²• : https://blog.naver.com/v-world/222009887650 ì›¹ì•± ë°°í¬ ë°©ë²• : https://dschloe.github.io/python/2022/11/streamlit_deploy&#x2F; ì „ì²´ ì½”ë“œ12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import numpy as npimport pandas as pdimport streamlit as stfrom PIL import Imageimport foliumimport vworld_keydef main(): # í˜ì´ì§€ ì„¤ì • st.set_page_config(page_title=&#x27;Where to meet&#x27;, layout=&quot;wide&quot;) # ì‚¬ì´ë“œë°” st.sidebar.image(Image.open(&#x27;streamlit_logo.png&#x27;)) st.sidebar.write(&quot;---&quot;) rainbow = [&#x27;red&#x27;, &#x27;orange&#x27;, &#x27;yellow&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;, &#x27;navy&#x27;, &#x27;purple&#x27;] color = [&#x27;black&#x27;, &#x27;black&#x27;, &#x27;black&#x27;, &#x27;white&#x27;, &#x27;white&#x27;, &#x27;white&#x27;, &#x27;white&#x27;] text = &#x27;WELCOME&#x27; for r, c, t in zip(rainbow, color, text): st.sidebar.markdown(f&quot;&lt;h3 style=&#x27;color:&#123;c&#125;; background-color:&#123;r&#125;&#x27;&gt;__&#123;t&#125;:&lt;/h3&gt;&quot;, unsafe_allow_html=True) st.sidebar.write(&quot;---&quot;) st.sidebar.text(&quot;This is Jiwon!\\nNice to meet you!&quot;) # ë©”ì¸ í™”ë©´ st.header(&quot;A Letter From Peter&quot;) st.subheader(&#x27;:blue[&quot;Let me know where we will meet on Satuerday, with the dashboard made by streamlit.&quot;]&#x27;) st.write(&quot;---&quot;) # ë ˆì´ì•„ì›ƒ(2ë¶„í• ) col1, col2 = st.columns([1,2]) with col1: st.image(Image.open(&#x27;question.jpg&#x27;)) with col2: st.subheader(&#x27;:blue[&quot;What about í™ëŒ€ì…êµ¬?&quot;]&#x27;) center = [37.5575,126.9245] # í™ëŒ€ì…êµ¬ì—­ ì¢Œí‘œ # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° df = pd.read_csv(&quot;place.csv&quot;, encoding=&#x27;utf-8&#x27;) df[&#x27;to_í™ëŒ€&#x27;] = np.round(np.sqrt(np.power((df[&#x27;Lat&#x27;]-center[0]),2) + np.power((df[&#x27;Lon&#x27;]-center[1]),2)),2) # íƒ­ ë§Œë“¤ê¸° tab1, tab2 = st.tabs([&#x27;On Map&#x27;, &#x27;Raw Data&#x27;]) with tab2: st.write(df) with tab1: # ì§€ë„ ê°ì²´ ë§Œë“¤ê¸° m = folium.Map(location=center, zoom_start=11) # ë°°ê²½ ë ˆì´ì–´ ì‚½ì… (*vworld API) tiles = f&quot;http://api.vworld.kr/req/wmts/1.0.0/&#123;vworld_key.key&#125;/Base/&#123;&#123;z&#125;&#125;/&#123;&#123;y&#125;&#125;/&#123;&#123;x&#125;&#125;.png&quot; folium.TileLayer( tiles=tiles, attr=&quot;Vworld&quot;, overlay=True, control=True ).add_to(m) # ë§ˆì»¤ ë° ì§ì„  ì‚½ì… for idx, row in df.iterrows(): folium.Marker(location = [row[&#x27;Lat&#x27;],row[&#x27;Lon&#x27;]], tooltip=row[&#x27;Name&#x27;], icon=folium.Icon(color=&#x27;gray&#x27;)).add_to(m) folium.PolyLine(locations = [center, [row[&#x27;Lat&#x27;],row[&#x27;Lon&#x27;]]], tooltip=row[&#x27;to_í™ëŒ€&#x27;]).add_to(m) folium.Marker(location = center, tooltip=&#x27;í™ëŒ€ì…êµ¬ì—­&#x27;, icon=folium.Icon(color=&#x27;red&#x27;)).add_to(m) # ê²½ê³„ì„  ë§ì¶”ê¸° m.fit_bounds(m.get_bounds()) # ì§€ë„ ì €ì¥ ë° í™”ë©´ ì¶œë ¥ m.save(&#x27;map.html&#x27;) st.components.v1.html(open(&quot;map.html&quot;, &quot;rb&quot;).read(), height=600) st.write(&quot;---&quot;) if __name__ == &#x27;__main__&#x27;: main()","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"streamlit","slug":"python/streamlit","permalink":"http://gonekng.github.io/categories/python/streamlit/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"streamlit","slug":"streamlit","permalink":"http://gonekng.github.io/tags/streamlit/"}],"author":"Jiwon Kang"},{"title":"íŒŒì´ì¬ ê°€ìƒí™˜ê²½ ì„¤ì •í•˜ê¸° (Git Bash)","slug":"Python/Setting/venv","date":"2023-02-06T14:47:10.000Z","updated":"2023-02-09T14:54:20.296Z","comments":true,"path":"2023/02/06/Python/Setting/venv/","link":"","permalink":"http://gonekng.github.io/2023/02/06/Python/Setting/venv/","excerpt":"","text":"ê°€ìƒí™˜ê²½(virtual environment)ì´ë€? í˜„ì¬ ì„¤ì¹˜ëœ íŒŒì´ì¬ í™˜ê²½ê³¼ ë³„ê°œë¡œ ì¡´ì¬í•˜ëŠ” ë…ë¦½ì ì¸ í™˜ê²½ì„ ì˜ë¯¸ ë‹¤ìˆ˜ì˜ í”„ë¡œê·¸ë¨ì„ ê°œë°œí• ë•Œ íŒ¨í‚¤ì§€ ê°„ì˜ ë²„ì „ì´ ë‹¬ë¼ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²° í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ : venv ë¹„í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ : virtualvenv, pyenv, pipenv ë“±ë“± ê°€ìƒí™˜ê²½ ì„¤ì • Git Bashì—ì„œ í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™í•œ í›„ ê°€ìƒí™˜ê²½ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•œë‹¤. 1python -m venv ê°€ìƒí™˜ê²½ì´ë¦„ ìƒì„±í•œ ê°€ì„±í™˜ê²½ì„ í™œì„±í™”í•œë‹¤. 12345# í™œì„±í™”(Windows)source ê°€ìƒí™˜ê²½ì´ë¦„/Scripts/activate# í™œì„±í™”(Mac)source ê°€ìƒí™˜ê²½ì´ë¦„/bin/activate ë¹„í™œì„±í™” : deactivate íŒ¨í‚¤ì§€ ê´€ë¦¬ íŒ¨í‚¤ì§€ ì¶”ê°€ íŒ¨í‚¤ì§€ì˜ íŠ¹ì • ë²„ì „ì„ ì§€ì •í•˜ì—¬ ì„¤ì¹˜í•  ìˆ˜ ìˆìŒ 1python -m pip install íŒ¨í‚¤ì§€ì´ë¦„ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸ 1python -m pip install --upgrade íŒ¨í‚¤ì§€ì´ë¦„ íŒ¨í‚¤ì§€ ì¡°íšŒ 12345# ê°€ìƒí™˜ê²½ì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ëª… ë° ë²„ì „ ì¡°íšŒpip list# ê°€ìƒí™˜ê²½ì— ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ëª… ë° ë²„ì „ì„ txt íŒŒì¼ë¡œ ì €ì¥pip freeze &gt; requirements.txt Reference https://potato-potahto.tistory.com/entry/GITíŒŒì´ì¬-ê°€ìƒí™˜ê²½ê°€ìƒí™˜ê²½-ì„¤ì •","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"setting","slug":"python/setting","permalink":"http://gonekng.github.io/categories/python/setting/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"git","slug":"git","permalink":"http://gonekng.github.io/tags/git/"}],"author":"Jiwon Kang"},{"title":"Feature Encoding","slug":"Python/ML/Feature Encoding","date":"2022-12-22T14:21:54.000Z","updated":"2022-12-22T14:58:43.429Z","comments":true,"path":"2022/12/22/Python/ML/Feature Encoding/","link":"","permalink":"http://gonekng.github.io/2022/12/22/Python/ML/Feature%20Encoding/","excerpt":"","text":"ë°ì´í„° ì¸ì½”ë”©Scikit-learn ì•Œê³ ë¦¬ì¦˜ì€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì…ë ¥ê°’ìœ¼ë¡œ í—ˆìš©í•˜ê¸° ë•Œë¬¸ì—,ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•´ì„œëŠ” ëª¨ë“  ë¬¸ìì—´ ë°ì´í„°ë¥¼ ì¸ì½”ë”©í•˜ì—¬ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë¬¸ìì—´ ë°ì´í„°ëŠ” ë²”ì£¼í˜• ë°ì´í„°ì™€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ë¯¸í•˜ëŠ”ë°,ë²”ì£¼í˜• ë°ì´í„°ëŠ” ê° ë²”ì£¼ì— ëŒ€ì‘í•˜ëŠ” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ì§€ë§Œí…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” êµ¬ë¶„ì ì—­í• ì´ê±°ë‚˜ ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ ê²½ìš°ê°€ ë§ë‹¤. ì´ëŸ° ê²½ìš°ì—ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ìˆ˜í–‰ì— ìˆì–´ì„œ ë¶ˆí•„ìš”í•  ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë¯€ë¡œí˜•ì‹ì ì¸ ì¸ì½”ë”©ë³´ë‹¤ëŠ” ë³€ìˆ˜ì˜ íŠ¹ì„±ì„ ì˜ ì‚´í´ë³¸ í›„ ì‚­ì œí•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ ëŒ€í‘œì ì¸ ì¸ì½”ë”© ë°©ì‹ìœ¼ë¡œëŠ”Label Encoding(ë ˆì´ë¸” ì¸ì½”ë”©)ê³¼ One-Hot Encoding(ì›-í•« ì¸ì½”ë”©)ì´ ìˆë‹¤. Label Encodingë ˆì´ë¸” ì¸ì½”ë”©ì€ ê°„ë‹¨í•˜ê²Œ ë¬¸ìì—´ ê°’ì„ ê° ë²”ì£¼ì— í•´ë‹¹í•˜ëŠ” ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë°©ì‹ì´ë‹¤. í•˜ì§€ë§Œ ì´ëŠ” ë‹¨ìˆœíˆ êµ¬ë¶„ì„ ìœ„í•œ ìˆ«ìì´ê¸° ë•Œë¬¸ì—ì¼ë¶€ ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” ê° ìˆ«ìë¥¼ ê°€ì¤‘ì¹˜ë¡œ í•´ì„í•˜ì—¬ ê°’ì„ ì™œê³¡í•˜ê³ ê²°ê³¼ì ìœ¼ë¡œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ê²½ìš°ë„ ë°œìƒí•œë‹¤. ë”°ë¼ì„œ ë ˆì´ë¸” ì¸ì½”ë”©ì€ ì„ í˜• íšŒê·€ì™€ ê°™ì€ ì•Œê³ ë¦¬ì¦˜ì—ëŠ” ì ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ì¢‹ë‹¤.ë°˜ë©´ íŠ¸ë¦¬ ê³„ì—´ì˜ ë¹„ì„ í˜• ì•Œê³ ë¦¬ì¦˜ì€ ì´ëŸ¬í•œ íŠ¹ì„±ì„ ë°˜ì˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì ìš©í•´ë„ ì¢‹ë‹¤. Scikit-learnì˜ LabelEncoderë¥¼ í™œìš©í•œë‹¤. 123456789from sklearn.preprocessing import LabelEncodercities = [&#x27;Seoul&#x27;, &#x27;LA&#x27;, &#x27;Paris&#x27;, &#x27;Tokyo&#x27;, &#x27;LA&#x27;, &#x27;London&#x27;, &#x27;Seoul&#x27;, &#x27;Berlin&#x27;]encoder = LabelEncoder()encoder.fit(cities)labels = encoder.transform(cities)print(labels)# [4 1 3 5 1 2 4 0] classes_ ì†ì„±ì„ í†µí•´ ê° ìˆ«ìê°€ ê°€ë¦¬í‚¤ëŠ” ë²”ì£¼ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤. 123print(encoder.classes_)# [&#x27;Berlin&#x27; &#x27;LA&#x27; &#x27;London&#x27; &#x27;Paris&#x27; &#x27;Seoul&#x27; &#x27;Tokyo&#x27;] inverse_transform ì†ì„±ì„ í†µí•´ ì—­ë³€í™˜ í•  ìˆ˜ ìˆë‹¤. 123print(encoder.inverse_transform([1,4,5,0,2,3]))# [&#x27;LA&#x27; &#x27;Seoul&#x27; &#x27;Tokyo&#x27; &#x27;Berlin&#x27; &#x27;London&#x27; &#x27;Paris&#x27;] One-Hot Encodingì›-í•« ì¸ì½”ë”©ì€ ê° ë²”ì£¼ì— ëŒ€ì‘ë˜ëŠ” ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬í•´ë‹¹ ë²”ì£¼ì— ëŒ€ì‘í•˜ëŠ” ì¹¼ëŸ¼ì—ë§Œ 1ì„ í‘œì‹œí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” 0ì„ í‘œì‹œí•˜ëŠ” ë°©ì‹ì´ë‹¤. ë”°ë¼ì„œ ì¸ì½”ë”©ì— ì•ì„œ ëª¨ë“  ë¬¸ìì—´ ê°’ì´ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•˜ë©°,Encoderì˜ ì…ë ¥ ê°’ìœ¼ë¡œ 2ì°¨ì› ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤. ë‹¨, ë²”ì£¼ê°€ ë§ì„ ê²½ìš° ê³¼ë„í•˜ê²Œ ë§ì€ ë³€ìˆ˜ê°€ ìƒì„±ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—ìƒí™©ì— ë§ê²Œ ë ˆì´ë¸” ì¸ì½”ë”©ê³¼ ì ì ˆí•˜ê²Œ í˜¼ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤. Scikit-learnì˜ OneHotEncoder í´ë˜ìŠ¤ 123456789101112131415161718192021222324252627282930from sklearn.preprocessing import OneHotEncoderimport numpy as npcities = [&#x27;Seoul&#x27;, &#x27;LA&#x27;, &#x27;Paris&#x27;, &#x27;Tokyo&#x27;, &#x27;LA&#x27;, &#x27;London&#x27;, &#x27;Seoul&#x27;, &#x27;Berlin&#x27;]#Step1: ëª¨ë“  ë¬¸ìë¥¼ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.encoder = LabelEncoder()encoder.fit(cities)labels = encoder.transform(cities)#Step2: 2ì°¨ì› ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.labels = labels.reshape(-1, 1)#Step3: One-Hot Encoding ì ìš©í•©ë‹ˆë‹¤.oh_encoder = OneHotEncoder()oh_encoder.fit(labels)oh_labels = oh_encoder.transform(labels)print(oh_labels.toarray())print(oh_labels.shape)# [[0. 0. 0. 0. 1. 0.]# [0. 1. 0. 0. 0. 0.]# [0. 0. 0. 1. 0. 0.]# [0. 0. 0. 0. 0. 1.]# [0. 1. 0. 0. 0. 0.]# [0. 0. 1. 0. 0. 0.]# [0. 0. 0. 0. 1. 0.]# [1. 0. 0. 0. 0. 0.]]# (8, 6) Pandasì˜ get_dummies í•¨ìˆ˜ 123456import pandas as pdcities = [&#x27;Seoul&#x27;, &#x27;LA&#x27;, &#x27;Paris&#x27;, &#x27;Tokyo&#x27;, &#x27;LA&#x27;, &#x27;London&#x27;, &#x27;Seoul&#x27;, &#x27;Berlin&#x27;]df = pd.DataFrame(&#123;&#x27;item&#x27;:cities&#125;)print(pd.get_dummies(df)) Referenceë°ì´í„° ì „ì²˜ë¦¬í•˜ê¸° : ë ˆì´ë¸” ì¸ì½”ë”© (Label Encoding), ì›-í•« ì¸ì½”ë”©(One-Hot Encoding), get_dummies()ë¥¼ Pandasì—ì„œ ì‚¬ìš©í•˜ê¸°","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"},{"name":"scikit-learn","slug":"scikit-learn","permalink":"http://gonekng.github.io/tags/scikit-learn/"}],"author":"Jiwon Kang"},{"title":"í† ì˜ë©´ì ‘ TIP","slug":"etc/í† ì˜ë©´ì ‘ TIP","date":"2022-12-10T14:23:51.000Z","updated":"2022-12-10T14:46:18.076Z","comments":true,"path":"2022/12/10/etc/í† ì˜ë©´ì ‘ TIP/","link":"","permalink":"http://gonekng.github.io/2022/12/10/etc/%ED%86%A0%EC%9D%98%EB%A9%B4%EC%A0%91%20TIP/","excerpt":"","text":"ì¶œì²˜ : Youtube ê°•ë¯¼í˜ ì±„ë„ í† ì˜ë©´ì ‘ í‰ê°€ìš”ì†Œ ê°œë°©ì„± ì„¤ë“ë ¥ ìˆëŠ” ë°˜ë¡  ì œê¸° ì‹œ ë³¸ì¸ ì£¼ì¥ì„ ìˆ˜ì •í•˜ë ¤ëŠ” ê°œë°©ì  ìì„¸ ì¸ì • : ë³¸ì¸ì´ í‹€ë¦´ ìˆ˜ë„ ìˆë‹¤ëŠ” ê²ƒì„ ì „ì œ ìˆ˜ì • : íƒ€ì¸ ì˜ê²¬ ìˆ˜ìš© í›„ ë”ìš± ì ê·¹ì ìœ¼ë¡œ ê³µê°í•¨ ì˜ê²¬ ê°œì§„ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ê²½ì²­ ë° ê°„ê²°í•˜ë©´ì„œë„ ì •í™•í•˜ê²Œ ë©”ì‹œì§€ë¥¼ ì „ë‹¬ ê²½ì²­ : ì•„ì´ì»¨íƒ, ë©”ëª¨, ë°œì–¸ì ë‚´ìš© í™•ì¸ ì „ë‹¬ : í•„ìš”í•œ ë©”ì‹œì§€ë¥¼ ì¶©ë¶„íˆ ì „ë‹¬ â†’ ë‘ê´„ì‹, ìˆ˜ì‚¬ í™œìš©, í•œ ë°œì–¸ì—ëŠ” í•œ ê°€ì§€ ì˜ë¯¸ë§Œ ì „ë‹¬ ë¶„ì„&#x2F;ì„¤ë“ë ¥ ë¶„ì„ë ¥ : ì œí•œëœ ì‹œê°„ ë‚´ì— ë‹¤ì–‘í•œ ì •ë³´ ìˆ˜ì§‘ ë° ê°€ê³µ ì„¤ë“ë ¥ : ë…¼ë¦¬ì  ê·¼ê±°ë¥¼ ì œì‹œí•˜ì—¬ ë³¸ì¸ì˜ ì£¼ì¥ì„ ë’·ë°›ì¹¨ ì ê·¹ì„±&#x2F;ìŠ¤íŠ¸ë ˆìŠ¤ë‚´ì„± ì ê·¹ì„± : ì£¼ì œ í•´ê²°ì„ ìœ„í•œ ì˜ì§€ â†’ íƒ€ì¸ì˜ ì£¼ì¥ì´ ë¹„í•©ë¦¬ì ì´ê±°ë‚˜ ë…¼ë¦¬ì ì´ì§€ ì•Šì„ ê²½ìš° ê³µì†í•˜ê²Œ ì±Œë¦°ì§€ ìŠ¤íŠ¸ë ˆìŠ¤ë‚´ì„± : ê¸´ì¥ê° ì ì ˆíˆ ê´€ë¦¬, ìì‹ ê° ìˆê²Œ ë§í•˜ê³  í–‰ë™ í† ì˜ ì‹œì‘ ì „ ì£¼ì œë¡œ ì¶œì œ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ê³µë¶€í•˜ê¸° ê¸°ì¶œë¬¸ì œ, ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¸ë Œë“œ, ì‚¬ì—…êµ° ì´ìŠˆ ë“± ì•„ì´ë””ì–´ êµ¬ìƒê³¼ í•¨ê»˜ ìƒëŒ€ë°© ë²ˆí˜¸ ê¸°ì–µí•˜ê¸° ì¤€ë¹„ ì‹œê°„ ì¡°ì ˆ ë° ì•ˆë°°í•˜ê¸° A4 êµ¬ì¡°í™” 1ë¶„ + ìë£Œ ì´í•´ 5ë¶„ + ì•„ì´ë””ì–´ ìƒê° 7ë¶„ + íœ ì‘ì„± 5ë¶„ + ìƒê° ì •ë¦¬ 2ë¶„ &#x3D; 20ë¶„ í† ì˜ ì‹œì‘ í›„ ê¸°ì¡° ë°œì–¸í•˜ê¸° Oë²ˆ ì§€ì›ì ê¸°ì¡°ë°œì–¸ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ì €ëŠ” â€˜OOOâ€™ ì£¼ì œì— ëŒ€í•˜ì—¬ ~~~ë¥¼ ì œì‹œí•©ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ê·¼ê±°ë¡œëŠ” í¬ê²Œ A, B, Cê°€ ìˆìœ¼ë©° ìì„¸í•œ ì‚¬í•­ì€ ë³¸ í† ì˜ ì‹œê°„ì— ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ìƒëŒ€ë°© ì˜ê²¬ í™•ì¥í•˜ê¸° Oë²ˆ ì§€ì›ìë‹˜ì˜ A ì˜ê²¬ì— ê³µê°í•©ë‹ˆë‹¤. ì¡°ê¸ˆ ë” ë‚´ìš©ì„ ë§ë¶™ì´ìë©´, ~~ í™”ì œ ì „í™˜í•˜ê¸° ì§€ê¸ˆê¹Œì§€ Aì™€ ê´€ë ¨í•˜ì—¬ ~~~ ë¼ëŠ” ê³µí†µ ì˜ê²¬ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, í•œì •ëœ ì‹œê°„ì„ ê³ ë ¤í• ë•Œ ì´ì œ Bì™€ Cì˜ ì¸¡ë©´ ë˜í•œ ì˜ë…¼í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. ë‹¤ë“¤ ë™ì˜í•˜ì‹œë‚˜ìš”? ì •ë¦¬ ë°œì–¸í•˜ê¸° ì§€ê¸ˆê¹Œì§€ â€˜OOOâ€™ ì£¼ì œì— ëŒ€í•œ ë°©ì•ˆìœ¼ë¡œ í¬ê²Œ A, B, Cì˜ ì¸¡ë©´ì— ëŒ€í•´ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤. ì„¸ë¶€ì ìœ¼ë¡œëŠ” ~~~ ë¼ëŠ” ì˜ê²¬ì´ ë‚˜ì™”ëŠ”ë°, ì´ë¥¼ í†µí•´ ~~~ì˜ íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.","categories":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"}],"tags":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ë©´ì ‘","slug":"ë©´ì ‘","permalink":"http://gonekng.github.io/tags/%EB%A9%B4%EC%A0%91/"}],"author":"Jiwon Kang"},{"title":"ë©´ì ‘ TIP","slug":"etc/ë©´ì ‘ TIP","date":"2022-12-10T12:56:01.000Z","updated":"2022-12-10T14:23:00.490Z","comments":true,"path":"2022/12/10/etc/ë©´ì ‘ TIP/","link":"","permalink":"http://gonekng.github.io/2022/12/10/etc/%EB%A9%B4%EC%A0%91%20TIP/","excerpt":"","text":"ì¶œì²˜ :Youtube AND(ì¸ì‹¸ë‹´ë‹¹ì) ì±„ë„Youtube ë©´ì ‘ì™•ì´í˜• ì±„ë„ ê¸°ì—… ë¶„ì„ í•„ìˆ˜ ìš”ì†Œ 4ê°€ì§€ ê¸°ì—… ê³µì‹ í™ˆí˜ì´ì§€ : ì¼ë°˜ í˜„í™©, ì¸ì‚¬ë§ : ì¡°ì§ ì²´ê³„, ë¹„ì „ ì²´ê³„ : ë‹¹í•´ë…„ë„ ì „ëµ ëª©í‘œ, ë¸Œë¡œìŠˆì–´, ESG ë³´ê³ ì„œ ê¸°ì—… ê³µì‹œ ìë£Œ â†’ ì‚¬ê¸°ì—… - DART, ê³µê¸°ì—… - ì¡ì•Œë¦¬ì˜¤ : ë§¤ì¶œì•¡, ì˜ì—…ì´ìµ, ì‚¬ì—… íë¦„ ë“±ë“± ìµœê·¼ 6ê°œì›” ê¸°ì—… ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì—… ëŒ€í‘œì˜ ì‹ ë…„ì‚¬ - í‚¤ì›Œë“œ ê¸°ì—… ë¶„ì„ í•„ìˆ˜ ì¤€ë¹„ ì§ˆë¬¸ 5ê°€ì§€ ì§€ì› íšŒì‚¬ê°€ ìˆ˜í–‰í•˜ëŠ” ì‚¬ì—…ì€ ë¬´ì—‡ì¸ê°€? ì§€ì› íšŒì‚¬ì˜ ê°•ì ê³¼ ì•½ì ì€ ë¬´ì—‡ì¸ê°€? ì§€ì› íšŒì‚¬ì˜ ë‹¹í•´ë…„ë„ ì „ëµ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€? ì§€ì› íšŒì‚¬ì˜ ê²½ìŸì‚¬ëŠ” ì–´ë””ë¼ê³  ìƒê°í•˜ëŠ”ê°€? í˜„ ì‹œì¥ ìƒí™©ì—ì„œ ì§€ì› íšŒì‚¬ê°€ ë‚˜ì•„ê°€ì•¼ í•  ë°©í–¥ì€? ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ë°©ë²• ğŸ’¡ ë‘ê´„ì‹ìœ¼ë¡œ ë‹µë³€ : ì£¼ì¥ â†’ ê·¼ê±° â†’ ê²°ê³¼ â†’ í¬ë¶€ Q. ~ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ë‚˜ìš”? ì €ëŠ” ì´ë ‡ê²Œ ìƒê°í•©ë‹ˆë‹¤. ê·¼ê±°ëŠ” ì´ê²ë‹ˆë‹¤. ê·¸ë˜ì„œ ì´ë ‡ê²Œ í•˜ê² ìŠµë‹ˆë‹¤. Q. ~ì™€ ê´€ë ¨ëœ ê²½í—˜ì´ ìˆë‚˜ìš”? ì €ëŠ” ì´ëŸ° ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë•Œì˜ ìƒí™©ì€ ì–´ë• ìŠµë‹ˆë‹¤. ì €ëŠ” ì–´ë–¤ ì•¡ì…˜ì„ ì·¨í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ë¬´ìŠ¨ ì¼ì´ ë²Œì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ ê²½í—˜ì„ í†µí•´ ì´ëŸ° ëŠ¥ë ¥ì„ ê¸¸ë €ìŠµë‹ˆë‹¤. ì§ë¬´ì í•©ì„± ìê¸°ì†Œê°œì„œë¶€í„° ë©´ì ‘ê¹Œì§€ ì¼ê´€ì„± ìˆê²Œ ë‹µë³€í•˜ê¸° í•´ë‹¹ ì§ë¬´ë¥¼ ì¢‹ì•„í•˜ê²Œ ëœ ì´ìœ ë‚˜ ê³„ê¸°ë¶€í„° ì‹œì‘í•˜ê¸° í•™êµ ìˆ˜ì—…, ì•„ë¥´ë°”ì´íŠ¸, ìœ íŠœë¸Œ ì˜ìƒ ë“± ì‚¬ì†Œí•œ ê³„ê¸°ë„ ì¶©ë¶„íˆ ê°€ëŠ¥ ë‹µë³€ì— ê¸°ìŠ¹ì „ê²°ì„ ê°–ì¶°ì„œ ìŠ¤í† ë¦¬í…”ë§í•˜ê¸° ì§ë¬´ë¥¼ ì¢‹ì•„í•˜ê²Œ ëœ ê³„ê¸° + ì§ë¬´ë¥¼ ìœ„í•œ ë…¸ë ¥ ë° ì¤€ë¹„ ê³¼ì • ë©´ì ‘ ì§ˆë¬¸ ê¸°ë³¸ ìœ í˜• 5ê°€ì§€ 1ë¶„ ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš” ì§ˆë¬¸ì˜ë„ : ì²«ì¸ìƒ ì²´í¬, ë§í•  ê¸°íšŒ ì£¼ê¸°, ì§ˆë¬¸ê±°ë¦¬ ì°¾ê¸° ìœ ì‚¬ì§ˆë¬¸ ê°„ë‹¨í•˜ê²Œ ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš” ì¤€ë¹„ëœ ê±° ë§ê³  í¸ì•ˆí•˜ê²Œ ìê¸°ì†Œê°œ í•´ì£¼ì„¸ìš” ë‹µë³€ë°©ë²• ê°€ì¥ ì–´í•„í•˜ê³  ì‹¶ì€ í•„ì‚´ê¸°ë¥¼ ì „ë‹¬í•˜ê¸° ë¹„êµì  ì„±ê³¼ê°€ ëª…í™•í•˜ê³  ì§ë¬´ ì—°ê´€ì„±ì´ ë†’ì€ ì„±ê³µê²½í—˜ ë¹„ìœ ì  í‘œí˜„, ì¶”ìƒì  ê°œë…, ì„±ê²©ì  íŠ¹ì§• X ì°¨ë³„í™”ëœ ë³¸ì¸ì˜ ê°•ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš” ì§ˆë¬¸ì˜ë„ : ë½‘ì•„ì•¼ í•  ì´ìœ  ì°¾ê¸° ìœ ì‚¬ì§ˆë¬¸ ì„±ê³µ ê²½í—˜ì— ëŒ€í•´ì„œ ì†Œê°œí•´ì£¼ì„¸ìš” ë¶„ì„ë ¥ì„ í†µí•´ì„œ ì„±ê³¼ë¥¼ ë‚¸ ê²½í—˜ì´ ìˆë‹¤ë©´ ì–˜ê¸°í•´ì£¼ì„¸ìš” ê·¸ ê²½í—˜ì„ ì¢€ ë” ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš” ë‹µë³€ë°©ë²• ê°€ì¥ ì˜ë¯¸ ìˆì—ˆë˜ ì„±ê³µê²½í—˜ì˜ ì•¡ì…˜ê³¼ ê²°ê³¼ë¶€í„° ë˜ì§€ê¸° (ë‘ê´„ì‹) ê·¸ ì´í›„ì— ìƒí™©, ì˜ë„, ë°°ìš´ ì ì„ ì„¤ëª…í•˜ê¸° ì™œ ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í•˜ì…¨ë‚˜ìš”? ì§ˆë¬¸ì˜ë„ : íšŒì‚¬ì— ëŒ€í•œ ë¡œì—´í‹°, ê´€ì‹¬ë„, í¥ë¯¸ë„ í™•ì¸ ìœ ì‚¬ì§ˆë¬¸ ë‹¤ë¥¸ íšŒì‚¬ ì–´ë”” ë˜ ì§€ì›í•˜ì…¨ë‚˜ìš”? ì—¬ê¸°ì„œ ë–¨ì–´ì§€ë©´ ì–´ë”” ê°ˆ ê±°ì—ìš”? ìš°ë¦¬ íšŒì‚¬ì— ëŒ€í•´ ì•„ëŠ” ëŒ€ë¡œ ì–˜ê¸°í•´ë³´ì„¸ìš” ë‹µë³€ë°©ë²• íšŒì‚¬ì˜ ê²½ìŸë ¥, ê¸°ìˆ ì  íŠ¹ì„±ì„ ë‚˜ì˜ ê²½í—˜ê³¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…í•˜ê¸° í˜„ì§ì ì¸í„°ë·°ë¥¼ í†µí•´ íšŒì‚¬ì˜ ì°¨ë³„í™”ëœ íŠ¹ì„±ì„ ì•Œì•„ë³´ê¸° ì„±ê²©ì˜ ì¥ë‹¨ì ì´ ìˆë‚˜ìš”? ì§ˆë¬¸ì˜ë„ : ìê¸° ê°ê´€í™”ê°€ ì˜ ë˜ì–´ìˆëŠ”ì§€, íšŒì‚¬ì— ì˜ ì ì‘í•  ìˆ˜ ìˆëŠ”ì§€ ìœ ì‚¬ì§ˆë¬¸ í˜ë“¤ì—ˆë˜ ê²½í—˜ì´ ìˆë‚˜ìš”? ê°™ì´ ì¼í•˜ê¸° í˜ë“  ì‚¬ëŒì€ ì–´ë–¤ ìœ í˜•ì¸ê°€ìš”? ì£¼ë³€ ì‚¬ëŒë“¤ì€ ë³¸ì¸ì„ ì–´ë–»ê²Œ í‰ê°€í•˜ì‹œë‚˜ìš”? ì–´ë–¤ ë³„ëª…ì„ ê°€ì§€ê³  ê³„ì‹ ê°€ìš”? ë‹µë³€ë°©ë²• MBTI ë“±ì„ í† ëŒ€ë¡œ ê°ê´€ì ì¸ ì„±ê²© ìš”ì†Œ ë‹µë³€í•˜ê¸° ë‚´ê°€ ê·¹ë³µí–ˆë˜ ë‹¨ì ì„ ê²½í—˜ê³¼ í•¨ê»˜ ì„¤ëª…í•˜ê¸° ë§ˆì§€ë§‰ í•˜ê³  ì‹¶ì€ ë§ ìˆìœ¼ì‹ ê°€ìš”? ì§ˆë¬¸ì˜ë„ : ë©´ì ‘ ë§ˆë¬´ë¦¬, ë”±íˆ ì˜ë¯¸ ì—†ìŒ ìœ ì‚¬ì§ˆë¬¸ ë§ˆì§€ë§‰ìœ¼ë¡œ ê¶ê¸ˆí•˜ì‹ ê±° ìˆìœ¼ì‹ ê°€ìš”? í˜¹ì‹œ í•˜ì§€ ëª»í•œ ë§ì´ ìˆë‚˜ìš”? ë‹µë³€ë°©ë²• ê²°ê³¼ê°€ ë°”ë€” ê°€ëŠ¥ì„±ì€ ê±°ì˜ ì—†ìŒ í•„ì‚´ê¸°ë¥¼ ì˜ ë˜ì¡Œì„ ê²½ìš° ê°ì‚¬ í‘œí˜„ê³¼ í•¨ê»˜ ê°„ë‹¨í•˜ê²Œ ë§ˆë¬´ë¦¬ í•„ì‚´ê¸°ë¥¼ ëª» ë˜ì¡Œì„ ê²½ìš° ì¤€ë¹„í•œ ë‚´ìš© ë˜ì§€ê¸° ë©´ì ‘ê´€ì´ ë‹µë³€í•˜ê¸° ì‰¬ìš´, ìë‘í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸í•˜ê¸° ex) íšŒì‚¬ì˜ í–¥í›„ ì„±ì¥ ì „ëµ ë“±","categories":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"}],"tags":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ë©´ì ‘","slug":"ë©´ì ‘","permalink":"http://gonekng.github.io/tags/%EB%A9%B4%EC%A0%91/"}],"author":"Jiwon Kang"},{"title":"ìì†Œì„œ TIP (3)","slug":"etc/ìì†Œì„œ TIP 3","date":"2022-12-08T14:57:25.000Z","updated":"2022-12-08T15:28:30.283Z","comments":true,"path":"2022/12/08/etc/ìì†Œì„œ TIP 3/","link":"","permalink":"http://gonekng.github.io/2022/12/08/etc/%EC%9E%90%EC%86%8C%EC%84%9C%20TIP%203/","excerpt":"","text":"ì¶œì²˜ : Youtube AND(ì¸ì‹¸ë‹´ë‹¹ì) ì±„ë„ ë…¼ë¦¬ì  ì‚¬ê³ ë ¥ğŸ“Œ ë…¼ë¦¬ì  ì‚¬ê³ ë ¥ (ë¬¸ì œ í•´ê²°ë ¥) : ë¶„ì„, ì „ëµ, ì•„ì´ë””ì–´, í˜ì‹ , ê°œì„ , ì°½ì˜ë ¥ â†’ í•˜ë‚˜ì˜ ë‹µë³€ìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì—­ëŸ‰ì— ëŒ€í•œ ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€ ê°€ëŠ¥ ê°œë… ì •ë¦¬ë¶„ì„ : Aì—ì„œ Bë¡œ ê°ˆ ìˆ˜ ìˆëŠ” ìœ ì˜ë¯¸í•œ ê¸¸ì„ ì°¾ì•„ë‚´ëŠ” ëŠ¥ë ¥ ì „ëµ : ê°€ì¥ ë¹ ë¥¸ ê¸¸ì„ ì„ íƒí•˜ê³ , í•„ìš”í•œ ìš”ì†Œë¥¼ í™œìš©í•  ì¤„ ì•„ëŠ” ëŠ¥ë ¥â†’ ë¶„ì„ë ¥ê³¼ ì „ëµì  ì‚¬ê³ ëŠ” í•­ìƒ í•¨ê»˜ í•˜ëŠ” ê²ƒ (ë¬´ì—‡ í•˜ë‚˜ ì—†ìœ¼ë©´ ë§¥ë½ì´ ë¹ ì ¸ë²„ë¦¼) ì°½ì˜ë ¥ : ê¸°ì¡´ì— ì—†ë˜, ê·¼ê±°ê°€ ì—†ëŠ” ê¸¸ì„ ë§Œë“œëŠ” ëŠ¥ë ¥â†’ ì§ˆë¬¸ì˜ ì˜ë„ëŠ” ì´ì™€ ë‹¤ë¥´ë©°, ì‹¤ì œë¡œ ìì†Œì„œì— ë…¹ì—¬ë‚´ê¸° ì–´ë ¤ì›€â†’ ë”°ë¼ì„œ ì°½ì˜ë ¥, í˜ì‹ , ìƒˆë¡œìš´ ì‚¬ê³  ì§ˆë¬¸ì—ë„ ë¶„ì„&amp;ì „ëµì— í•´ë‹¹í•˜ëŠ” ë‹µë³€ì„ ì ìœ¼ë©´ ë¨ í•µì‹¬ í¬ì¸íŠ¸ë‹¨ìˆœí•œ í˜„ìƒì˜ í•´ê²°ì´ ì•„ë‹Œ ê·¼ë³¸ì ì¸ ë¬¸ì œì˜ ì›ì¸ì„ í•´ê²°í–ˆë‹¤. ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì‚¬ê³  ê³¼ì • : ë¬¸ì œ ì¸ì‹ - ì›ì¸ ë¶„ì„ - ì›ì¸ í•´ê²° - ìƒí™© í•´ê²° ì´ë•Œ ì›ì¸ì€ ì¼ì°¨ì›ì ìœ¼ë¡œ ìƒê°í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë‚´ê°€ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë‹¨ìœ„ê¹Œì§€ ì—°ê²°í•´ì•¼ í•¨ ex) ì¹´í˜ì—ì„œ ì•Œë°”í•˜ë˜ ì¤‘ ë§¤ì¶œì´ ë–¨ì–´ì§„ ì›ì¸ì„ ì°¾ê¸° ìœ„í•´ ì¸ê·¼ ìƒê¶Œì„ ì¡°ì‚¬í–ˆìŠµë‹ˆë‹¤. ì•Œê³  ë³´ë‹ˆ ë¹„ìŠ·í•œ ì»¨ì…‰ì˜ ì¹´í˜ê°€ ê·¼ì²˜ì— ë§ì´ ìƒê¸´ ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. (ì›ì¸ X) ê·¸ë˜ì„œ ì €í¬ ë‹¨ê³¨ ê³ ê°ì—ê²Œ OOì¹´í˜ë¥¼ ìì£¼ ì´ìš©í•˜ëŠ” ì´ìœ ë¥¼ ë¬¼ì–´ë´¤ë”ë‹ˆ ë‹¤ë¥¸ ì¹´í˜ë“¤ì— ë¹„í•´ ìƒê³¼ì¼ ì£¼ìŠ¤ê°€ ë” ë§›ìˆì–´ì„œ ìì£¼ ì°¾ê²Œ ëœë‹¤ëŠ” ë‹µë³€ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ìƒê³¼ì¼ ì£¼ìŠ¤ ë¼ì¸, íŠ¹íˆ ê³„ì ˆì— ë§ëŠ” ìˆ˜ë°•ì£¼ìŠ¤ ë“±ì„ ë©”ë‰´ì— ì¶”ê°€í•˜ì˜€ê³ , ì»¤í”¼ì˜ ë§¤ì¶œì€ ì¡°ê¸ˆ ë–¨ì–´ì¡Œì§€ë§Œ ìƒê³¼ì¼ ì£¼ìŠ¤ì˜ ë§¤ì¶œì´ ë§ì´ ì˜¬ë¼ì„œ ì „ì²´ ë§¤ì¶œì„ ìœ ì§€í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ë¬¸ì œ ë¬¸ì œ ì¸ì‹ ë° ì›ì¸ í™•ì¸ ì›ì¸ í•´ê²° ë° ê·¼ê±° ê²°ê³¼ í¬ë¶€ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ğŸ“Œ ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ì€ ì„±ê³¼ë³´ë‹¤ ë¬¸ì œ í•´ê²°ì— ì´ˆì ì„ ë§ì¶° ì–´í•„í•´ì•¼ í•˜ëŠ” ì—­ëŸ‰ ê°œë… ì •ë¦¬í”ŒëŸ¬ìŠ¤(+) ì—­ëŸ‰ : ì„±ê³¼ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²° ex) ëª©í‘œ ë‹¬ì„± ëŠ¥ë ¥, ë„ì „ ì •ì‹ , ë…¼ë¦¬ì  ì‚¬ê³ ë ¥ ë“±ë“± ë§ˆì´ë„ˆìŠ¤(-) ì—­ëŸ‰ : ì‹¤íŒ¨ì™€ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²° ex) ì˜ì‚¬ì†Œí†µ, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜, íŒ€ì›Œí¬ ë“±ë“±â†’ ì•„ë¬´ë¦¬ ë›°ì–´ë‚˜ë„ ì•„ë¬´ ë¬¸ì œê°€ ì¼ì–´ë‚˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ìì†Œì„œì— ë…¹ì—¬ë‚´ê¸° ì–´ë ¤ì›€â†’ ë§ˆì´ë„ˆìŠ¤ ì—­ëŸ‰ì€ â€˜ë›°ì–´ë‚˜ë‹¤â€™ë³´ë‹¤ â€˜ë…¸ë ¥í–ˆë‹¤â€™ë¥¼ ì„œìˆ í•´ì•¼ í•˜ëŠ” ì—­ëŸ‰â†’ ë‚˜ì˜ ì‹¤ìˆ˜ ë˜ëŠ” ì˜ëª»ìœ¼ë¡œ ì´ëŸ¬í•œ ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤. í•˜ì§€ë§Œ ì´ ì—­ëŸ‰ì„ ê°€ì§€ê³  ë…¸ë ¥í•´ì„œ ê·¹ë³µí–ˆë‹¤. | ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ |ì •ë³´ ì „ë‹¬ì˜ ì˜¤ë¥˜ë¥¼ ë§‰ê¸° ìœ„í•´ì„œ ë‚´ê°€ í•œ ì–¸ì–´ì , ë¹„ì–¸ì–´ì ì¸ ë…¸ë ¥ê³¼ ê·¸ë¡œ ì¸í•œ ë¬¸ì œ í•´ê²° ê²½í—˜ í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥ì˜ ì •ì˜ëŠ” ì‚¬ëŒë§ˆë‹¤ ì²œì°¨ë§Œë³„ì´ê¸° ë•Œë¬¸ì— ì¬ì •ì˜ê°€ íŠ¹íˆ ì¤‘ìš”í•¨ ì •ë³´ì „ë‹¬ì˜ ì˜¤ë¥˜ë¡œ ë°œìƒí•œ í˜„ìƒ ë‚´ê°€ ìƒê°í•˜ëŠ” ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì˜ ì •ì˜ ë°˜ë“œì‹œ ë¬¸ì œê°€ ì˜ˆìƒë˜ê±°ë‚˜ ë¬¸ì œê°€ ìˆì–´ì•¼ í•¨ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ì˜ì‚¬ì†Œí†µì˜ í˜•íƒœë¥¼ ë°”ê¾¼ ì•¡ì…˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì„ ìœ„í•œ ì–¸ì–´ì , ë¹„ì–¸ì–´ì  ë…¸ë ¥ ë³´ì¶© ì„¤ëª…, ë‹¨ì–´ êµì²´, ì‚¬ë¡€ ì œì‹œ, ì‹œê°ìë£Œ í™œìš©, ì¬ì°¨ í™•ì¸ ê²°ê³¼ í¬ë¶€ | ì„¤ë“ë ¥ |ê°€ì¹˜ê´€/ì´í•´ê´€ê³„ë¡œ ëŒ€ë¦½ë  ë•Œ ìƒëŒ€ë°©ì˜ ìƒê°ì„ ë‚˜ì˜ ìƒê°ìœ¼ë¡œ ë°”ê¾¼ ê²½í—˜ (ë‚˜ë§Œì˜ ë…¸í•˜ìš°/ë°©ë²•) â€» ìƒì‚¬ëŠ” ì„¤ë“í•˜ëŠ” ëŒ€ìƒì´ ì•„ë‹ˆë¼, ë‚´ê°€ ì»¨íŒë°›ì•„ì•¼ í•˜ëŠ” ëŒ€ìƒ â†’ ì„¤ë“ë ¥ì˜ ì‚¬ë¡€ X í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ë‚˜ë§Œì˜ ì„¤ë“ ë°©ë²•&#x2F;ë…¸í•˜ìš° ìƒí™© ì•¡ì…˜ ì„¤ë“ ê³¼ì •ì„ ì•¡ì…˜ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ  ê²°ê³¼ í¬ë¶€ ì¡°ì§ ê²½í—˜| ì£¼ë„ì„± &#x2F; ì ê·¹ì„± |ì¡°ì§ ê²½í—˜ ë¬¸í•­ì´ê¸° ë•Œë¬¸ì— ê¸°ì¡´ì— ì£¼ì–´ì§„ ì—…ë¬´ ìˆ˜í–‰ì€ í•„ìˆ˜ ì„ í–‰ì¡°ê±´ ì•„ë¬´ë„ ì‹œí‚¤ì§€ ì•Šì€ ì¼ ì£¼ì–´ì§„ ì—…ë¬´ ì™¸ì— ì¶”ê°€ì ìœ¼ë¡œ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œ ê²½í—˜ ì—…ë¬´ì˜ ë²”ìœ„ì™€ í•œê³„ë¥¼ ì„œìˆ í•´ì„œ ê·¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ì¼ì´ë¼ëŠ” ê²ƒì„ ì–´í•„ ì£¼ë„ì ì¸ ëª©í‘œ ì„ ì • | ì±…ì„ê° | ì¡°ì¥ìœ¼ë¡œì„œ ì¡°ë³„ê³¼ì œë¥¼ ì´ëŒì—ˆë˜ ê²½í—˜ì€ ë„ˆë¬´ í”í•œ ì‚¬ë¡€ â†’ ë‹¤ë¥¸ ê²½í—˜ ì°¾ì•„ë³´ê¸° í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ìƒí™© ë…¸ë ¥(í¬ìƒ) ì˜ˆìƒì¹˜ ëª»í•œ ì¥ì• ë¬¼ì„ ê·¹ë³µí•œ ê²½í—˜ë„ í¬ìƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ ê²°ê³¼ í¬ë¶€ | ë¦¬ë”ì‹­ |ë¦¬ë”ì‹­ 3ìš”ì†Œ : â€˜ì¡°ì§â€™ì´ â€˜ëª©í‘œâ€™ë¥¼ ë‹¬ì„±í•  ë•Œ ë‚´ê°€ ì¤€ â€˜ì˜í–¥ë ¥â€™ â†’ ì•„ë¬´ë¦¬ ë§ì€ ì˜í–¥ë ¥ì„ ì£¼ê³  í° ê¸°ì—¬ë¥¼ í•´ë„ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì§€ ëª»í•˜ë©´ ë¦¬ë”ì‹­ ë¶€ì¡±ìœ¼ë¡œ ê°„ì£¼ í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ì¡°ì§ì˜ ëª©í‘œ ë˜ëŠ” ë°œìƒí•œ ë¬¸ì œ ì¡°ì§ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ê³ ë¯¼ ëì— ë‚´ë¦° ë‚˜ì˜ ì˜ì‚¬ê²°ì • ë‚˜ì˜ ê³ ë¯¼, ê²°ì •, í–‰ë™ì˜ ì´ìœ  ì¡°ì§ì›ë“¤ì—ê²Œ ì¤€ ì˜í–¥ë ¥ ê²°ê³¼ í¬ë¶€ | íŒ€ì›Œí¬ |ì±…ì„ê°ê³¼ ìœ ì‚¬í•œ ì—­ëŸ‰. ë‚˜ë¥¼ í¬ìƒí•´ì„œ ì¡°ì§ì„ ìœ„í•´ í—Œì‹ í•  ìˆ˜ ìˆëŠ”ê°€? ì„ í–‰ì¡°ê±´ í¬ìƒê³¼ ì‹œë„ˆì§€ ì—…ë¬´ ìŠµê´€ ë˜ëŠ” ë°©ì‹ì˜ ì°¨ì´ ì—…ë¬´ ìŠµê´€ì´ë‚˜ ë°©ì‹ì€ ê°œì¸ì˜ ì„±ê²©ê³¼ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ ìƒê°ì˜ ê³¼ì • í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) íŒ€ì› ë˜ëŠ” í˜‘ì—…ìì˜ ë¬¸ì œ ë‚˜ë¥¼ í¬ìƒí•´ì„œ ì¡°ì§ì„ ìœ„í•´ í—Œì‹ í•œ ë¶€ë¶„ ë‚˜ì˜ ê³ ë¯¼, ê²°ì •, í–‰ë™ì˜ ì´ìœ  ì¡°ì§ì›ë“¤ì—ê²Œ ì¤€ ì˜í–¥ë ¥ ê²°ê³¼ í¬ë¶€ ê¸°íƒ€ ì—­ëŸ‰| ì¹˜ë°€í•¨ |ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ ì˜ˆìƒí•˜ì—¬ ëŒ€ë¹„í•œ ê²½í—˜ (ê¼¼ê¼¼í•¨, ì¹˜ë°€í•¨, ê³„íšë ¥, ê¸°íšë ¥) â†’ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ í”ŒëœA / í”ŒëœB / í”ŒëœC ë¥¼ ì„¸ì› ë˜ ê²½í—˜ ì„ í–‰ì¡°ê±´ ë¬¸ì œ ìƒí™©ì„ ì˜ˆìƒ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ì— ëŒ€í•œ ì¤€ë¹„ ê·¸ ì¤‘ í•œ ê°€ì§€ ìƒí™©ì´ ë°œìƒí•˜ì—¬ ì ìš© í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ì•¡ì…˜ ë°œìƒ ì§ì „ì˜ ìƒí™© í”ŒëœA, í”ŒëœB, í”ŒëœCë¥¼ ì„¸ìš°ê³  ê·¸ ì¤‘ í•˜ë‚˜ê°€ ë°œìƒ ê²°ê³¼ í¬ë¶€ | ìœ¤ë¦¬ |ê³¼ê±°ì˜ ê²½í—˜ìœ¼ë¡œ ë¯¸ë˜ë¥¼ ì¶”ì¸¡í•  ìˆ˜ ì—†ëŠ” ìœ ì¼í•œ ì—­ëŸ‰ â†’ ê·¸ëƒ¥ ë¬¼ì–´ë³´ëŠ” ì‡¼ìœˆë„ ë¬¸í•­ ìœ í˜¹ì— ë¹ ì¡ŒëŠ”ë° ê·¹ë³µí•œ ì¼€ì´ìŠ¤ ìœ í˜¹ì— ë¹ ì¡Œë‹¤ê°€ ë°˜ì„±í•œ ì¼€ì´ìŠ¤ íƒ€ì¸ì´ ì˜ëª»í•œ ì¼€ì´ìŠ¤ (ë°˜ë©´ êµì‚¬) í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ìƒí™© ë…¸ë ¥(í¬ìƒ) ì˜ˆìƒì¹˜ ëª»í•œ ì¥ì• ë¬¼ì„ ê·¹ë³µí•œ ê²½í—˜ë„ í¬ìƒìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ ê²°ê³¼ í¬ë¶€","categories":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"}],"tags":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ìì†Œì„œ","slug":"ìì†Œì„œ","permalink":"http://gonekng.github.io/tags/%EC%9E%90%EC%86%8C%EC%84%9C/"}],"author":"Jiwon Kang"},{"title":"ìì†Œì„œ TIP (2)","slug":"etc/ìì†Œì„œ TIP 2","date":"2022-12-08T14:52:11.000Z","updated":"2022-12-08T15:29:30.712Z","comments":true,"path":"2022/12/08/etc/ìì†Œì„œ TIP 2/","link":"","permalink":"http://gonekng.github.io/2022/12/08/etc/%EC%9E%90%EC%86%8C%EC%84%9C%20TIP%202/","excerpt":"","text":"ì¶œì²˜ : Youtube AND(ì¸ì‹¸ë‹´ë‹¹ì) ì±„ë„ ì„±ì¥ê³¼ì •ğŸ“Œ ì„±ì¥ê³¼ì • ê·¸ ìì²´ë³´ë‹¤, ì§€ì›ìì˜ ì—­ëŸ‰ì— ëŒ€í•œ ê·¼ê±°ë¥¼ ì•Œê³ ì í•˜ëŠ” ì§ˆë¬¸ í•µì‹¬ í¬ì¸íŠ¸ ì—­ëŸ‰ì´ ì„±ì¥ëë‹¤. 2) ê°€ì¹˜ê´€ì˜ ì„±ì¥ì„ í†µí•˜ì—¬ ì—­ëŸ‰ì´ ì„±ì¥ëë‹¤. â†’ ë‚˜ì˜ ì„±ì¥ê³¼ì •ê³¼ ê²½í—˜ì€ â€˜OOO ì§ë¬´ì— ê°€ì¥ ì í•©í•œ ì‚¬ëŒâ€™ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì—ˆë‹¤. Ver 1. í•µì‹¬ ì—­ëŸ‰ ì¤‘ì‹¬ ì§ë¬´ í•µì‹¬ ì—­ëŸ‰ ì§€ì› ì§ë¬´ì˜ í•µì‹¬ì—­ëŸ‰ì´ ê²½í—˜1, ê²½í—˜2ë¥¼ í†µí•´ì„œ ê°•ì ì´ ë˜ì—ˆë‹¤. ê²½í—˜1 and ê²½í—˜2 ë‚˜ì˜ ê°•ì ì˜ ê·¼ê±°ë¡œ ì œì‹œí•  ìˆ˜ ìˆëŠ” ê²½í—˜ì„ ìƒí™©, ì•¡ì…˜, ê²°ê³¼ë¡œ ì œì‹œ ë¯¸ë˜ì˜ í¬ë¶€ í¬ë¶€ë¡œ ë§ˆë¬´ë¦¬ Ver 2. ê°€ì¹˜ê´€ ì¤‘ì‹¬ ê°€ì¹˜ê´€ ë¬¸êµ¬ ì„¤ì • ë‹¨ì–´ ë˜ëŠ” ë¬¸ì¥ìœ¼ë¡œ ì‘ì„± ê°€ì¹˜ê´€ í˜•ì„± ê³„ê¸° ì‹¤íŒ¨í–ˆë˜ ê²½í—˜, ê°€ì¥ í˜ë“¤ì—ˆë˜ ê²½í—˜, ì‹¤ìˆ˜í–ˆë˜ ê²½í—˜ ë“±ì„ í†µí•´ ì–»ì€ ê°€ì¹˜ê´€ ê°€ì¹˜ê´€ â†’ ì—­ëŸ‰ ì—­ëŸ‰ì„ í¼ì¹œ ê²½í—˜ ë¯¸ë˜ì˜ í¬ë¶€ ì§ë¬´ì™€ ì—°ê²°ì‹œì¼œ í¬ë¶€ë¥¼ ë°í˜ ex) ì €ëŠ” â€œë°”ëŒì´ ë¶ˆì§€ ì•Šìœ¼ë©´ ë…¸ë¥¼ ì €ì–´ë¼â€ë¼ëŠ” ê°€ì¹˜ê´€ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ° ì‹¤í–‰ë ¥ì´ ìˆìŠµë‹ˆë‹¤.ì œê°€ ëŒ€í•™êµ ë•Œ MTë¥¼ ê°€ì„œ ëˆ„êµ°ê°€í•œí…Œ ì´ëŸ° ì´ì•¼ê¸°ë¥¼ ë“¤ì—ˆëŠ”ë°ìš”.ê·¸ë•Œ ì œ ë¶€ì¡±í•œ ì ì— ëŒ€í•´ì„œ ê¹¨ë‹¬ì•˜ê³  ê·¸ê²ƒë“¤ì´ ì œ ì‚¶ì— ë…¹ì•„ì ¸ì„œ ì´ëŸ° ì—­ëŸ‰ìœ¼ë¡œ ë°œì „ë˜ì—ˆìŠµë‹ˆë‹¤.ì´ëŸ¬í•œ ì‹¤í–‰ë ¥ì€ ì´ëŸ¬í•œ ê²½í—˜ë“¤ ì†ì—ì„œ ì±„ìš©íŒ€ì¥ì„ í•˜ë©´ì„œ ì–´ë–¤ ì„±ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.ì´ëŸ° ì‹¤í–‰ë ¥ì„ í†µí•´ì„œ ì´ ì§ë¬´ë¥¼ í•˜ë©´ì„œ ì–´ë–»ê²Œ ë” ì„±ê³¼ë¥¼ ë‚´ë³´ê² ìŠµë‹ˆë‹¤. ì„±ê²©ì˜ ì¥ë‹¨ì ğŸ“Œ ì„±ê²©ì˜ ì¥ë‹¨ì ì„ í†µí•´ ì—­ëŸ‰ì„ ìœ ì¶”í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ìƒí™©ì—ì„œ ê¸ì •ì ì´ë©´ ê°•ì /ì¥ì , ë¶€ì •ì ì´ë©´ ì•½ì /ë‹¨ì ì´ ëœë‹¤. í•µì‹¬ í¬ì¸íŠ¸ë‚˜ëŠ” ì†”ì§íˆ ì´ ì§ë¬´ì™€ ì •ë§ ì˜ ë§ëŠ”ë‹¤. ì¥ì ì€ ë¬¼ë¡  ë‹¨ì ë§ˆì €ë„ ì˜ ë§ëŠ”ë‹¤. í…œí”Œë¦¿ ì„±ê²©ì˜ ì¥ì  ì¥ì ì´ ë°œíœ˜ë˜ì—ˆë˜ ì‚¬ë¡€ ì„±ê²©ì˜ ë‹¨ì  ì„±ê²©ì˜ ë‹¨ì ì—ì„œ ë°œìƒí•˜ëŠ” ë¬¸ì œì  ë° ë³´ì™„í•˜ëŠ” ë…¸ë ¥ ë‹¨ì ì€ ì ˆëŒ€ ì™„ë²½í•˜ê²Œ ê°œì„ ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ê·¸ ìì²´ë¥¼ ê°œì„ í•œë‹¤ê³  í•˜ì§€ ë§ê¸° ë‹¨ì ì´ í•´ë‹¹ ì§ë¬´ì—ì„œ ê°€ì§€ëŠ” ë¬¸ì œì ì„ ì¥ì ì„ í†µí•´ ë³´ì™„í•œë‹¤ëŠ” ë°©í–¥ì´ ì˜¤íˆë ¤ ë‚«ë‹¤ ex) ì €ì˜ ì¥ì ì€ ì¶”ì§„ë ¥ì…ë‹ˆë‹¤.ì €ì˜ ë‹¨ì ì€ ë‹¤ì†Œ ê¼¼ê¼¼í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ê³„íšì„ ì„¸ìš°ë©´ ëˆ„ë½ë˜ëŠ” ê²ƒë“¤ì´ ê°€ë” ë°œìƒí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°€ë” ë°œìƒí•œ ê²ƒì„ ë³´ì™„í•˜ë ¤ê³  ë…¸ë ¥í–ˆì§€ë§Œ ì˜ ê°œì„ ë˜ì§€ëŠ” ì•Šì•˜ìŠµë‹ˆë‹¤.ê·¸ë˜ì„œ ì €ëŠ” ì €ì˜ ê°•ì ì„ í™œìš©í•´ì„œ ë‚¨ë“¤ë³´ë‹¤ ë¹ ë¥´ê²Œ ì‹¤í–‰í•˜ê³  ëª‡ë²ˆ ë” ë°˜ë³µí•¨ìœ¼ë¡œì¨ ì™„ì„±ë„ë¥¼ ë†’ì—¬ê°€ëŠ” ì „ëµìœ¼ë¡œ ì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ex) ì €ì˜ ì¥ì ì€ ì‚¬êµì„±ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ê³¼ì˜ íŒ€ì›Œí¬ë¥¼ í†µí•´ ì„±ê³¼ë¥¼ ëƒˆìŠµë‹ˆë‹¤.ì €ì˜ ë‹¨ì ì€ ìš°ìœ ë¶€ë‹¨í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‹¤ë³´ë‹ˆ ì–´ë– í•œ íŠ¹ì • ê²°ì •ì´ ëŠ¦ì–´ì ¸ ì•ˆ ì¢‹ì€ ê²°ê³¼ë¡œ ì´ì–´ì§€ê¸°ë„ í–ˆìŠµë‹ˆë‹¤. ë¹ ë¥¸ ê²°ì •ì„ ìœ„í•´ ë…¸ë ¥í•˜ì§€ë§Œ ë‹¤ì–‘í•œ ê±±ì •ìœ¼ë¡œ ì¸í•´ ì‰½ê²Œ ê°œì„ ë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.ì €ëŠ” ì´ëŸ¬í•œ ë‹¨ì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì €ì˜ ê°•ì ì¸ ì‚¬êµì„±ì„ ë°œíœ˜í•˜ì—¬ ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ì—ê²Œ ì¡°ì–¸ì„ ë“¤ìŒìœ¼ë¡œì¨ ë¹ ë¥¸ ì˜ì‚¬ê²°ì •ì„ ë°©í•´í•˜ëŠ” ì—¬ëŸ¬ ë¬¸ì œì ë“¤ì„ í•´ì†Œí•˜ê³  ê²°ì •í•˜ë ¤ê³  ë…¸ë ¥í•˜ê³  ìˆê³ , ì‹¤ì œë¡œ ì˜ì‚¬ê²°ì •ì´ ë”ìš±ë” ë¹¨ë¼ì¡ŒìŠµë‹ˆë‹¤. ì„±ê²© ë‹¨ì–´ ì˜¤ì§ - ë¼ìš´ì§€ - ì•„ì¹´ì´ë¸Œ - ì§ë¬´ ì°¾ê¸° ê°•ì˜ìë£Œ - Cross Checking ì„±ê²© ë¬¸ì¥ ì¡ì½”ë¦¬ì•„ - í“¨ì²˜ë© - ì·¨ì—… ì„±ê³µ íˆ´ - ìì†Œì„œ ìë™ì™„ì„± - ì„±ê²©ì˜ ì¥ë‹¨ì  ì„±ê³¼ì§€í–¥ì„±ğŸ“Œ ëª©í‘œ ë‹¬ì„± ëŠ¥ë ¥, ì—´ì •, ì‹¤í–‰ë ¥, ì¶”ì§„ë ¥, ë„ì „ê²½í—˜, ì‹¤íŒ¨/ê·¹ë³µê²½í—˜ â†’ ë‹µë³€ í•˜ë‚˜ë¡œ ì„±ê³¼ì§€í–¥ì„±ì„ íŒë‹¨í•˜ëŠ” ëª¨ë“  ì§ˆë¬¸ì— ëŒ€ì‘ ê°€ëŠ¥ | ëª©í‘œ ë‹¬ì„± ëŠ¥ë ¥ |ëª©í‘œ ë‹¬ì„± ëŠ¥ë ¥ = ì¥ì• ë¬¼ + ì„±ê³µ â†’ ë‚˜ëŠ” ì–´ë– í•œ ì¥ì• ë¬¼ë„ ê·¹ë³µí•˜ê³  ëª©í‘œí•œ ë°”ë¥¼ ì´ë£¨ëŠ” ì‚¬ëŒì´ë‹¤. ì„ í–‰ì¡°ê±´ ëª…í™•í•˜ê³  ë†’ì€ ëª©í‘œ ì˜ˆìƒí•˜ì§€ ëª»í•œ ì¥ì• ë¬¼ (í¬ê¸°í•˜ê³  ì‹¶ì€ ìƒí™©) ëª©í‘œ ë‹¬ì„± í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ex) ë†’ì€ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ì„œëŠ” OOOì„ ~í•´ì•¼ í•œë‹¤ê³  ìƒê°í–ˆê³ , ì´ëŸ¬í•œ ê²½í—˜ì„ í†µí•´ ì´ëŸ¬í•œ ëª©í‘œë¥¼ ë‹¬ì„±í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì•¡ì…˜ ë°œìƒ ì§ì „ì˜ ìƒí™©ê³¼ ëª©í‘œ ëª©í‘œì˜ ë†’ê³  ë‚®ì€ ì •ë„ëŠ” ìƒëŒ€ì ì¸ ê²ƒ â†’ ë†’ê²Œ ìŒ“ì•„ ì˜¬ë¦¬ê±°ë‚˜, ì£¼ë³€ì„ ê¹Šê²Œ íŒŒê±°ë‚˜ ëª©í‘œê°€ ë” ë†’ê²Œ ë³´ì´ëŠ” ë°©ë²• ì£¼ë³€ ì‚¬ëŒë“¤ì˜ ë¶€ì •ì ì¸ ë°˜ì‘ (í•˜ì§€ë§ˆ, ê·¸ë§Œí•´, ì•ˆë ê±°ì•¼, ì–´ë ¤ì›Œ ë“±ë“±) ì´ì „ì˜ ìƒí™©ì´ë‚˜ ì£¼ë³€ ì‚¬ëŒë“¤ì˜ ëª©í‘œì™€ ë¹„êµ (ì‘ë…„ë³´ë‹¤ 2ë°° ë†’ê²Œ, ë‚¨ë“¤ë³´ë‹¤ ì§§ì€ ê¸°ê°„ ë“±ë“±) ëª©í‘œ ë‹¬ì„±ì— í•„ìš”í•œ ì„¸ë¶€ ëª©í‘œë¥¼ ì„¤ì •í•˜ì—¬ ì¥ì• ë¬¼ê³¼ ì—°ê²° (OOì„ ìœ„í•´ì„œ ë°˜ë“œì‹œ OOì„ í•´ì•¼í•¨) ì¥ì• ë¬¼ â†’ ê·¹ë³µ ê²°ê³¼ í¬ë¶€ | ë„ì „ ê²½í—˜ |ë„ì „ ê²½í—˜ : ë‹¨ìˆœí•œ ì‹œë„ë‚˜ í–‰ìœ„ X, ì˜ˆìƒë˜ëŠ” ë¦¬ìŠ¤í¬ë¥¼ ê°ë‚´í•˜ê³  ì‹¤í–‰í–ˆë˜ ê²½í—˜ â†’ ë‚˜ëŠ” ì´ëŸ¬í•œ ë¦¬ìŠ¤í¬ê°€ ì˜ˆìƒë˜ì—ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ~ë¥¼ í¬ê¸°í•˜ê³  ì´ëŸ¬í•œ ë„ì „ì„ í–ˆë‹¤. í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ex) ë†’ì€ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ì„œëŠ” OOOì„ ~í•´ì•¼ í•œë‹¤ê³  ìƒê°í–ˆê³ , ì´ëŸ¬í•œ ê²½í—˜ì„ í†µí•´ ì´ëŸ¬í•œ ëª©í‘œë¥¼ ë‹¬ì„±í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ë„ì „ ìƒí™©ê³¼ ë¦¬ìŠ¤í¬ ì¥ì• ë¬¼ â†’ ê·¹ë³µ ê²°ê³¼ ë°°ìš´ì  í¬ë¶€ | ì‹¤íŒ¨ ê²½í—˜ |ì‹¤íŒ¨ ê²½í—˜ â‰  ì‹¤ìˆ˜ ê²½í—˜ - ì‹¤íŒ¨ : ìˆ˜í–‰ ì˜ì§€ê°€ ìˆëŠ” ìƒíƒœì—ì„œ ì˜ëª»ëœ ìƒí™© - ì‹¤ìˆ˜ : ìš°ì—°íˆ ì˜ëª»ëœ ìƒí™© (ë…¸ë ¥ì´ë‚˜ ì˜ì§€ì™€ ë¬´ê´€) ì„ í–‰ì¡°ê±´ ì£¼ì–´ì§„ ëª©í‘œê°€ í¼ ë„ì „ ê²½í—˜ ë‚´ê°€ ì„¸ìš´ ëª©í‘œë„ ê°€ëŠ¥ â€» ì‹¤íŒ¨í•œ ê²½í—˜ì´ ì—†ì„ ê²½ìš°, ëª©í‘œ ë‹¬ì„± ê²½í—˜ì—ì„œì˜ ëª©í‘œë¥¼ ë†’ì—¬ì„œ ì„œìˆ í•˜ê¸° í…œí”Œë¦¿ ì—­ëŸ‰ì„ í•œ ì¤„ë¡œ ìš”ì•½(ì¬ì •ì˜) ex) ë†’ì€ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ì„œëŠ” OOOì„ ~í•´ì•¼ í•œë‹¤ê³  ìƒê°í–ˆê³ , ì´ëŸ¬í•œ ê²½í—˜ì„ í†µí•´ ì´ëŸ¬í•œ ëª©í‘œë¥¼ ë‹¬ì„±í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. ì•¡ì…˜ ë°œìƒ ì§ì „ì˜ ìƒí™©ê³¼ ëª©í‘œ ì¥ì• ë¬¼ â†’ ê·¹ë³µ ì‹¤íŒ¨ â†’ ì›ì¸ ë¶„ì„ ê·¹ë³µ í¬ë¶€ ì…ì‚¬ í›„ í¬ë¶€ğŸ“Œ í•´ë‹¹ ì§ë¬´ì— ëŒ€í•´ ì œëŒ€ë¡œ ì•Œê³  ìˆëŠ”ì§€ ì•„ë‹Œì§€ íŒë‹¨í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ â†’ ë¯¿ê¸° ì–´ë µê² ì§€ë§Œ ë‚˜ëŠ” ì´ ì§ë¬´ë¥¼ ì˜ˆì „ë¶€í„° ê¿ˆê¿”ì™”ë‹¤ëŠ” ê²ƒì„ ì–´í•„ ì„ í–‰ì¡°ê±´ êµ¬ì²´ì„± (ìƒí™© ê°€ì •) ~í•  í…ë°, ~í•  ì¼ì´ ìƒê¸°ëŠ”ë° ë“±ë“± ì§ë¬´ ì§€ì‹ &#x2F; CDP &#x2F; í•«ì´ìŠˆ í˜„ì¬ì™€ ë¯¸ë˜ì˜ ë°¸ëŸ°ìŠ¤ â€» 10ë…„ ë’¤ì— ë­í• ê±°ì—ìš”? &#x3D; ë„ˆê°€ ì´ ì—…ê³„ 10ë…„ì°¨(ìµœì „ì„±ê¸°)ê°€ ë˜ë©´ ë­˜ í•˜ê³  ì‹¶ë‹ˆ? Ver 1. ì¥ê¸° í…œí”Œë¦¿ (ì§ë¬´ ë¶„ì„ O) ìµœì¢… Goal &#x2F; í•˜ê³  ì‹¶ì€ ì¼ í•´ë‹¹ ì§ë¬´ì—ì„œ ë„ë‹¬í•˜ê³  ì‹¶ì€ ì§ì±…, ê·¸ ì§ì±…ì— ë„ë‹¬í•˜ë©´ í•˜ê³  ì‹¶ì€ ì¼ Në…„ ì°¨ì˜ í¬ë¶€ &#x2F; ë‹¨ê³„ë³„ ëª©í‘œ ìµœì¢… Goalì— ë„ë‹¬í•˜ê¸° ìœ„í•œ ë‹¨ê³„, ê·¸ë¦¬ê³  ë³¸ì¸ì´ ê°€ê³  ì‹¶ì€ CDP ë§¡ê²Œ ë˜ëŠ” ì¼ + í•˜ê³  ì‹¶ì€ ì¼ ë§¡ê²Œ ë˜ëŠ” ì¼ + ì–´ë ¤ì›€ + ê·¹ë³µ ë°©ë²• Ver 2. ë‹¨ê¸° í…œí”Œë¦¿ (ì§ë¬´ ë¶„ì„ X) ìµœì¢… Goal &#x2F; í•˜ê³  ì‹¶ì€ ì¼ í•´ë‹¹ ì§ë¬´ì—ì„œ ë„ë‹¬í•˜ê³  ì‹¶ì€ ì§ì±…, ê·¸ ì§ì±…ì— ë„ë‹¬í•˜ë©´ í•˜ê³  ì‹¶ì€ ì¼ ë¬¸ì œ í•´ê²° í˜„ì¬ ì§ë¬´ &#x2F; ì‚°ì—…êµ° &#x2F; íšŒì‚¬ì—ì„œ ê²ªê³  ìˆëŠ” ì–´ë ¤ì›€ì„ í•´ê²°í•˜ê² ë‹¤. â€» ë‚´ê°€ ì•Œê³  ìˆëŠ” ê²ƒê³¼ ëª¨ë¥´ê³  ìˆëŠ” ê²ƒì˜ ì°¨ì´ë¥¼ ëª…í™•í•˜ê²Œ ì¸ì§€í•˜ëŠ” ê²ƒì´ ë„ì›€ì´ ë  ìˆ˜ ìˆìŒex) í•™êµì—ì„œëŠ” Aë¥¼ ë°°ì› ëŠ”ë°, íšŒì‚¬ ì‹¤ë¬´ì—ì„œëŠ” Bì™€ Cê¹Œì§€ í•„ìš”. ë”°ë¼ì„œ ë¶€ì¡±í•œ Bì™€ CëŠ” ì–´ë–»ê²Œ í•™ìŠµí•˜ê² ë‹¤.","categories":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"}],"tags":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ìì†Œì„œ","slug":"ìì†Œì„œ","permalink":"http://gonekng.github.io/tags/%EC%9E%90%EC%86%8C%EC%84%9C/"}],"author":"Jiwon Kang"},{"title":"ìì†Œì„œ TIP (1)","slug":"etc/ìì†Œì„œ TIP 1","date":"2022-12-08T14:31:51.000Z","updated":"2022-12-08T15:21:54.583Z","comments":true,"path":"2022/12/08/etc/ìì†Œì„œ TIP 1/","link":"","permalink":"http://gonekng.github.io/2022/12/08/etc/%EC%9E%90%EC%86%8C%EC%84%9C%20TIP%201/","excerpt":"","text":"ì¶œì²˜ : Youtube AND(ì¸ì‹¸ë‹´ë‹¹ì) ì±„ë„ ì§€ì›ë™ê¸°ğŸ“Œ ìš°ë¦¬ì˜ ì •ì²´ì„± : êµ¬ì§ì = ì¼í•˜ëŠ” ì‚¬ëŒ â†’ íšŒì‚¬ì™€ êµ¬ì§ìì˜ êµì§‘í•©ì€ ëˆì´ ì•„ë‹ˆë¼ ì¼! â†’ ë‚˜ëŠ” ì¼ì„ í•˜ê¸° ìœ„í•´ ì§€ì›í•˜ê³ , íšŒì‚¬ëŠ” ì¼ì„ ì‹œí‚¤ê¸° ìœ„í•´ ì±„ìš©í•œë‹¤. í•µì‹¬ í¬ì¸íŠ¸ì´ íšŒì‚¬ë¥¼ ì¢‹ì•„í•´ì„œ, ê´€ì‹¬ì´ ìˆì–´ì„œ, ë§ˆìŒì— ë“¤ì–´ì„œ ì§€ì›í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë‚´ê°€ ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” &#x2F; ì„±ê³µì‹œí‚¬ ìˆ˜ ìˆëŠ” &#x2F; ì™„ì„±í•  ìˆ˜ ìˆëŠ” ì´ ì¼ì„ í•˜ê¸° ìœ„í•´ì„œ ì§€ì›í•©ë‹ˆë‹¤. ì„ í–‰ì¡°ê±´ ì§ë¬´ ì§€ì›ë™ê¸° (ì „ë¬¸ ì—­ëŸ‰) ì‚°ì—…êµ° ì§€ì›ë™ê¸° (ì „ë¬¸ ì§€ì‹) íšŒì‚¬ ì§€ì›ë™ê¸° Ver 1. ìœ ì‚¬ ê²½í—˜ì´ ìˆëŠ” ê²½ìš° ~ì„ ì™„ì„±&#x2F;ì„±ê³µ&#x2F;ê¸°ì—¬í•´ë³´ê³  ì‹¶ë‹¤. (ìš”ì•½) í•´ë‹¹ ì§ë¬´ì˜ ê³¼ì—…, ë¬¸ì œ, í•´ê²°ë°©ë²•ì— ë”°ë¼ ì²«ì¤„ì— ëª…ì‹œí•˜ê¸° ex) ì €ëŠ” ì¸ì‹¸ë‹´ë‹¹ì PDê°€ ë˜ì–´ì„œ ì·¨ì¤€ìƒë“¤ì—ê²Œ ì˜ìƒì„ ì œê³µí•  ë•Œ ì‹¤ì§ˆì ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•œ ì •ë³´ì˜ ì½˜í…ì¸ ë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œ í˜„ì§ìë“¤ì„ ëª¨ì…”ì˜¤ê³  í˜„ì§ìë“¤ê³¼ ëŒ€í™”í•˜ëŠ” ì½˜í…ì¸ ë¥¼ ë§Œë“¤ì–´ì„œ êµ¬ë…ì 100ë§Œì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤. ê´€ì‹¬ì„ ê°–ê²Œ ëœ ë°°ê²½ (ì‚°ì—… &#x2F; ì§ë¬´) ê·¸ íšŒì‚¬ë¥¼ ì–´ë–»ê²Œ ì¸ì§€í•˜ê²Œ ë˜ì—ˆëŠ”ê°€ ë‹¨ìˆœíˆ ì œí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•´ë³¸ ê²½í—˜ X êµìˆ˜ë‹˜, ì¹œêµ¬, ê°€ì¡±, ì„ ë°° ë“±ë“± í‰ë²”í•œ ê²½ë¡œë¼ë„ ìƒê´€ ì—†ìŒ ì´í›„ì— ì„œìˆ í•  íŠ¹ì • ê²½í—˜ê³¼ ì—°ê²°í•˜ê¸° ëˆì„ ë²Œê¸° ìœ„í•œ ì†Œê·¹ì  ê²½í—˜ì„ íšŒì‚¬ì— ëŒ€í•´ ë” ì•Œì•„ë³´ê¸° ìœ„í•œ ì ê·¹ì  ê²½í—˜ìœ¼ë¡œ ë§Œë“¤ê¸° ex) ìˆ˜ì—… ì‹œê°„ì— êµìˆ˜ë‹˜ê³¼ ìœ í†µ ì‚°ì—…ì— ëŒ€í•œ ì¡°ì‚¬ë¥¼ í•˜ë‹¤ë³´ë‹ˆ BGF ë¦¬í…Œì¼ì˜ ì˜ì—…ì´ìµë¥ ê³¼ ë°œì „ ê°€ëŠ¥ì„±ì— ëŒ€í•´ ê´€ì‹¬ì„ ê°–ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê´€ì‹¬ ë•Œë¬¸ì— ë” ì•Œì•„ë³´ê³ ì GS25 í¸ì˜ì ì—ì„œ ì•„ë¥´ë°”ì´íŠ¸ë¥¼ í–ˆìŠµë‹ˆë‹¤. ì§ë¬´ &#x2F; ì‚°ì—…êµ° ì§€ì›ë™ê¸° ê´€ë ¨ ì „ë¬¸ ì§€ì‹ íšŒì‚¬ ì§€ì›ë™ê¸° í¬ë¶€ Ver 2. ìœ ì‚¬ ê²½í—˜ì´ ì—†ì§€ë§Œ ì‹œê°„ì  ì—¬ìœ ê°€ ìˆëŠ” ê²½ìš° â†’ ì‚°ì—… ë¶„ì„ ë° ê¸°ì—… ë¶„ì„ í•„ìˆ˜â€œ ë„ˆí¬ê°€ ì˜í•˜ê³  ìˆëŠ” ê²ƒì„ ë‚´ê°€ ~ìœ¼ë¡œì„œ ë” ì˜ë˜ê²Œ í•  ìˆ˜ ìˆë‹¤. â€ ì´ íšŒì‚¬ì—ëŠ” ì–´ë– í•œ ê°•ì ì´ ìˆê³ , ë‚˜ì˜ ì§ë¬´ë¡œì„œ ê·¸ ê°•ì ì— ì–´ë–¤ ë„ì›€ì„ ì£¼ê³  ì‹¶ì–´ì„œ ì§€ì›í•©ë‹ˆë‹¤. ~ì„ ì™„ì„±&#x2F;ì„±ê³µ&#x2F;ê¸°ì—¬í•´ë³´ê³  ì‹¶ë‹¤. (ìš”ì•½) í•´ë‹¹ ì§ë¬´ì˜ ê³¼ì—…, ë¬¸ì œ, í•´ê²°ë°©ë²•ì— ë”°ë¼ ì²«ì¤„ì— ëª…ì‹œí•˜ê¸° íšŒì‚¬ì˜ ê°•ì  &amp; íšŒì‚¬ê°€ ì˜í•˜ê³  ìˆëŠ” ì  ê²½ìŸì‚¬ì— ë¹„í•´ ê°€ì§€ê³  ìˆëŠ” ê°•ì ì´ë‚˜ ì°¨ë³„ì„± ex) OO íšŒì‚¬ëŠ” í˜„ì¬ í•´ë‹¹ ë¶€ë¶„ì—ì„œ ì´ëŸ¬í•œ ë°©ë²•ìœ¼ë¡œ ì•ì„œ ë‚˜ê°€ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ê°€ ì˜í•  ìˆ˜ ìˆëŠ” ì´ìœ  (ê²½í—˜1, ê²½í—˜2) ì§€ì›í•œ ì§ë¬´ë¡œì„œ ê·¸ ê°•ì ì— ê¸°ì—¬í•  ìˆ˜ ìˆëŠ” ì—­ëŸ‰ 1~2ê°€ì§€ ì–´í•„ í•´ë‹¹ ì—­ëŸ‰ì„ ë°œê²¬ í˜¹ì€ ë°œíœ˜í•œ ê²½í—˜ 1~2ê°€ì§€ ì–´í•„ ì‚°ì—…êµ°ì— ëŒ€í•œ ê´€ì‹¬ì‚¬ì— ë”°ë¥¸ í™œë™ ë° ê²½í—˜(ìê²©ì¦, êµìœ¡ ìˆ˜ë£Œ, ë°•ëŒíšŒ ì°¸ê°€ ë“±) ex) OO íšŒì‚¬ëŠ” ì´ ì œí’ˆì„ ê°€ì¥ ê°€ë³ê²Œ ë§Œë“ ë‹¤ëŠ” ê°•ì ì´ ìˆëŠ”ë° (ë§ˆì¼€íŒ…) ì´ëŸ¬í•œ íŠ¹ì§•ì„ B2C ê³ ê°ë“¤ì—ê²Œ ì–´ë– í•œ ë°©ì‹ì„ í†µí•´ì„œ ë” ì˜ ì•Œë¦¬ê³  ì‹¶ìŠµë‹ˆë‹¤. (ì¸ì‚¬) ì´ëŸ¬í•œ íŠ¹ì§•ì„ ìœ„í•´ì„œëŠ”R&amp;D ì—­ëŸ‰ì´ ê°€ì¥ ì¤‘ìš”í•œë° ê·¸ë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ë§Œë“œëŠ” ë°ì— ê¸°ì—¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. í¬ë¶€ Ver 3. ìœ ì‚¬ ê²½í—˜ë„ ì—†ê³  ì‹œê°„ì  ì—¬ìœ ë„ ì—†ëŠ” ê²½ìš° â†’ ì§ë¬´ ì§€ì›ë™ê¸°ë¥¼ ì‘ì„±í•œë‹¤ê³  ìƒê°í•˜ê¸° ~ì„ ì™„ì„±&#x2F;ì„±ê³µ&#x2F;ë„ì „í•´ë³´ê³  ì‹¶ë‹¤. (ìš”ì•½) í•´ë‹¹ ì§ë¬´ì˜ ê³¼ì—…, ë¬¸ì œ, í•´ê²°ë°©ë²•ì— ë”°ë¼ ì²«ì¤„ì— ëª…ì‹œí•˜ê¸° í•´ë‹¹ ì§ë¬´ì˜ ë¬¸ì œ í•´ë‹¹ ì§ë¬´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë™ì•ˆ í•´ê²°í•´ì•¼ í•  ë¬¸ì œ ex) OO ì§ë¬´ëŠ” OO ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ë©°, ì´ë•Œ ì–´ë– ì–´ë– í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ë‚´ê°€ ì˜í•  ìˆ˜ ìˆëŠ” ì´ìœ  (ê²½í—˜1, ê²½í—˜2) í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ ì—­ëŸ‰ 1~2ê°€ì§€ ì–´í•„ í•´ë‹¹ ì—­ëŸ‰ì„ ë°œê²¬ í˜¹ì€ ë°œíœ˜í•œ ê²½í—˜ 1~2ê°€ì§€ ì–´í•„ Ver 4. íŠ¹ì • íšŒì‚¬ë¥¼ ê°•ì¡°í•˜ê³  ì‹¶ì€ ê²½ìš° ~ì„ ì™„ì„±&#x2F;ì„±ê³µ&#x2F;ë„ì „í•´ë³´ê³  ì‹¶ë‹¤. (ìš”ì•½) í•´ë‹¹ ì§ë¬´ì˜ ê³¼ì—…, ë¬¸ì œ, í•´ê²°ë°©ë²•ì— ë”°ë¼ ì²«ì¤„ì— ëª…ì‹œí•˜ê¸° íšŒì‚¬ì˜ ë¹„ì „ ë° ì¸ì¬ìƒ íšŒì‚¬ì˜ ì¸ì¬ìƒì„ ë°”ë¡œ ë‚´ ì—­ëŸ‰ê³¼ ì—°ê²°ì‹œí‚¤ì§€ ë§ê¸° ì–´ë– í•œ ì¸ì¬ìƒì´ ê·¸ íšŒì‚¬ì˜ ì–´ë– í•œ ì‚¬ì—…ì— ì–´ë–»ê²Œ ë°˜ì˜ë˜ê³  ìˆëŠ”ì§€ ì—°ê²° ex) OO íšŒì‚¬ëŠ” ì´ëŸ¬í•œ ì¸ì¬ìƒì„ ê°€ì§€ê³  ìˆëŠ”ë°, í˜„ì¬ ì´ë£¨ì–´ì§€ê³  ìˆëŠ” ì–´ë– í•œ ì‚¬ì—… ë°©í–¥ì— ë…¹ì—¬ì ¸ ìˆë‹¤ëŠ” ê²ƒì„ ëŠê¼ˆìŠµë‹ˆë‹¤. ì € ë˜í•œ ì´ëŸ¬í•œ ê°€ì¹˜ê´€ì„ ê°€ì§€ê³  ìˆê¸° ë–„ë¬¸ì— ì´ íšŒì‚¬ë¥¼ ì„ íƒí•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ê°€ ì˜í•  ìˆ˜ ìˆëŠ” ì´ìœ  (ê²½í—˜1, ê²½í—˜2) í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•œ ì—­ëŸ‰ 1~2ê°€ì§€ ì–´í•„ í•´ë‹¹ ì—­ëŸ‰ì„ ë°œê²¬ í˜¹ì€ ë°œíœ˜í•œ ê²½í—˜ 1~2ê°€ì§€ ì–´í•„","categories":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"}],"tags":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ìì†Œì„œ","slug":"ìì†Œì„œ","permalink":"http://gonekng.github.io/tags/%EC%9E%90%EC%86%8C%EC%84%9C/"}],"author":"Jiwon Kang"},{"title":"1ë¶„ ìê¸°ì†Œê°œ TIP","slug":"etc/1ë¶„ ìê¸°ì†Œê°œ TIP","date":"2022-12-07T02:18:25.000Z","updated":"2022-12-08T14:32:31.990Z","comments":true,"path":"2022/12/07/etc/1ë¶„ ìê¸°ì†Œê°œ TIP/","link":"","permalink":"http://gonekng.github.io/2022/12/07/etc/1%EB%B6%84%20%EC%9E%90%EA%B8%B0%EC%86%8C%EA%B0%9C%20TIP/","excerpt":"","text":"ì¶œì²˜ : Youtube AND(ì¸ì‹¸ë‹´ë‹¹ì) ì±„ë„ í•µì‹¬ í¬ì¸íŠ¸ì§„ì •ì„± + íŠ¹ì´ ê²½í—˜ + ì–´ê·¸ë¡œ â†’ ì¶”ê°€ ì§ˆë¬¸ì„ ëŒì–´ë‚´ë©´ ì„±ê³µ 4ê°€ì§€ ë¸”ë¡ ë‚˜ëŠ” ~~í•œ ì‚¬ëŒì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì„íŒ©íŠ¸ê°€ ì—†ìœ¼ë©´ ë’·ë¶€ë¶„ì€ ê·€ì— ì˜ ì•ˆ ë“¤ì–´ì˜´ ì˜ˆì‹œ ì €ëŠ” êµ­í† ëŒ€ì¥ì •ì„ ìŠ¤ìŠ¤ë¡œ ë§Œë“  OOOì…ë‹ˆë‹¤. ì €ëŠ” ë¬´ì—‡ì´ë“  í•˜ë©´ 5ë…„ ì´ìƒ í•˜ëŠ” ëˆê¸°ë¥¼ ê°€ì§„ OOOì…ë‹ˆë‹¤. ë‚˜ì˜ íŠ¹ì§•, ì„±ê²©, ê°€ì¹˜ê´€, ì£¼ë³€ì˜ í‰ê°€, ì¥ë‹¨ì , íŠ¹ì´ ê²½í—˜, ì„±ê³µ ê²½í—˜ ë“±ë“± ë§ˆì§€ë§‰ì—ëŠ” ê¼­ ì§ë¬´ì™€ ì—°ê²°ì‹œì¼œì•¼ í•¨ ë‚˜ë¥¼ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ë‹¨ì–´ë¥¼ ì°¾ì•„ë³¸ë‹¤ ë‚˜ì˜ ê²½í—˜ ê²½í—˜ A &#x2F; ê²½í—˜ A, ê²½í—˜ B &#x2F; ê²½í—˜ A, ì§€ì‹ ê³µë¶€ B ì¤‘ìš”í•œ í¬ì¸íŠ¸ë¥¼ ì‚´ì§ ë¹¼ê¸° (ìƒí™© ì•¡ì…˜ ê²°ê³¼ì—ì„œ ì•¡ì…˜ì„ ë¹¼ê¸°) ë‚´ ê²½í—˜ ìì²´ë¥¼ ë“œëŸ¬ë‚´ê¸°ë³´ë‹¤ëŠ” ê´€ì‹¬ì„ ëŒê³  ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ì–´ê°€ê¸° ìœ„í•œ ëª©ì  ê¿ˆë³´ë‹¤ í•´ëª½ ìˆ«ìì ì¸ ì¸¡ë©´ì„ ì‚´ì§ ë„£ì–´ì£¼ë©´ ì¡°ê¸ˆ ë” ì˜ ë“¤ë¦¼ (ë»¥íŠ€ê¸° ê¸ˆì§€) ì§„ì •ì„± ê°•ì¡°í•˜ëŠ” ìš”ì•½ ì˜ˆì‹œ : â€œì œê°€ ì´ëŸ¬í•œ ê²½í—˜ì„ í•  ìˆ˜ ìˆì—ˆë˜ ê²ƒì€ ì €ì˜ ì´ëŸ° ìºë¦­í„° ë•Œë¬¸ì´ì—ˆìŠµë‹ˆë‹¤.â€ ë‚˜ì˜ ìºë¦­í„°ì™€ ì„±ê³µ ê²½í—˜ì„ ì´ì–´ì£¼ëŠ” ì—­í•  ë‚˜ì˜ í¬ë¶€ í•´ë‹¹ ì—­ëŸ‰ì´ ì–´ë–»ê²Œ ê·¸ ì§ë¬´ì—ì„œ ì ìš©ë  ê²ƒì¸ì§€ ì„œìˆ  5ê°€ì§€ ë°©ë²• ê°€ì¹˜ê´€ ì²«ë²ˆì§¸ ë¸”ë¡ì—ì„œ ê°€ì¹˜ê´€ê³¼ í•µì‹¬ ì—­ëŸ‰ì„ ì—°ê²°í•´ì£¼ê¸° íŠ¹ìƒ‰ ìˆëŠ” ê²½í—˜ ìœ ì‚¬ ê²½í—˜ ê´€ë ¨ ê²½í—˜ ìì²´ë¥¼ ì„œìˆ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í…ìŠ¤íŠ¸ë‚˜ ì˜ìƒìœ¼ë¡œ ì²´ë“í•  ìˆ˜ ì—†ëŠ”, ëª¸ìœ¼ë¡œ ê²ªì€ ë¶€ë¶„ì„ ì´ì•¼ê¸°í•¨ ê³µë¶€í–ˆë‹¤, ëŠê¼ˆë‹¤, ì²´í—˜í•´ë´¤ë‹¤, ë‹¤ë¥´ë‹¤ëŠ” ê±¸ ê¹¨ë‹¬ì•˜ë‹¤ ë“±ë“± ë² ì´ì§ ì—­ëŸ‰ ì§ë¬´ì—­ëŸ‰ê³¼ ë‹¤ë¥¸ ë² ì´ì§ ì—­ëŸ‰ (ë¶„ì„ë ¥, ì„±ì‹¤í•¨, ì±…ì„ê° ë“±ë“±) ì§€ì‹ ì§€ì‹ì„ ì–´ë–»ê²Œ ì ìš©í–ˆëŠ”ì§€ì— ëŒ€í•œ ê²½í—˜ ì§€ì‹ì„ ì–»ê¸° ìœ„í•œ ë‚˜ì˜ ë…¸ë ¥ ìì²´ë¥¼ ì–´í•„","categories":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"}],"tags":[{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ë©´ì ‘","slug":"ë©´ì ‘","permalink":"http://gonekng.github.io/tags/%EB%A9%B4%EC%A0%91/"}],"author":"Jiwon Kang"},{"title":"Feature Scaling","slug":"Python/ML/Feature Scaling","date":"2022-12-02T11:18:35.000Z","updated":"2022-12-02T11:33:27.103Z","comments":true,"path":"2022/12/02/Python/ML/Feature Scaling/","link":"","permalink":"http://gonekng.github.io/2022/12/02/Python/ML/Feature%20Scaling/","excerpt":"","text":"ì •ê·œí™” vs í‘œì¤€í™”ì •ê·œí™” : ë°ì´í„°ì˜ ë²”ìœ„ì˜ ì°¨ì´ë¥¼ ì™œê³¡í•˜ì§€ ì•Šê³  ê³µí†µ ì²™ë„ë¡œ ë³€ê²½í•˜ëŠ” ê²ƒí‘œì¤€í™” : ë°ì´í„°ê°€ í‘œì¤€ì •ê·œë¶„í¬ì˜ ì†ì„±ì„ ê°–ë„ë¡ ì¬ì¡°ì •ë˜ëŠ” ê²ƒ ì •ê·œí™”(Normalization) í‘œì¤€í™”(Standardization) Scalingì— ìµœëŒ€&#x2F;ìµœì†Œê°’ ì‚¬ìš© Scalingì— í‰ê·  ë° í‘œì¤€í¸ì°¨ ì‚¬ìš© [0,1] ë˜ëŠ” [-1,1] ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜ íŠ¹ì • ë²”ìœ„ë¡œ ì œí•œë˜ì§€ ì•ŠìŒ Featureì˜ í¬ê¸°(ë²”ìœ„)ê°€ ë‹¤ë¥¼ ë•Œ ì‚¬ìš© í‰ê· ì„ 0, í‘œì¤€í¸ì°¨ë¥¼ 1ë¡œ ë§Œë“¤ê³ ì í•  ë•Œ ì‚¬ìš© Featureì˜ ë¶„í¬ì— ëŒ€í•´ ëª¨ë¥¼ ë•Œ ìœ ìš© Featureê°€ ì •ê·œë¶„í¬(ì— ê·¼ì‚¬)ì¸ ê²½ìš° ìœ ìš© MinMaxScaler, MinAbsScaler, Normalizer StandardScaler, RobustScaler Scaler ì¢…ë¥˜StandardScaler í‰ê· ì´ 0, ë¶„ì‚°ì´ 1ì¸ í‘œì¤€ì •ê·œë¶„í¬í™” ì´ìƒì¹˜ì˜ ì˜í–¥ ë§ì´ ë°›ìŒ 123456from sklearn.preprocessing import StandardScalerstd = StandardScaler()std.fit(X_train)X_train_scaled = std.transform(X_train)X_test_scaled = std.transform(X_test) RobustScaler í‰ê· ê³¼ ë¶„ì‚° ëŒ€ì‹  ì¤‘ê°„ê°’ê³¼ ì‚¬ë¶„ìœ„ê°’ì„ ì‚¬ìš© ì´ìƒì¹˜ì˜ ì˜í–¥ ìµœì†Œí™” 123456from sklearn.preprocessing import StandardScalerstd = StandardScaler()std.fit(X_train)X_train_scaled = std.transform(X_train)X_test_scaled = std.transform(X_test) MinMaxScaler 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜ ì´ìƒì¹˜ì˜ ì˜í–¥ ë§ì´ ë°›ìŒ 123456from sklearn.preprocessing import MinMaxScalermms = MinMaxScaler()mms.fit(X_train)X_train_scaled = mms.transform(X_train)X_test_scaled = mms.transform(X_test) MaxAbsScaler -1ê³¼ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜ ì´ìƒì¹˜ì˜ ì˜í–¥ ë§ì´ ë°›ìŒ 123456from sklearn.preprocessing import MaxAbsScalermas = MaxAbsScaler()mas.fit(X_train)X_train_scaled = mas.transform(X_train)X_test_scaled = mas.transform(X_test) Normalizer ê° ì—´ì´ ì•„ë‹Œ í–‰ë§ˆë‹¤ ì •ê·œí™” ìˆ˜í–‰ í•œ í–‰ì˜ ëª¨ë“  í”¼ì²˜ë“¤ ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ê°€ 1ì´ ë˜ë„ë¡ í•¨ í•™ìŠµì´ ë¹ ë¥´ê³ , ê³¼ëŒ€ì í•© ê°€ëŠ¥ì„±ì„ ë‚®ì¶œ ìˆ˜ ìˆìŒ 12345from sklearn.preprocessing import RobustScalerrbs = RobustScaler()X_train_scaled = rbs.fit_transform(X_train)X_test_scaled = rbs.transform(X_test)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"},{"name":"scikit-learn","slug":"scikit-learn","permalink":"http://gonekng.github.io/tags/scikit-learn/"}],"author":"Jiwon Kang"},{"title":"Jupyter Notebookì—ì„œ SQL ì‹¤í–‰í•˜ê¸°","slug":"SQL/Jupyter Notebookì—ì„œ SQL ì‹¤í–‰í•˜ê¸°","date":"2022-11-18T14:37:04.000Z","updated":"2022-11-18T14:46:58.121Z","comments":true,"path":"2022/11/18/SQL/Jupyter Notebookì—ì„œ SQL ì‹¤í–‰í•˜ê¸°/","link":"","permalink":"http://gonekng.github.io/2022/11/18/SQL/Jupyter%20Notebook%EC%97%90%EC%84%9C%20SQL%20%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/","excerpt":"","text":"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ê³µí†µì ìœ¼ë¡œ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤ 1pip install ipython-sql ì ‘ì†í•˜ê³ ì í•˜ëŠ” DBì— ë§ê²Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•œë‹¤ 1234567891011# sql serverpip install pyodbc# PostgreSQL pip install pyscopg2# MySQLpip install PyMySQL# Oraclepip install cx_Oracle Jupyter Notebookì—ì„œ ì„¤ì •í•˜ê¸° Jupyter Notebookì—ì„œ ë§¤ì§ëª…ë ¹ì–´ë¡œ ìµìŠ¤í…ì…˜ì„ ë¡œë“œí•œë‹¤. 1%load_ext sql ë‹¤ìŒê³¼ ê°™ì€ ì°½ì´ ëœ¨ë©´ Installì„ ëˆ„ë¥¸ë‹¤. ì„¤ì¹˜í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ì´ ëœë‹¤ ì ‘ì†í•˜ë ¤ëŠ” DBì— ë§ëŠ” ì½”ë“œë¥¼ ì…ë ¥ í›„ ì‹¤í–‰ 1234567891011# SQL Server%sql mssql+pyodbc://user_name:password@host:port_number/db# PostgreSQL%sql postgresql://user_name:password@host:port_number/db # MySQL%sql mysql://user_name:password@host:port_number/db# Oracle%sql oracle://user_name:password@127.0.0.1:port_number/db ì—°ê²°ì´ ë˜ì—ˆìœ¼ë©´ ì½”ë“œ ì•ì— %%sqlì„ ë¶™ì´ê³  ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•œë‹¤ (ì„¸ë¯¸ì½œë¡  ì œì™¸) Jupyterlabì—ì„œ ì˜ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. Reference ì°¸ê³ 1 : https://95pbj.tistory.com/47 ì°¸ê³ 2 : https://towardsdatascience.com/heres-how-to-run-sql-in-jupyter-notebooks-f26eb90f3259","categories":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/tags/sql/"},{"name":"oracle","slug":"oracle","permalink":"http://gonekng.github.io/tags/oracle/"}],"author":"Jiwon Kang"},{"title":"Disqusë¡œ ë¸”ë¡œê·¸ ëŒ“ê¸€ ê¸°ëŠ¥ ì„¤ì •","slug":"hexo/disqus_comment","date":"2022-11-16T09:55:51.000Z","updated":"2022-11-16T10:10:34.615Z","comments":true,"path":"2022/11/16/hexo/disqus_comment/","link":"","permalink":"http://gonekng.github.io/2022/11/16/hexo/disqus_comment/","excerpt":"","text":"Hexo ë¸”ë¡œê·¸ì˜ Hueman í…Œë§ˆëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Disqus ì„œë¹„ìŠ¤ë¥¼ ì§€ì›í•˜ë©°, ì´ë¥¼ í†µí•´ ë¸”ë¡œê·¸ì˜ ëŒ“ê¸€ ê¸°ëŠ¥ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. (Hexo ë¸”ë¡œê·¸ Hueman í…Œë§ˆ ì„¤ì •) Disqus íšŒì›ê°€ì… Disqus ì‚¬ì´íŠ¸ì— íšŒì›ê°€ì… í›„ ë¡œê·¸ì¸í•œë‹¤. Disqus ì‚¬ì´íŠ¸ ì¶”ê°€ ë©”ì¸ í˜ì´ì§€ì—ì„œ Get Started í´ë¦­ I want to install Disqus on my site í´ë¦­ Website Name, Category, Language ì§€ì • Basic ìš”ê¸ˆì œ ì„ íƒ I donâ€™t see my platform listed, install manually with Universal Code í´ë¦­ configure í´ë¦­ Website URL í•­ëª©ì— ë¸”ë¡œê·¸ ì£¼ì†Œ ì…ë ¥ í›„ Next í´ë¦­ Balanced ì˜µì…˜ ì„ íƒ í›„ Complete Setup í´ë¦­ Dismiss Setup í´ë¦­ ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ìˆëŠ” Edit Settings í´ë¦­ Shortname í•­ëª©ì— ìˆëŠ” ë‚˜ì˜ Shortname í™•ì¸ _config.icarus.ymlì— Shortname ì„¤ì •í•˜ê¸° ë¸”ë¡œê·¸ í…Œë§ˆ í´ë”ì˜ _config.yml íŒŒì¼ì—ì„œ ë‹¤ìŒ ìœ„ì¹˜ì— ë‚˜ì˜ Disqus Shortnameì„ ì…ë ¥í•œë‹¤. 123# Commentcomment: disqus: gonekng # enter disqus shortname here Reference https://chinsun9.github.io/2020/09/23/hexo/disqusë¡œ-ë¸”ë¡œê·¸-ëŒ“ê¸€-ì‚¬ìš©í•˜ê¸°/","categories":[{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/tags/hexo/"},{"name":"hueman","slug":"hueman","permalink":"http://gonekng.github.io/tags/hueman/"},{"name":"disqus","slug":"disqus","permalink":"http://gonekng.github.io/tags/disqus/"}],"author":"Jiwon Kang"},{"title":"Hexo ë¸”ë¡œê·¸ Hueman í…Œë§ˆ ì„¤ì •","slug":"hexo/hueman_theme","date":"2022-11-16T08:01:23.000Z","updated":"2022-11-16T10:02:01.966Z","comments":true,"path":"2022/11/16/hexo/hueman_theme/","link":"","permalink":"http://gonekng.github.io/2022/11/16/hexo/hueman_theme/","excerpt":"","text":"Install theme ë¸”ë¡œê·¸ì™€ ì—°ê²°ëœ ë£¨íŠ¸ í´ë”ì—ì„œ git ëª…ë ¹ì–´ë¡œ Hueman í…Œë§ˆë¥¼ ë‹¤ìš´ë¡œë“œí•œë‹¤. 1$ git clone [https://github.com/ppoffice/hexo-theme-hueman.git](https://github.com/ppoffice/hexo-theme-hueman.git) themes/hueman ë¸”ë¡œê·¸ì˜ _config.ymlì„ ìˆ˜ì •í•©ë‹ˆë‹¤. 1theme: hueman themes í´ë” ì•ˆì— ìˆëŠ” _config.yml.exampleì˜ ì´ë¦„ì„ _config.ymlë¡œ ìˆ˜ì •í•œë‹¤. ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìœ„í•´ hexo-generator-json-contentë¥¼ ì„¤ì¹˜í•œë‹¤. 1$ npm install -S hexo-generator-json-content Change settingsì•ì—ì„œ ì´ë¦„ì„ ë³€ê²½í–ˆë˜ _config.yml íŒŒì¼ì„ ìˆ˜ì •í•˜ë©´ ê°ì¢… ì„¤ì •ì„ ë³€ê²½í•  ìˆ˜ ìˆë‹¤. ë©”ë‰´123456# Menusmenu: Home: / # Delete this row if you don&#x27;t want categories in your header nav bar Categories: About: https://about.me/gonekng ê° ë©”ë‰´ë¥¼ í´ë¦­í–ˆì„ ë•Œ ì´ë™í•  ê²½ë¡œë¥¼ ì§€ì •í•  ìˆ˜ ìˆë‹¤. ì´ë•Œ ì¹´í…Œê³ ë¦¬ëŠ” ë”°ë¡œ ì§€ì •í•˜ì§€ ì•Šì•„ë„ ê° ê²Œì‹œê¸€ì—ì„œ ì§€ì •í•œëŒ€ë¡œ ìë™ ì ìš©ëœë‹¤. About ë©”ë‰´ëŠ” ë¸”ë¡œê·¸ ì£¼ì¸ì— ëŒ€í•œ ìê¸°ì†Œê°œ í˜ì´ì§€ë¡œ ì´ë™í•˜ê¸° ìœ„í•œ ê²ƒìœ¼ë¡œ, í•„ìëŠ” About.me ë¼ëŠ” ì‚¬ì´íŠ¸ë¥¼ ì´ìš©í•˜ì—¬ ë§Œë“  í”„ë¡œí•„ URLì„ ì—°ê²°í–ˆë‹¤. ì»¤ìŠ¤í„°ë§ˆì´ì§•1234567891011121314# Customizecustomize: logo: width: 165 height: 60 url: images/logo-header.png theme_color: &#x27;#006bde&#x27; highlight: androidstudio sidebar: right # sidebar position, options: left, right thumbnail: false # enable posts thumbnail, options: true, false favicon: # path to favicon social_links: # for more icons, please see http://fontawesome.io/icons/#brand instagram: https://instagram.com/gone_kng github: https://github.com/gonekng ë©”ë‰´ ìœ„ì— ì‚½ì…í•  ë¡œê³  íŒŒì¼ urlì„ ì§€ì •í•  ìˆ˜ ìˆë‹¤. hueman/source/css/images í´ë” ë‚´ë¶€ì— ì €ì¥ëœ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆê³ , ì›¹ ì´ë¯¸ì§€ urlë„ ê°€ëŠ¥í•˜ë‹¤. í…Œë§ˆì˜ ìƒ‰ìƒì„ ì§€ì •í•  ìˆ˜ ìˆë‹¤. ê²Œì‹œê¸€ì— í¬í•¨ëœ ì½”ë“œ ë¸”ëŸ­ì—ì„œ ì ìš©ë˜ëŠ” í•˜ì´ë¼ì´íŠ¸ë¥¼ ì§€ì •í•  ìˆ˜ ìˆë‹¤. ê¸°ë³¸ê°’ì€ androidstudioì´ë©°, hueman/source/css/_highlight í´ë”ì— ìˆëŠ” ê²ƒë“¤ ì¤‘ ì„ íƒí•  ìˆ˜ ìˆë‹¤. ì‚¬ì´ë“œë°”ì˜ ìœ„ì¹˜ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆë‹¤. ê²Œì‹œê¸€ì˜ ì¸ë„¤ì¼ì„ í‘œì‹œí•˜ê±°ë‚˜ ìˆ¨ê¸¸ ìˆ˜ ìˆë‹¤. ê²Œì‹œê¸€ì˜ ì¸ë„¤ì¼ì€ ê²Œì‹œê¸€ì— í¬í•¨ëœ ì²«ë²ˆì§¸ ì‚¬ì§„ì´ ê¸°ë³¸ê°’ì´ë©°, ê²Œì‹œê¸€ì˜ front-matter ë¶€ë¶„ì—ì„œ ê²½ë¡œë¥¼ ì¶”ê°€í•˜ë©´ ë³€ê²½ ê°€ëŠ¥í•˜ë‹¤. 123title: Hello Worlddate: 2022/11/16 16:36:10thumbnail: images/example.jpg íŒŒë¹„ì½˜(URL ì•ì— ë¶™ëŠ” ì‘ì€ ì•„ì´ì½˜)ì„ ì§€ì •í•  ìˆ˜ ìˆë‹¤. ì—°ê²°í•˜ê³ ì í•˜ëŠ” SNS ë§í¬ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤. ì•„ì´ì½˜ì€ FontAwesomeì—ì„œ ì„ íƒí•˜ì—¬ ì´ë¦„ê³¼ URLì„ ì§€ì •í•˜ë©´ ì ìš©ëœë‹¤. ìœ„ì ¯12345678# Widgetswidgets: - recent_posts - category - archive - tagcloud - tag - links ì‚¬ì´ë“œë°”ì— ì¶”ê°€ë˜ëŠ” ë‹¤ì–‘í•œ ìœ„ì ¯ì„ ì§€ì •í•  ìˆ˜ ìˆìœ¼ë©°, ì‘ì„±í•œ ìˆœì„œëŒ€ë¡œ ì°¨ë¡€ë¡œ ë³´ì—¬ì§€ê²Œ ëœë‹¤. ë§í¬ ìœ„ì ¯ì— ë“¤ì–´ê°ˆ ë‚´ìš©ì€ _config.yml í•˜ë‹¨ì—ì„œ ë‹¤ìŒì˜ ì½”ë“œë¥¼ í†µí•´ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤. 12345# Miscellaneousmiscellaneous: links: Hexo: http://hexo.io Naver blog: https://blog.naver.com/donumm ê²€ìƒ‰12345# Searchsearch: insight: true # you need to install `hexo-generator-json-content` before using Insight Search swiftype: # enter swiftype install key here baidu: false # you need to disable other search engines to use Baidu search, options: true, false ë¸”ë¡œê·¸ ë‚´ì˜ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. í•„ìëŠ” í…Œë§ˆì—ì„œ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” Insight Searchë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ hexo-generator-json-contentë¥¼ ì„¤ì¹˜í•´ì•¼ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. ëŒ“ê¸€123# Commentcomment: disqus: gonekng # enter disqus shortname here ëŒ“ê¸€ ê¸°ëŠ¥ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì œê³µí•˜ëŠ” Disqus ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤. Disqus ì‚¬ì´íŠ¸ì— íšŒì›ê°€ì… ë° ë¡œê·¸ì¸ í›„ í•´ë‹¹í•˜ëŠ” ì•„ì´ë””ë¥¼ ì…ë ¥í•œë‹¤. ìì„¸í•œ ë‚´ìš©ì€ Disqusë¡œ ë¸”ë¡œê·¸ ëŒ“ê¸€ ê¸°ëŠ¥ ì„¤ì • ì°¸ì¡° ê³µìœ 12# Shareshare: default # options: jiathis, bdshare, addtoany, default í•´ë‹¹ ê²Œì‹œê¸€ì˜ ê³µìœ  ê¸°ëŠ¥ì—ë„ ëª‡ê°€ì§€ ì˜µì…˜ì´ ìˆìœ¼ë‚˜, í•„ìëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ë‹¤. Result Reference https://futurecreator.github.io/2016/06/14/hexo-apply-hueman-theme/","categories":[{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/tags/hexo/"},{"name":"hueman","slug":"hueman","permalink":"http://gonekng.github.io/tags/hueman/"}],"author":"Jiwon Kang"},{"title":"Coding Test Ex.2","slug":"Python/Exercise/coding_test_ex2","date":"2022-11-15T07:45:15.000Z","updated":"2022-11-15T07:43:28.504Z","comments":true,"path":"2022/11/15/Python/Exercise/coding_test_ex2/","link":"","permalink":"http://gonekng.github.io/2022/11/15/Python/Exercise/coding_test_ex2/","excerpt":"","text":"ì„±ê²©ìœ í˜•ê²€ì‚¬ë¬¸ì œë‚˜ë§Œì˜ ì¹´ì¹´ì˜¤ ì„±ê²© ìœ í˜• ê²€ì‚¬ì§€ë¥¼ ë§Œë“¤ë ¤ê³  í•©ë‹ˆë‹¤. ì„±ê²© ìœ í˜• ê²€ì‚¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ 4ê°œ ì§€í‘œë¡œ ì„±ê²© ìœ í˜•ì„ êµ¬ë¶„í•©ë‹ˆë‹¤. ì„±ê²©ì€ ê° ì§€í‘œì—ì„œ ë‘ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ê²°ì •ë©ë‹ˆë‹¤. ì§€í‘œ ë²ˆí˜¸ ì„±ê²© ìœ í˜• 1ë²ˆ ì§€í‘œ ë¼ì´ì–¸í˜•(R), íŠœë¸Œí˜•(T) 2ë²ˆ ì§€í‘œ ì½˜í˜•(C), í”„ë¡œë„í˜•(F) 3ë²ˆ ì§€í‘œ ì œì´ì§€í˜•(J), ë¬´ì§€í˜•(M) 4ë²ˆ ì§€í‘œ ì–´í”¼ì¹˜í˜•(A), ë„¤ì˜¤í˜•(N) 4ê°œì˜ ì§€í‘œê°€ ìˆìœ¼ë¯€ë¡œ ì„±ê²© ìœ í˜•ì€ ì´ 16(&#x3D;2 x 2 x 2 x 2)ê°€ì§€ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œRFMNâ€ì´ë‚˜ â€œTCMAâ€ì™€ ê°™ì€ ì„±ê²© ìœ í˜•ì´ ìˆìŠµë‹ˆë‹¤. ê²€ì‚¬ì§€ì—ëŠ” ì´ nê°œì˜ ì§ˆë¬¸ì´ ìˆê³ , ê° ì§ˆë¬¸ì—ëŠ” ì•„ë˜ì™€ ê°™ì€ 7ê°œì˜ ì„ íƒì§€ê°€ ìˆìŠµë‹ˆë‹¤. ë§¤ìš° ë¹„ë™ì˜ ë¹„ë™ì˜ ì•½ê°„ ë¹„ë™ì˜ ëª¨ë¥´ê² ìŒ ì•½ê°„ ë™ì˜ ë™ì˜ ë§¤ìš° ë™ì˜ ê° ì§ˆë¬¸ì€ 1ê°€ì§€ ì§€í‘œë¡œ ì„±ê²© ìœ í˜• ì ìˆ˜ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ í•œ ì§ˆë¬¸ì—ì„œ 4ë²ˆ ì§€í‘œë¡œ ì•„ë˜ í‘œì²˜ëŸ¼ ì ìˆ˜ë¥¼ ë§¤ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„ íƒì§€ ì„±ê²© ìœ í˜• ì ìˆ˜ ë§¤ìš° ë¹„ë™ì˜ ë„¤ì˜¤í˜• 3ì  ë¹„ë™ì˜ ë„¤ì˜¤í˜• 2ì  ì•½ê°„ ë¹„ë™ì˜ ë„¤ì˜¤í˜• 1ì  ëª¨ë¥´ê² ìŒ ì–´ë–¤ ì„±ê²© ìœ í˜•ë„ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤ ì•½ê°„ ë™ì˜ ì–´í”¼ì¹˜í˜• 1ì  ë™ì˜ ì–´í”¼ì¹˜í˜• 2ì  ë§¤ìš° ë™ì˜ ì–´í”¼ì¹˜í˜• 3ì  ê²€ì‚¬ìê°€ ì§ˆë¬¸ì—ì„œ ì•½ê°„ ë™ì˜ ë¥¼ ì„ íƒí•  ê²½ìš° ì–´í”¼ì¹˜í˜•(A) ì„±ê²© ìœ í˜• 1ì ì„ ë°›ê²Œ ë©ë‹ˆë‹¤. ë§Œì•½ ê²€ì‚¬ìê°€ ë§¤ìš° ë¹„ë™ì˜ ë¥¼ ì„ íƒí•  ê²½ìš° ë„¤ì˜¤í˜•(N) ì„±ê²© ìœ í˜• 3ì ì„ ë°›ê²Œ ë©ë‹ˆë‹¤. ìœ„ ì˜ˆì‹œì²˜ëŸ¼ ë„¤ì˜¤í˜•ì´ ë¹„ë™ì˜, ì–´í”¼ì¹˜í˜•ì´ ë™ì˜ì¸ ê²½ìš°ë§Œ ì£¼ì–´ì§€ì§€ ì•Šê³ , ì§ˆë¬¸ì— ë”°ë¼ ë„¤ì˜¤í˜•ì´ ë™ì˜, ì–´í”¼ì¹˜í˜•ì´ ë¹„ë™ì˜ì¸ ê²½ìš°ë„ ì£¼ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ê° ì„ íƒì§€ëŠ” ê³ ì •ì ì¸ í¬ê¸°ì˜ ì ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë§¤ìš° ë™ì˜ë‚˜ ë§¤ìš° ë¹„ë™ì˜ ë¥¼ ì„ íƒí•˜ë©´ 3ì ì„ ì–»ìŠµë‹ˆë‹¤. ë™ì˜ë‚˜ ë¹„ë™ì˜ ë¥¼ ì„ íƒí•˜ë©´ 2ì ì„ ì–»ìŠµë‹ˆë‹¤. ì•½ê°„ ë™ì˜ë‚˜ ì•½ê°„ ë¹„ë™ì˜ ë¥¼ ì„ íƒí•˜ë©´ 1ì ì„ ì–»ìŠµë‹ˆë‹¤. ëª¨ë¥´ê² ìŒ ë¥¼ ì„ íƒí•˜ë©´ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤. ê²€ì‚¬ ê²°ê³¼ëŠ” ëª¨ë“  ì§ˆë¬¸ì˜ ì„±ê²© ìœ í˜• ì ìˆ˜ë¥¼ ë”í•˜ì—¬ ê° ì§€í‘œì—ì„œ ë” ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ ì„±ê²© ìœ í˜•ì´ ê²€ì‚¬ìì˜ ì„±ê²© ìœ í˜•ì´ë¼ê³  íŒë‹¨í•©ë‹ˆë‹¤. ë‹¨, í•˜ë‚˜ì˜ ì§€í‘œì—ì„œ ê° ì„±ê²© ìœ í˜• ì ìˆ˜ê°€ ê°™ìœ¼ë©´, ë‘ ì„±ê²© ìœ í˜• ì¤‘ ì‚¬ì „ ìˆœìœ¼ë¡œ ë¹ ë¥¸ ì„±ê²© ìœ í˜•ì„ ê²€ì‚¬ìì˜ ì„±ê²© ìœ í˜•ì´ë¼ê³  íŒë‹¨í•©ë‹ˆë‹¤. ì§ˆë¬¸ë§ˆë‹¤ íŒë‹¨í•˜ëŠ” ì§€í‘œë¥¼ ë‹´ì€ 1ì°¨ì› ë¬¸ìì—´ ë°°ì—´ surveyì™€ ê²€ì‚¬ìê°€ ê° ì§ˆë¬¸ë§ˆë‹¤ ì„ íƒí•œ ì„ íƒì§€ë¥¼ ë‹´ì€ 1ì°¨ì› ì •ìˆ˜ ë°°ì—´ choicesê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§‘ë‹ˆë‹¤. ì´ë•Œ, ê²€ì‚¬ìì˜ ì„±ê²© ìœ í˜• ê²€ì‚¬ ê²°ê³¼ë¥¼ ì§€í‘œ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ 1 â‰¤ surveyì˜ ê¸¸ì´ ( &#x3D; n) â‰¤ 1,000 surveyì˜ ì›ì†ŒëŠ” &quot;RT&quot;, &quot;TR&quot;, &quot;FC&quot;, &quot;CF&quot;, &quot;MJ&quot;, &quot;JM&quot;, &quot;AN&quot;, &quot;NA&quot; ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. survey[i]ì˜ ì²« ë²ˆì§¸ ìºë¦­í„°ëŠ” i+1ë²ˆ ì§ˆë¬¸ì˜ ë¹„ë™ì˜ ê´€ë ¨ ì„ íƒì§€ë¥¼ ì„ íƒí•˜ë©´ ë°›ëŠ” ì„±ê²© ìœ í˜•ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. survey[i]ì˜ ë‘ ë²ˆì§¸ ìºë¦­í„°ëŠ” i+1ë²ˆ ì§ˆë¬¸ì˜ ë™ì˜ ê´€ë ¨ ì„ íƒì§€ë¥¼ ì„ íƒí•˜ë©´ ë°›ëŠ” ì„±ê²© ìœ í˜•ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. choicesì˜ ê¸¸ì´ &#x3D; surveyì˜ ê¸¸ì´ choices[i]ëŠ” ê²€ì‚¬ìê°€ ì„ íƒí•œ i+1ë²ˆì§¸ ì§ˆë¬¸ì˜ ì„ íƒì§€ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. 1 â‰¤ choicesì˜ ì›ì†Œ â‰¤ 7 choices ëœ» 1 ë§¤ìš° ë¹„ë™ì˜ 2 ë¹„ë™ì˜ 3 ì•½ê°„ ë¹„ë™ì˜ 4 ëª¨ë¥´ê² ìŒ 5 ì•½ê°„ ë™ì˜ 6 ë™ì˜ 7 ë§¤ìš° ë™ì˜ ì…ì¶œë ¥ ì˜ˆì‹œ survey choices result [â€œANâ€, â€œCFâ€, â€œMJâ€, â€œRTâ€, â€œNAâ€] [5, 3, 2, 7, 5] â€œTCMAâ€ [â€œTRâ€, â€œRTâ€, â€œTRâ€] [7, 1, 3] â€œRCJAâ€ ì…ì¶œë ¥ ì˜ˆ #1 1ë²ˆ ì§ˆë¬¸ì˜ ì ìˆ˜ ë°°ì¹˜ëŠ” ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì„ íƒì§€ ì„±ê²© ìœ í˜• ì ìˆ˜ ë§¤ìš° ë¹„ë™ì˜ ì–´í”¼ì¹˜í˜• 3ì  ë¹„ë™ì˜ ì–´í”¼ì¹˜í˜• 2ì  ì•½ê°„ ë¹„ë™ì˜ ì–´í”¼ì¹˜í˜• 1ì  ëª¨ë¥´ê² ìŒ ì–´ë–¤ ì„±ê²© ìœ í˜•ë„ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤ ì•½ê°„ ë™ì˜ ë„¤ì˜¤í˜• 1ì  ë™ì˜ ë„¤ì˜¤í˜• 2ì  ë§¤ìš° ë™ì˜ ë„¤ì˜¤í˜• 3ì  1ë²ˆ ì§ˆë¬¸ì—ì„œëŠ” ì§€ë¬¸ì˜ ì˜ˆì‹œì™€ ë‹¤ë¥´ê²Œ ë¹„ë™ì˜ ê´€ë ¨ ì„ íƒì§€ë¥¼ ì„ íƒí•˜ë©´ ì–´í”¼ì¹˜í˜•(A) ì„±ê²© ìœ í˜•ì˜ ì ìˆ˜ë¥¼ ì–»ê³ , ë™ì˜ ê´€ë ¨ ì„ íƒì§€ë¥¼ ì„ íƒí•˜ë©´ ë„¤ì˜¤í˜•(N) ì„±ê²© ìœ í˜•ì˜ ì ìˆ˜ë¥¼ ì–»ìŠµë‹ˆë‹¤. 1ë²ˆ ì§ˆë¬¸ì—ì„œ ê²€ì‚¬ìëŠ” ì•½ê°„ ë™ì˜ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆìœ¼ë¯€ë¡œ ë„¤ì˜¤í˜•(N) ì„±ê²© ìœ í˜• ì ìˆ˜ 1ì ì„ ì–»ê²Œ ë©ë‹ˆë‹¤. 2ë²ˆ ì§ˆë¬¸ì˜ ì ìˆ˜ ë°°ì¹˜ëŠ” ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì„ íƒì§€ ì„±ê²© ìœ í˜• ì ìˆ˜ ë§¤ìš° ë¹„ë™ì˜ ì½˜í˜• 3ì  ë¹„ë™ì˜ ì½˜í˜• 2ì  ì•½ê°„ ë¹„ë™ì˜ ì½˜í˜• 1ì  ëª¨ë¥´ê² ìŒ ì–´ë–¤ ì„±ê²© ìœ í˜•ë„ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤ ì•½ê°„ ë™ì˜ í”„ë¡œë„í˜• 1ì  ë™ì˜ í”„ë¡œë„í˜• 2ì  ë§¤ìš° ë™ì˜ í”„ë¡œë„í˜• 3ì  2ë²ˆ ì§ˆë¬¸ì—ì„œ ê²€ì‚¬ìëŠ” ì•½ê°„ ë¹„ë™ì˜ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆìœ¼ë¯€ë¡œ ì½˜í˜•(C) ì„±ê²© ìœ í˜• ì ìˆ˜ 1ì ì„ ì–»ê²Œ ë©ë‹ˆë‹¤. 3ë²ˆ ì§ˆë¬¸ì˜ ì ìˆ˜ ë°°ì¹˜ëŠ” ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì„ íƒì§€ ì„±ê²© ìœ í˜• ì ìˆ˜ ë§¤ìš° ë¹„ë™ì˜ ë¬´ì§€í˜• 3ì  ë¹„ë™ì˜ ë¬´ì§€í˜• 2ì  ì•½ê°„ ë¹„ë™ì˜ ë¬´ì§€í˜• 1ì  ëª¨ë¥´ê² ìŒ ì–´ë–¤ ì„±ê²© ìœ í˜•ë„ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤ ì•½ê°„ ë™ì˜ ì œì´ì§€í˜• 1ì  ë™ì˜ ì œì´ì§€í˜• 2ì  ë§¤ìš° ë™ì˜ ì œì´ì§€í˜• 3ì  3ë²ˆ ì§ˆë¬¸ì—ì„œ ê²€ì‚¬ìëŠ” ë¹„ë™ì˜ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆìœ¼ë¯€ë¡œ ë¬´ì§€í˜•(M) ì„±ê²© ìœ í˜• ì ìˆ˜ 2ì ì„ ì–»ê²Œ ë©ë‹ˆë‹¤. 4ë²ˆ ì§ˆë¬¸ì˜ ì ìˆ˜ ë°°ì¹˜ëŠ” ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì„ íƒì§€ ì„±ê²© ìœ í˜• ì ìˆ˜ ë§¤ìš° ë¹„ë™ì˜ ë¼ì´ì–¸í˜• 3ì  ë¹„ë™ì˜ ë¼ì´ì–¸í˜• 2ì  ì•½ê°„ ë¹„ë™ì˜ ë¼ì´ì–¸í˜• 1ì  ëª¨ë¥´ê² ìŒ ì–´ë–¤ ì„±ê²© ìœ í˜•ë„ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤ ì•½ê°„ ë™ì˜ íŠœë¸Œí˜• 1ì  ë™ì˜ íŠœë¸Œí˜• 2ì  ë§¤ìš° ë™ì˜ íŠœë¸Œí˜• 3ì  4ë²ˆ ì§ˆë¬¸ì—ì„œ ê²€ì‚¬ìëŠ” ë§¤ìš° ë™ì˜ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆìœ¼ë¯€ë¡œ íŠœë¸Œí˜•(T) ì„±ê²© ìœ í˜• ì ìˆ˜ 3ì ì„ ì–»ê²Œ ë©ë‹ˆë‹¤. 5ë²ˆ ì§ˆë¬¸ì˜ ì ìˆ˜ ë°°ì¹˜ëŠ” ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì„ íƒì§€ ì„±ê²© ìœ í˜• ì ìˆ˜ ë§¤ìš° ë¹„ë™ì˜ ë„¤ì˜¤í˜• 3ì  ë¹„ë™ì˜ ë„¤ì˜¤í˜• 2ì  ì•½ê°„ ë¹„ë™ì˜ ë„¤ì˜¤í˜• 1ì  ëª¨ë¥´ê² ìŒ ì–´ë–¤ ì„±ê²© ìœ í˜•ë„ ì ìˆ˜ë¥¼ ì–»ì§€ ì•ŠìŠµë‹ˆë‹¤ ì•½ê°„ ë™ì˜ ì–´í”¼ì¹˜í˜• 1ì  ë™ì˜ ì–´í”¼ì¹˜í˜• 2ì  ë§¤ìš° ë™ì˜ ì–´í”¼ì¹˜í˜• 3ì  5ë²ˆ ì§ˆë¬¸ì—ì„œ ê²€ì‚¬ìëŠ” ì•½ê°„ ë™ì˜ ì„ íƒì§€ë¥¼ ì„ íƒí–ˆìœ¼ë¯€ë¡œ ì–´í”¼ì¹˜í˜•(A) ì„±ê²© ìœ í˜• ì ìˆ˜ 1ì ì„ ì–»ê²Œ ë©ë‹ˆë‹¤. 1ë²ˆë¶€í„° 5ë²ˆê¹Œì§€ ì§ˆë¬¸ì˜ ì„±ê²© ìœ í˜• ì ìˆ˜ë¥¼ í•©ì¹˜ë©´ ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì§€í‘œ ë²ˆí˜¸ ì„±ê²© ìœ í˜• ì ìˆ˜ ì„±ê²© ìœ í˜• ì ìˆ˜ 1ë²ˆ ì§€í‘œ ë¼ì´ì–¸í˜•(R) 0 íŠœë¸Œí˜•(T) 3 2ë²ˆ ì§€í‘œ ì½˜í˜•(C) 1 í”„ë¡œë„í˜•(F) 0 3ë²ˆ ì§€í‘œ ì œì´ì§€í˜•(J) 0 ë¬´ì§€í˜•(M) 2 4ë²ˆ ì§€í‘œ ì–´í”¼ì¹˜í˜•(A) 1 ë„¤ì˜¤í˜•(N) 1 ê° ì§€í‘œì—ì„œ ë” ì ìˆ˜ê°€ ë†’ì€ T,C,Mì´ ì„±ê²© ìœ í˜•ì…ë‹ˆë‹¤.í•˜ì§€ë§Œ, 4ë²ˆ ì§€í‘œëŠ” 1ì ìœ¼ë¡œ ë™ì¼í•œ ì ìˆ˜ì…ë‹ˆë‹¤. ë”°ë¼ì„œ, 4ë²ˆ ì§€í‘œì˜ ì„±ê²© ìœ í˜•ì€ ì‚¬ì „ìˆœìœ¼ë¡œ ë¹ ë¥¸ Aì…ë‹ˆë‹¤. ë”°ë¼ì„œ &quot;TCMA&quot;ë¥¼ return í•´ì•¼ í•©ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆ #2 1ë²ˆë¶€í„° 3ë²ˆê¹Œì§€ ì§ˆë¬¸ì˜ ì„±ê²© ìœ í˜• ì ìˆ˜ë¥¼ í•©ì¹˜ë©´ ì•„ë˜ í‘œì™€ ê°™ìŠµë‹ˆë‹¤. ì§€í‘œ ë²ˆí˜¸ ì„±ê²© ìœ í˜• ì ìˆ˜ ì„±ê²© ìœ í˜• ì ìˆ˜ 1ë²ˆ ì§€í‘œ ë¼ì´ì–¸í˜•(R) 6 íŠœë¸Œí˜•(T) 1 2ë²ˆ ì§€í‘œ ì½˜í˜•(C) 0 í”„ë¡œë„í˜•(F) 0 3ë²ˆ ì§€í‘œ ì œì´ì§€í˜•(J) 0 ë¬´ì§€í˜•(M) 0 4ë²ˆ ì§€í‘œ ì–´í”¼ì¹˜í˜•(A) 0 ë„¤ì˜¤í˜•(N) 0 1ë²ˆ ì§€í‘œëŠ” íŠœë¸Œí˜•(T)ë³´ë‹¤ ë¼ì´ì–¸í˜•(R)ì˜ ì ìˆ˜ê°€ ë” ë†’ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì²« ë²ˆì§¸ ì§€í‘œì˜ ì„±ê²© ìœ í˜•ì€ Rì…ë‹ˆë‹¤.í•˜ì§€ë§Œ, 2, 3, 4ë²ˆ ì§€í‘œëŠ” ëª¨ë‘ 0ì ìœ¼ë¡œ ë™ì¼í•œ ì ìˆ˜ì…ë‹ˆë‹¤. ë”°ë¼ì„œ 2, 3, 4ë²ˆ ì§€í‘œì˜ ì„±ê²© ìœ í˜•ì€ ì‚¬ì „ìˆœìœ¼ë¡œ ë¹ ë¥¸ C, J, Aì…ë‹ˆë‹¤. ë”°ë¼ì„œ &quot;RCJA&quot;ë¥¼ return í•´ì•¼ í•©ë‹ˆë‹¤. í’€ì´ 1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145def solution(survey, choices): answer = &#x27;&#x27; score = [[0,0], # R, T [0,0], # C, F [0,0], # J, M [0,0]] # A, N for i, string in enumerate(survey): if string == &quot;RT&quot;: if choices[i] == 1: score[0][0] += 3 elif choices[i] == 2: score[0][0] += 2 elif choices[i] == 3: score[0][0] += 1 elif choices[i] == 5: score[0][1] += 1 elif choices[i] == 6: score[0][1] += 2 elif choices[i] == 7: score[0][1] += 3 else: continue elif string == &quot;TR&quot;: if choices[i] == 1: score[0][1] += 3 elif choices[i] == 2: score[0][1] += 2 elif choices[i] == 3: score[0][1] += 1 elif choices[i] == 5: score[0][0] += 1 elif choices[i] == 6: score[0][0] += 2 elif choices[i] == 7: score[0][0] += 3 else: continue elif string == &quot;CF&quot;: if choices[i] == 1: score[1][0] += 3 elif choices[i] == 2: score[1][0] += 2 elif choices[i] == 3: score[1][0] += 1 elif choices[i] == 5: score[1][1] += 1 elif choices[i] == 6: score[1][1] += 2 elif choices[i] == 7: score[1][1] += 3 else: continue elif string == &quot;FC&quot;: if choices[i] == 1: score[1][1] += 3 elif choices[i] == 2: score[1][1] += 2 elif choices[i] == 3: score[1][1] += 1 elif choices[i] == 5: score[1][0] += 1 elif choices[i] == 6: score[1][0] += 2 elif choices[i] == 7: score[1][0] += 3 else: continue elif string == &quot;JM&quot;: if choices[i] == 1: score[2][0] += 3 elif choices[i] == 2: score[2][0] += 2 elif choices[i] == 3: score[2][0] += 1 elif choices[i] == 5: score[2][1] += 1 elif choices[i] == 6: score[2][1] += 2 elif choices[i] == 7: score[2][1] += 3 else: continue elif string == &quot;MJ&quot;: if choices[i] == 1: score[2][1] += 3 elif choices[i] == 2: score[2][1] += 2 elif choices[i] == 3: score[2][1] += 1 elif choices[i] == 5: score[2][0] += 1 elif choices[i] == 6: score[2][0] += 2 elif choices[i] == 7: score[2][0] += 3 else: continue elif string == &quot;AN&quot;: if choices[i] == 1: score[3][0] += 3 elif choices[i] == 2: score[3][0] += 2 elif choices[i] == 3: score[3][0] += 1 elif choices[i] == 5: score[3][1] += 1 elif choices[i] == 6: score[3][1] += 2 elif choices[i] == 7: score[3][1] += 3 else: continue elif string == &quot;NA&quot;: if choices[i] == 1: score[3][1] += 3 elif choices[i] == 2: score[3][1] += 2 elif choices[i] == 3: score[3][1] += 1 elif choices[i] == 5: score[3][0] += 1 elif choices[i] == 6: score[3][0] += 2 elif choices[i] == 7: score[3][0] += 3 else: continue if score[0][0] &gt;= score[0][1]: answer = answer + &#x27;R&#x27; else: answer = answer + &#x27;T&#x27; if score[1][0] &gt;= score[1][1]: answer = answer + &#x27;C&#x27; else: answer = answer + &#x27;F&#x27; if score[2][0] &gt;= score[2][1]: answer = answer + &#x27;J&#x27; else: answer = answer + &#x27;M&#x27; if score[3][0] &gt;= score[3][1]: answer = answer + &#x27;A&#x27; else: answer = answer + &#x27;N&#x27; return answer í’€ì´ 21234567891011121314151617181920def solution(survey, choices): my_dict = &#123;&quot;RT&quot;:0,&quot;CF&quot;:0,&quot;JM&quot;:0,&quot;AN&quot;:0&#125; for A,B in zip(survey,choices): if A not in my_dict.keys(): A = A[::-1] my_dict[A] -= B-4 else: my_dict[A] += B-4 result = &quot;&quot; for name in my_dict.keys(): if my_dict[name] &gt; 0: result += name[1] elif my_dict[name] &lt; 0: result += name[0] else: result += sorted(name)[0] return result í’€ì´ 3123456789101112131415161718192021222324252627282930313233343536373839404142434445def solution(ì„¤ë¬¸_ì¡°ì‚¬_ë°°ì—´, ì„ íƒì§€_ë°°ì—´): ì§€í‘œ = &#123;&#125; ì§€í‘œ[&#x27;RT&#x27;] = ì§€í‘œ[&#x27;TR&#x27;] = &#123;&#x27;R&#x27;: 0, &#x27;T&#x27;: 0,&#125; ì§€í‘œ[&#x27;FC&#x27;] = ì§€í‘œ[&#x27;CF&#x27;] = &#123;&#x27;C&#x27;: 0, &#x27;F&#x27;: 0,&#125; ì§€í‘œ[&#x27;MJ&#x27;] = ì§€í‘œ[&#x27;JM&#x27;] = &#123;&#x27;J&#x27;: 0, &#x27;M&#x27;: 0,&#125; ì§€í‘œ[&#x27;AN&#x27;] = ì§€í‘œ[&#x27;NA&#x27;] = &#123;&#x27;A&#x27;: 0, &#x27;N&#x27;: 0,&#125; ì ìˆ˜ = &#123; &#x27;ë§¤ìš° ë¹„ë™ì˜&#x27;: 3, &#x27;ë¹„ë™ì˜&#x27;: 2, &#x27;ì•½ê°„ ë¹„ë™ì˜&#x27;: 1, &#x27;ëª¨ë¥´ê² ìŒ&#x27;: 0, &#x27;ì•½ê°„ ë™ì˜&#x27;: 1, &#x27;ë™ì˜&#x27;: 2, &#x27;ë§¤ìš° ë™ì˜&#x27;: 3, &#125; ë¹„ë™ì˜ = [1, 2, 3] ë™ì˜ = [5, 6, 7] ì„ íƒì§€ = &#123; 1: &#x27;ë§¤ìš° ë¹„ë™ì˜&#x27;, 2: &#x27;ë¹„ë™ì˜&#x27;, 3: &#x27;ì•½ê°„ ë¹„ë™ì˜&#x27;, 4: &#x27;ëª¨ë¥´ê² ìŒ&#x27;, 5: &#x27;ì•½ê°„ ë™ì˜&#x27;, 6: &#x27;ë™ì˜&#x27;, 7: &#x27;ë§¤ìš° ë™ì˜&#x27;, &#125; answer = &#x27;&#x27; for ì¸ë±ìŠ¤ in range(len(ì„¤ë¬¸_ì¡°ì‚¬_ë°°ì—´)): ë¹„ë™ì˜_ìºë¦­í„°, ë™ì˜_ìºë¦­í„° = ì„¤ë¬¸_ì¡°ì‚¬_ë°°ì—´[ì¸ë±ìŠ¤] if ì„ íƒì§€_ë°°ì—´[ì¸ë±ìŠ¤] in ë¹„ë™ì˜: ì§€í‘œ[ì„¤ë¬¸_ì¡°ì‚¬_ë°°ì—´[ì¸ë±ìŠ¤]][ë¹„ë™ì˜_ìºë¦­í„°] += ì ìˆ˜[ì„ íƒì§€[ì„ íƒì§€_ë°°ì—´[ì¸ë±ìŠ¤]]] continue if ì„ íƒì§€_ë°°ì—´[ì¸ë±ìŠ¤] in ë™ì˜: ì§€í‘œ[ì„¤ë¬¸_ì¡°ì‚¬_ë°°ì—´[ì¸ë±ìŠ¤]][ë™ì˜_ìºë¦­í„°] += ì ìˆ˜[ì„ íƒì§€[ì„ íƒì§€_ë°°ì—´[ì¸ë±ìŠ¤]]] ê²°ê³¼_ë°°ì—´ = [ì§€í‘œ[&#x27;RT&#x27;].items(), ì§€í‘œ[&#x27;FC&#x27;].items(), ì§€í‘œ[&#x27;MJ&#x27;].items(), ì§€í‘œ[&#x27;AN&#x27;].items()] ì •ë ¬ëœ_ë°°ì—´ = [] for ê²°ê³¼ in ê²°ê³¼_ë°°ì—´: ì •ë ¬ëœ_ë°°ì—´.append(sorted(ê²°ê³¼, key=lambda x: -x[1])) return &#x27;&#x27;.join([ìºë¦­í„°_ì ìˆ˜_íŠœí”Œ[0] for [ìºë¦­í„°_ì ìˆ˜_íŠœí”Œ, _] in ì •ë ¬ëœ_ë°°ì—´]) ì¶œì²˜ : Programmers","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"coding test","slug":"python/coding-test","permalink":"http://gonekng.github.io/categories/python/coding-test/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"programmers","slug":"programmers","permalink":"http://gonekng.github.io/tags/programmers/"}],"author":"Jiwon Kang"},{"title":"Coding Test Ex.1","slug":"Python/Exercise/coding_test_ex1","date":"2022-11-15T06:43:00.000Z","updated":"2022-11-15T07:37:30.102Z","comments":true,"path":"2022/11/15/Python/Exercise/coding_test_ex1/","link":"","permalink":"http://gonekng.github.io/2022/11/15/Python/Exercise/coding_test_ex1/","excerpt":"","text":"Kë²ˆì§¸ìˆ˜ë¬¸ì œë°°ì—´ arrayì˜ ië²ˆì§¸ ìˆ«ìë¶€í„° jë²ˆì§¸ ìˆ«ìê¹Œì§€ ìë¥´ê³  ì •ë ¬í–ˆì„ ë•Œ, kë²ˆì§¸ì— ìˆëŠ” ìˆ˜ë¥¼ êµ¬í•˜ë ¤ í•©ë‹ˆë‹¤.ì˜ˆë¥¼ ë“¤ì–´ arrayê°€ [1, 5, 2, 6, 3, 7, 4], i &#x3D; 2, j &#x3D; 5, k &#x3D; 3ì´ë¼ë©´, arrayì˜ 2ë²ˆì§¸ë¶€í„° 5ë²ˆì§¸ê¹Œì§€ ìë¥´ë©´ [5, 2, 6, 3]ì…ë‹ˆë‹¤. 1ì—ì„œ ë‚˜ì˜¨ ë°°ì—´ì„ ì •ë ¬í•˜ë©´ [2, 3, 5, 6]ì…ë‹ˆë‹¤. 2ì—ì„œ ë‚˜ì˜¨ ë°°ì—´ì˜ 3ë²ˆì§¸ ìˆ«ìëŠ” 5ì…ë‹ˆë‹¤. ë°°ì—´ array, [i, j, k]ë¥¼ ì›ì†Œë¡œ ê°€ì§„ 2ì°¨ì› ë°°ì—´ commandsê°€ ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§ˆ ë•Œ, commandsì˜ ëª¨ë“  ì›ì†Œì— ëŒ€í•´ ì•ì„œ ì„¤ëª…í•œ ì—°ì‚°ì„ ì ìš©í–ˆì„ ë•Œ ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ë°°ì—´ì— ë‹´ì•„ return í•˜ë„ë¡ solution í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì œí•œì‚¬í•­ arrayì˜ ê¸¸ì´ëŠ” 1 ì´ìƒ 100 ì´í•˜ì…ë‹ˆë‹¤. arrayì˜ ê° ì›ì†ŒëŠ” 1 ì´ìƒ 100 ì´í•˜ì…ë‹ˆë‹¤. commandsì˜ ê¸¸ì´ëŠ” 1 ì´ìƒ 50 ì´í•˜ì…ë‹ˆë‹¤. commandsì˜ ê° ì›ì†ŒëŠ” ê¸¸ì´ê°€ 3ì…ë‹ˆë‹¤. ì…ì¶œë ¥ ì˜ˆì‹œ array commands return [1, 5, 2, 6, 3, 7, 4] [[2, 5, 3], [4, 4, 1], [1, 7, 3]] [5, 6, 3] [1, 5, 2, 6, 3, 7, 4]ë¥¼ 2ë²ˆì§¸ë¶€í„° 5ë²ˆì§¸ê¹Œì§€ ìë¥¸ í›„ ì •ë ¬í•©ë‹ˆë‹¤. [2, 3, 5, 6]ì˜ ì„¸ ë²ˆì§¸ ìˆ«ìëŠ” 5ì…ë‹ˆë‹¤. [1, 5, 2, 6, 3, 7, 4]ë¥¼ 4ë²ˆì§¸ë¶€í„° 4ë²ˆì§¸ê¹Œì§€ ìë¥¸ í›„ ì •ë ¬í•©ë‹ˆë‹¤. [6]ì˜ ì²« ë²ˆì§¸ ìˆ«ìëŠ” 6ì…ë‹ˆë‹¤. [1, 5, 2, 6, 3, 7, 4]ë¥¼ 1ë²ˆì§¸ë¶€í„° 7ë²ˆì§¸ê¹Œì§€ ìë¦…ë‹ˆë‹¤. [1, 2, 3, 4, 5, 6, 7]ì˜ ì„¸ ë²ˆì§¸ ìˆ«ìëŠ” 3ì…ë‹ˆë‹¤. í’€ì´ 11234567def solution(array, commands): answer = [] for com in commands: temp = array[com[0]-1:com[1]] temp.sort() answer.append(temp[com[2]-1]) return answer í’€ì´ 212def solution(array, commands): return list(map(lambda x:sorted(array[x[0]-1:x[1]])[x[2]-1], commands)) í’€ì´ 3123456def solution(array, commands): answer = [] for command in commands: i,j,k = command answer.append(list(sorted(array[i-1:j]))[k-1]) return answer ì¶œì²˜ : Programmers","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"coding test","slug":"python/coding-test","permalink":"http://gonekng.github.io/categories/python/coding-test/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"programmers","slug":"programmers","permalink":"http://gonekng.github.io/tags/programmers/"}],"author":"Jiwon Kang"},{"title":"Git Installation in Windows11","slug":"Setting/Git Installation in Windows11","date":"2022-10-17T07:14:08.000Z","updated":"2022-10-17T07:54:02.758Z","comments":true,"path":"2022/10/17/Setting/Git Installation in Windows11/","link":"","permalink":"http://gonekng.github.io/2022/10/17/Setting/Git%20Installation%20in%20Windows11/","excerpt":"","text":"Git ì„¤ì¹˜íŒŒì¼ ë‹¤ìš´ë¡œë“œ git-scm.com ì—ì„œ Downloads í´ë¦­ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ìš´ì˜ì²´ì œ(Windows) í´ë¦­ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜(64ë¹„íŠ¸)ì— í•´ë‹¹í•˜ëŠ” ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì„¤ì¹˜ íŒŒì¼ ë‹¤ìš´ Git Setup ë§ˆë²•ì‚¬ ì‹¤í–‰ ë‹¤ìš´ë¡œë“œë°›ì€ Git Setup íŒŒì¼ì„ ì‹¤í–‰ ì„¤ì¹˜í•˜ê¸° ìœ„í•œ ê²½ë¡œ ì§€ì • í›„ Next í´ë¦­ ì„¤ì¹˜í•  êµ¬ì„±ìš”ì†Œ ì„ íƒ í›„ Next í´ë¦­ ì¼ë°˜ì ìœ¼ë¡œ ê¸°ë³¸ ìƒíƒœ ê·¸ëŒ€ë¡œ ì§„í–‰í•´ë„ ë¬´ê´€ Additional icons On the Desktop : ë°”íƒ•í™”ë©´ì— ë°”ë¡œê°€ê¸° ì•„ì´ì½˜ ì¶”ê°€ Windows Explorer integration Git Bash Here : Git Bash ì—°ê²° ê¸°ëŠ¥ Git GUI Here : Git GUI ì—°ê²° ê¸°ëŠ¥ Git LFS ( Large File Support) : ëŒ€ìš©ëŸ‰ íŒŒì¼ ì§€ì› ì—¬ë¶€ Associate .git* configuration files with the default text editor : Git êµ¬ì„± íŒŒì¼ì„ ê¸°ë³¸ í…ìŠ¤íŠ¸ í¸ì§‘ê¸°ì™€ ì—°ê²°í• ì§€ ì—¬ë¶€ Associate .sh files to be run with Bash : .sh í™•ì¥ì íŒŒì¼ì„ Bashì™€ ì—°ê²°í• ì§€ ì„ íƒ Check daily for Git for Windows updates : Git ì—…ë°ì´íŠ¸ë¥¼ ë§¤ì¼ ì²´í¬í• ì§€ ì—¬ë¶€ Add a Git Bash Profile to Windows Terminal : ìœˆë„ìš° í„°ë¯¸ë„ì— Git Bash ì¶”ê°€í• ì§€ ì—¬ë¶€ ì‹œì‘ í´ë” ê²½ë¡œ ì§€ì • í›„ Next í´ë¦­ ê¸°ë³¸ Git ì—ë””í„° ì„ íƒ í›„ Next í´ë¦­ ê¸°ë³¸ ì˜µì…˜ì€ Vim í¸ì§‘ê¸°ì´ë©°, Notepad, VSCode, Sublime ë“±ë“± ì„ íƒ ê°€ëŠ¥ Branch ì´ë¦„ ì§€ì • ì˜µì…˜ ì„ íƒ í›„ Next í´ë¦­ Let Git decide : ê¸°ë³¸ì ìœ¼ë¡œ masterë¡œ ì§€ì •, ì¶”í›„ ë³€ê²½ ê°€ëŠ¥ Override the default branch name for new repositories : ì…ë ¥í•œ ì´ë¦„ìœ¼ë¡œ ìë™ ì§€ì • í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ ê²½ìš° mainìœ¼ë¡œ í†µìš©ë˜ê³  ìˆìŒ ì´í›„ ì˜µì…˜ë“¤ì€ ë³„ë„ ì§€ì •ì´ë‚˜ ë³€ê²½ ì—†ì´ ë„˜ì–´ê°€ê³ , ë§ˆì§€ë§‰ Install ì‹œ ì„¤ì¹˜ ì§„í–‰ ëª¨ë“  ì„¤ì¹˜ê°€ ì™„ë£Œëœ í›„ Finish í´ë¦­ Git Bash ì‚¬ìš©ì ì •ë³´ ì…ë ¥ Git Bash ì‹¤í–‰ í›„ ì‚¬ìš©ì ì •ë³´ ë“±ë¡ ì‚¬ìš©ì ì •ë³´ë¥¼ ë“±ë¡í•˜ë©´ ë¡œì»¬ì—ì„œ Git ì»¤ë°‹ ì‹œ í•­ìƒ ì´ ì •ë³´ê°€ ì‚¬ìš©ë¨ 12git config --global user.name &quot;Name&quot;git config --global user.email &quot;Email&quot; .gitconfigì— ì €ì¥ë˜ì–´ ìˆëŠ” ì„¤ì • ê°’ í™•ì¸ : cat ~/.gitconfig Ref.https://iboxcomein.com/windows-git-install/","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"git","slug":"git","permalink":"http://gonekng.github.io/tags/git/"},{"name":"windows11","slug":"windows11","permalink":"http://gonekng.github.io/tags/windows11/"}],"author":"Jiwon Kang"},{"title":"ì›¹ ê°œë°œì„ ìœ„í•œ VS code ì„¤ì •","slug":"dev/Setting VS Code for Web Development","date":"2022-05-03T06:53:01.000Z","updated":"2022-12-10T14:22:39.728Z","comments":true,"path":"2022/05/03/dev/Setting VS Code for Web Development/","link":"","permalink":"http://gonekng.github.io/2022/05/03/dev/Setting%20VS%20Code%20for%20Web%20Development/","excerpt":"","text":"Install Beautify in Extension tap. Functional contribution â†’ Command â†’ Copy HookyQR.beautify Type Ctrl + Shift + P and paste HookyQR.beautify in the search window. Set the key binding of Beauty Selection to Ctrl + Alt + L. Install Live Server in Extension tap. Install Auto Rename Tag in Extension tap.","categories":[{"name":"development","slug":"development","permalink":"http://gonekng.github.io/categories/development/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://gonekng.github.io/tags/vscode/"},{"name":"development","slug":"development","permalink":"http://gonekng.github.io/tags/development/"}],"author":"Jiwon Kang"},{"title":"SQL TEST 6-7","slug":"SQL/SQL TEST 6-7","date":"2022-05-02T03:08:45.000Z","updated":"2022-11-16T15:14:56.484Z","comments":true,"path":"2022/05/02/SQL/SQL TEST 6-7/","link":"","permalink":"http://gonekng.github.io/2022/05/02/SQL/SQL%20TEST%206-7/","excerpt":"","text":"SQL Subquery â€˜ì˜¤ë¼í´ SQLê³¼ PL&#x2F;SQLì„ ë‹¤ë£¨ëŠ” ê¸°ìˆ  (ê¸¸ë²—)â€™ Q1.populations í…Œì´ë¸”ì—ì„œ 2015ë…„ í‰ê·  ê¸°ëŒ€ìˆ˜ëª…ë³´ë‹¤ ë†’ì€ ëª¨ë“  ì •ë³´ë¥¼ ì¡°íšŒí•œë‹¤. A1.12345678SELECT * FROM populations WHERE year = 2015 AND life_expectancy &gt; (SELECT AVG(life_expectancy) as AVG FROM populations WHERE year = 2015 GROUP BY year); Q2.subquery_countries í…Œì´ë¸”ì— ìˆëŠ” capitalê³¼ ë§¤ì¹­ë˜ëŠ” cities í…Œì´ë¸”ì˜ ì •ë³´ë¥¼ ì¡°íšŒí•œë‹¤. A2.123456SELECT a.name, a.country_code, a.urbanarea_pop FROM cities a WHERE a.name IN (SELECT b.capital FROM subquery_countries b) ORDER BY a.urbanarea_pop desc; Q3.economies í…Œì´ë¸”ì—ì„œ code, inflation_rate, unemployment_rateë¥¼ ì¡°íšŒí•œë‹¤. inflation_rate ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•œë‹¤. subquery_countries í…Œì´ë¸”ë‚´ gov_form ì»¬ëŸ¼ì—ì„œ Constitutional Monarchy ë˜ëŠ” Republicì´ ë“¤ì–´ê°„ êµ­ê°€ëŠ” ì œì™¸í•œë‹¤. A3.123456789SELECT a.code, a.inflation_rate, a.unemployment_rate FROM economies a WHERE a.year = 2015 AND a.code NOT IN (SELECT b.code FROM subquery_countries b WHERE b.gov_form = &#x27;Constitutional Monarchy&#x27; OR b.gov_form LIKE &#x27;%Republic%&#x27;) ORDER BY a.inflation_rate ASC; Q4.2015ë…„ ê° ëŒ€ë¥™ë³„ inflation_rateê°€ ê°€ì¥ ì‹¬í•œ êµ­ê°€ì™€ inflation_rateë¥¼ êµ¬í•œë‹¤. íŒíŠ¸) ì•„ë˜ ì¿¼ë¦¬ ì‹¤í–‰ 123456SELECT country_name, continent, inflation_rate FROM subquery_countries INNER JOIN economies USING (code) WHERE year = 2015; A4.123456789101112131415With basis AS ( SELECT country_name, continent, inflation_rate FROM subquery_countries INNER JOIN economies USING (code) WHERE year = 2015 ) , max_inf AS ( SELECT continent, MAX(inflation_rate) as inflation_rate FROM basis GROUP BY continent )SELECT a.country_name, b.continent, b.inflation_rate FROM basis a, max_inf b WHERE a.inflation_rate = b.inflation_rate; SQL Window FunctionQ1.ê° í–‰ì— ìˆ«ìë¥¼ 1, 2, 3, â€¦ í˜•íƒœë¡œ ì¶”ê°€í•œë‹¤. (row_nìœ¼ë¡œ í‘œì‹œ) row_n ê¸°ì¤€ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì¶œë ¥ í…Œì´ë¸”ëª…ì— aliasë¥¼ ì ìš©í•œë‹¤. A1.12345678With sub_table AS ( SELECT ROWNUM-95 AS ROW_N , YEAR, CITY, SPORT, DISCIPLINE, ATHLETE FROM summer_medals )SELECT * FROM sub_table WHERE ROW_N &gt; 0; Q2.ì˜¬ë¦¼í”½ ë…„ë„ë¥¼ ì˜¤ë¦„ì°¨ìˆœ ìˆœë²ˆëŒ€ë¡œ ì‘ì„±í•œë‹¤. íŒíŠ¸) ì„œë¸Œì¿¼ë¦¬ì™€ ìœˆë„ìš° í•¨ìˆ˜ë¥¼ ì´ìš©í•œë‹¤. A2.12345SELECT year , ROW_NUMBER() OVER (ORDER BY year) as ROW_N FROM (SELECT year FROM summer_medals GROUP BY year); Q3.(1) WITH ì ˆ ì‚¬ìš©í•˜ì—¬ ê° ìš´ë™ì„ ìˆ˜ë“¤ì´ íšë“í•œ ë©”ë‹¬ ê°¯ìˆ˜ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ë„ë¡ í•œë‹¤.(2) (1) ì¿¼ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ê·¸ë¦¬ê³  ì„ ìˆ˜ë“¤ì˜ ë­í‚¹ì„ ì¶”ê°€í•œë‹¤. ìƒìœ„ 5ê°œë§Œ ì¶”ì¶œ : OFFSET 0 ROWS FETCH NEXT 5 ROWS ONLY A3.123456789With basis AS ( SELECT ATHLETE, COUNT() AS MEDALS FROM summer_medals GROUP BY ATHLETE ORDER BY COUNT() desc )SELECT MEDALS, ATHLETE, ROWNUM FROM basis OFFSET 0 ROWS FETCH NEXT 5 ROWS ONLY; Q4.ë‹¤ìŒ ì¿¼ë¦¬ëŠ” ë‚¨ì 69KG ì—­ë„ ê²½ê¸°ì—ì„œ ë§¤ë…„ ê¸ˆë©”ë‹¬ë¦¬ìŠ¤íŠ¸ ì¡°íšŒí•˜ëŠ” ì¿¼ë¦¬ì´ë‹¤. ì´ë•Œ ë§¤ë…„ ì „ë…„ë„ ì±”í”¼ì–¸ë„ ê°™ì´ ì¡°íšŒí•˜ë„ë¡ í•œë‹¤. (LAG &amp; WITHì ˆ ì‚¬ìš©) 123456SELECT Year, Country AS champion FROM summer_medals WHERE Discipline = &#x27;Weightlifting&#x27; AND Event = &#x27;69KG&#x27; AND Gender = &#x27;Men&#x27; AND Medal = &#x27;Gold&#x27;; A4.1234567891011WITH basis AS ( SELECT Year, Country AS champion FROM summer_medals WHERE Discipline = &#x27;Weightlifting&#x27; AND Event = &#x27;69KG&#x27; AND Gender = &#x27;Men&#x27; AND Medal = &#x27;Gold&#x27; )SELECT year, champion , LAG(champion, 1) OVER(order by champion) AS LAST_CHAMPION FROM basis;","categories":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/tags/sql/"},{"name":"oracle","slug":"oracle","permalink":"http://gonekng.github.io/tags/oracle/"}],"author":"Jiwon Kang"},{"title":"SQL EXERCISE 6-7","slug":"SQL/SQL EXERCISE 6-7","date":"2022-05-02T00:32:11.000Z","updated":"2022-11-16T15:14:53.482Z","comments":true,"path":"2022/05/02/SQL/SQL EXERCISE 6-7/","link":"","permalink":"http://gonekng.github.io/2022/05/02/SQL/SQL%20EXERCISE%206-7/","excerpt":"","text":"CHAPTER 06 â€˜ì˜¤ë¼í´ SQLê³¼ PL&#x2F;SQLì„ ë‹¤ë£¨ëŠ” ê¸°ìˆ  (ê¸¸ë²—)â€™ Q1.101ë²ˆ ì‚¬ì›ì— ëŒ€í•´ ì•„ë˜ì˜ ê²°ê³¼ë¥¼ ì‚°ì¶œí•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ë³´ì. 123---------------------------------------------------------------------------------------ì‚¬ë²ˆ ì‚¬ì›ëª… jobëª…ì¹­ jobì‹œì‘ì¼ì jobì¢…ë£Œì¼ì jobìˆ˜í–‰ë¶€ì„œëª…--------------------------------------------------------------------------------------- A1.1234567891011121314SELECT a.employee_id ì‚¬ë²ˆ , a.emp_name ì‚¬ì›ëª… , b.job_title job ëª…ì¹­ , c.start_date job ì‹œì‘ì¼ì , c.end_date job ì¢…ë£Œì¼ì , d.department_name FROM employees a , jobs b , job_history c , departments d WHERE a.employee_id = c.employee_id AND b.job_id = c.job_id AND c.department_id = d.department_id AND a.employee_id = 101; í•„ìš”í•œ ì»¬ëŸ¼ ë° í…Œì´ë¸” ì‚¬ë²ˆ(employee_id), ì‚¬ì›ëª…(emp_name) â†’ employees jobëª…ì¹­(job_title) â†’ jobs jobì‹œì‘ì¼ì(start_date), jobì¢…ë£Œì¼ì(end_date) â†’ job_history jobìˆ˜í–‰ë¶€ì„œëª…(department_name) â†’ departments í…Œì´ë¸” ì¡°ì¸ ì¡°ê±´ employees &amp; job_history â†’ employee_id jobs &amp; job_history â†’ job_id job_history &amp; departments â†’ department_id ê¸°íƒ€ ì¡°ê±´ 101ë²ˆ ì‚¬ì›ì— ëŒ€í•œ ì •ë³´ : a.employee_id = 101 Q2.ì•„ë˜ì˜ ì¿¼ë¦¬ë¥¼ ìˆ˜í–‰í•˜ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤. ì˜¤ë¥˜ì˜ ì›ì¸ì€ ë¬´ì—‡ì¸ê°€? 12345select a.employee_id, a.emp_name, b.job_id, b.department_idfrom employees a,job_history bwhere a.employee_id = b.employee_id(+)and a.department_id(+) = b.department_id; A2.(+) ì—°ì‚°ìë¥¼ í™œìš©í•œ ì™¸ë¶€ ì¡°ì¸ì˜ ê²½ìš° í•œìª½ ë°©í–¥ìœ¼ë¡œë§Œ ê°€ëŠ¥í•˜ê³ , ì´ë•Œ (+) ì—°ì‚°ìëŠ” ë°ì´í„°ê°€ ì—†ëŠ” í…Œì´ë¸”ì˜ ì»¬ëŸ¼ì—ë§Œ ë¶™ì—¬ì•¼ í•œë‹¤. ë”°ë¼ì„œ, ìœ„ì˜ ì¿¼ë¦¬ì—ì„œëŠ” ë§ˆì§€ë§‰ ì¤„ì„ and a.department_id = b.department_id(+)ë¡œ ìˆ˜ì •í•´ì•¼ í•œë‹¤. Q3.ì™¸ë¶€ì¡°ì¸ì‹œ (+)ì—°ì‚°ìë¥¼ ê°™ì´ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ”ë°, INì ˆì— ì‚¬ìš©í•˜ëŠ” ê°’ì´ 1ê°œì¸ ê²½ìš°ëŠ” ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œ? A3.INì ˆì— ì‚¬ìš©í•˜ëŠ” ê°’ì´ 1ê°œì¸ ê²½ìš°ëŠ” ë“±í˜¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ê°™ì€ ì˜ë¯¸ì´ë¯€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. Q4.ë‹¤ìŒì˜ ì¿¼ë¦¬ë¥¼ ANSI ë¬¸ë²•ìœ¼ë¡œ ë³€ê²½í•´ ë³´ì. 1234567SELECT a.department_id , a.department_name FROM departments a , employees b WHERE a.department_id = b.department_id AND b.salary &gt; 3000 ORDER BY a.department_name; A4.123456SELECT a.department_id, a.department_name FROM departments a INNER JOIN employees b On (a.department_id = b.department_id AND b.salary &gt; 3000) ORDER BY a.department_name; ìœ„ì˜ ì¿¼ë¦¬ëŠ” departments í…Œì´ë¸”ê³¼ employees í…Œì´ë¸”ì˜ ë‚´ë¶€ ì¡°ì¸ì´ë‹¤. ANSI ë¬¸ë²•ì—ì„œ ë‚´ë¶€ ì¡°ì¸ì€ FROMì ˆì—ì„œ INNER JOIN ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©°,ì¡°ì¸ ì¡°ê±´ì€ ON ì ˆì— ëª…ì‹œí•œë‹¤. Q5.ë‹¤ìŒì€ ì—°ê´€ì„± ìˆëŠ” ì„œë¸Œì¿¼ë¦¬ì´ë‹¤. ì´ë¥¼ ì—°ê´€ì„± ì—†ëŠ” ì„œë¸Œì¿¼ë¦¬ë¡œ ë³€í™˜í•´ ë³´ì. 123456SELECT a.department_id , a.department_name FROM departments a WHERE EXISTS ( SELECT 1 FROM job_history b WHERE a.department_id = b.department_id ); A5.123456SELECT a.department_id , a.department_name FROM departments a WHERE a.department_id IN (SELECT b.department_id FROM job_history b); ìœ„ì˜ ì¿¼ë¦¬ëŠ” job_history í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ” department_idì— ëŒ€í•´departments í…Œì´ë¸”ì˜ department_idì™€ department_nameì„ ì¶œë ¥í•œë‹¤. ì´ë¥¼ ì—°ê´€ì„± ì—†ëŠ” ì„œë¸Œì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ì¡°ì¸ ì¡°ê±´ ëŒ€ì‹  IN ì—°ì‚°ìë¥¼ í†µí•´ ë©”ì¸ ì¿¼ë¦¬ì˜ ì¡°ê±´ìœ¼ë¡œ í™œìš©í–ˆë‹¤. Q6.ì—°ë„ë³„ ì´íƒœë¦¬ ìµœëŒ€ë§¤ì¶œì•¡ê³¼ ì‚¬ì›ì„ ì‘ì„±í•˜ëŠ” ì¿¼ë¦¬ë¥¼ í•™ìŠµí–ˆë‹¤. ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ë§¤ì¶œì•¡, ìµœì†Œë§¤ì¶œì•¡, í•´ë‹¹ ì‚¬ì›ì„ ì¡°íšŒí•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ë³´ì. A6.1234567891011121314151617181920212223242526272829303132333435363738SELECT emp.sales_year , emp.employee_id , emp2.emp_name , emp.amount_sold FROM (SELECT SUBSTR(a.sales_month, 1, 4) AS sales_year , a.employee_id , SUM(a.amount_sold) as amount_sold FROM sales a , customers b , countries c WHERE a.cust_id = b.cust_id AND b.country_id = c.country_id AND c.country_name = &#x27;Italy&#x27; GROUP BY SUBSTR(a.sales_month, 1, 4) , a.employee_id) emp , (SELECT sales_year , MAX(amount_sold) AS max_sold , MIN(amount_sold) AS min_sold FROM (SELECT SUBSTR(a.sales_month, 1, 4) AS sales_year , a.employee_id , SUM(a.amount_sold) as amount_sold FROM sales a , customers b , countries c WHERE a.cust_id = b.cust_id AND b.country_id = c.country_id AND c.country_name = &#x27;Italy&#x27; GROUP BY SUBSTR(a.sales_month, 1, 4) , a.employee_id) k GROUP BY sales_year) sale , employees emp2 WHERE emp.sales_year = sale.sales_year AND (emp.amount_sold = sale.max_sold OR emp.amount_sold = sale.min_sold) AND emp.employee_id = emp2.employee_id ORDER BY sales_year; ì„œë¸Œì¿¼ë¦¬ 1 : ì—°ë„, ì‚¬ì›ë³„ ì´íƒˆë¦¬ì•„ ë§¤ì¶œì•¡ (emp) sales, customers, countriesë¥¼ ì¡°ì¸í•˜ì—¬ ë§¤ì¶œì•¡ í•©ê³„ ê³„ì‚° 123456789101112SELECT SUBSTR(a.sales_month, 1, 4) AS sales_year , a.employee_id , SUM(a.amount_sold) as amount_sold FROM sales a , customers b , countries c WHERE a.cust_id = b.cust_id AND b.country_id = c.country_id AND c.country_name = &#x27;Italy&#x27; GROUP BY SUBSTR(a.sales_month, 1, 4) , a.employee_id ì„œë¸Œì¿¼ë¦¬ 2: ì—°ë„ë³„ ìµœëŒ€, ìµœì†Œ ë§¤ì¶œì•¡ (sale) emp ì„œë¸Œì¿¼ë¦¬ì—ì„œ ì—°ë„ë³„ ìµœëŒ€, ìµœì†Œê°’ ê³„ì‚° 12345678910111213141516SELECT sales_year , MAX(amount_sold) AS max_sold , MIN(amount_sold) AS min_sold FROM (SELECT SUBSTR(a.sales_month, 1, 4) AS sales_year , a.employee_id , SUM(a.amount_sold) as amount_sold FROM sales a , customers b , countries c WHERE a.cust_id = b.cust_id AND b.country_id = c.country_id AND c.country_name = &#x27;Italy&#x27; GROUP BY SUBSTR(a.sales_month, 1, 4) , a.employee_id) k GROUP BY sales_year CHAPTER 07Q1.ê³„ì¸µí˜• ì¿¼ë¦¬ ì‘ìš©í¸ì—ì„œ LISTAGG í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ ë‹¤ìŒê³¼ ê°™ì´ ë¡œìš°ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬í–ˆì—ˆë‹¤. 12345SELECT department_id,LISTAGG(emp_name, &#x27;,&#x27;) WITHIN GROUP (ORDER BY emp_name) as empnamesFROM employeesWHERE department_id IS NOT NULLGROUP BY department_id; LISTAGG í•¨ìˆ˜ ëŒ€ì‹  ê³„ì¸µí˜• ì¿¼ë¦¬, ë¶„ì„í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ìœ„ ì¿¼ë¦¬ì™€ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì‚°ì¶œí•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ë³´ì. A1.123456789101112131415SELECT department_id , SUBSTR(SYS_CONNECT_BY_PATH(emp_name, &#x27;,&#x27;),2) empnames FROM ( SELECT emp_name , department_id , COUNT(*) OVER (PARTITION BY department_id) cnt , ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY emp_name) rowseq FROM employees WHERE department_id IS NOT NULL ) WHERE rowseq = cnt START WITH rowseq = 1 CONNECT BY PRIOR rowseq + 1 = rowseq AND PRIOR department_id = department_id; ì„œë¸Œì¿¼ë¦¬ : ë¶€ì„œë³„ ì‚¬ì›ëª…, ì‚¬ì› ìˆ˜, í–‰ ë²ˆí˜¸ êµ¬í•˜ê¸° ë¶€ì„œë³„ íŒŒí‹°ì…˜ : PARTITION BY department_id ORDER BY emp_name 1234567SELECT emp_name , department_id , COUNT(*) OVER (PARTITION BY department_id) cnt , ROW_NUMBER() OVER (PARTITION BY department_id ORDER BY emp_name) rowseq FROM employees WHERE department_id IS NOT NULL ê° íŒŒí‹°ì…˜ì˜ ë§ˆì§€ë§‰ í–‰ì— ëŒ€í•˜ì—¬(WHERE rowseq = cnt)íŒŒí‹°ì…˜ì˜ ì²« í–‰ë¶€í„°(START WITH rowseq = 1)ë¶€ì„œë²ˆí˜¸ê°€ ê°™ì€ ì§ì „ í–‰ê¹Œì§€(CONNECT BY PRIOR rowseq + 1 = rowseq AND PRIOR department_id = department_id)ì˜ emp_nameì„ì—°ê²°í•˜ì—¬ ë‚˜íƒ€ë‚¸ë‹¤.(SUBSTR(SYS_CONNECT_BY_PATH(emp_name, &#39;,&#39;),2)) Q2.ì•„ë˜ì˜ ì¿¼ë¦¬ëŠ” ì‚¬ì›í…Œì´ë¸”ì—ì„œ JOB_IDê°€ â€˜SH_CLERKâ€˜ì¸ ì‚¬ì›ì„ ì¡°íšŒí•˜ëŠ” ì¿¼ë¦¬ì´ë‹¤. 12345678910111213141516SELECT employee_id, emp_name, hire_dateFROM employeesWHERE job_id = &#x27;SH_CLERK&#x27;ORDER By hire_date;EMPLOYEE_ID EMP_NAME HIRE_DATE ----------- -------------------- ------------------- 184 Nandita Sarchand 2004/01/27 00:00:00 192 Sarah Bell 2004/02/04 00:00:00 185 Alexis Bull 2005/02/20 00:00:00 193 Britney Everett 2005/03/03 00:00:00 188 Kelly Chung 2005/06/14 00:00:00.... .... 199 Douglas Grant 2008/01/13 00:00:00 183 Girard Geoni 2008/02/03 00:00:00 ì‚¬ì›í…Œì´ë¸”ì—ì„œ í‡´ì‚¬ì¼ì(retire_date)ëŠ” ëª¨ë‘ ë¹„ì–´ìˆëŠ”ë°,ìœ„ ê²°ê³¼ì—ì„œ ì‚¬ì›ë²ˆí˜¸ê°€ 184ì¸ ì‚¬ì›ì˜ í‡´ì‚¬ì¼ìëŠ” ë‹¤ìŒìœ¼ë¡œ ì…ì‚¬ì¼ìê°€ ë¹ ë¥¸ 192ë²ˆ ì‚¬ì›ì˜ ì…ì‚¬ì¼ìë¼ê³  ê°€ì •í•´ì„œë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ì¶”ì¶œí•´ë‚¼ ìˆ˜ ìˆë„ë¡ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ë³´ì. (ì…ì‚¬ì¼ìê°€ ê°€ì¥ ìµœê·¼ì¸ 183ë²ˆ ì‚¬ì›ì˜ í‡´ì‚¬ì¼ìëŠ” NULLì´ë‹¤) 1234567891011EMPLOYEE_ID EMP_NAME HIRE_DATE RETIRE_DATE----------- -------------------- ------------------- --------------------------- 184 Nandita Sarchand 2004/01/27 00:00:00 2004/02/04 00:00:00 192 Sarah Bell 2004/02/04 00:00:00 2005/02/20 00:00:00 185 Alexis Bull 2005/02/20 00:00:00 2005/03/03 00:00:00 193 Britney Everett 2005/03/03 00:00:00 2005/06/14 00:00:00 188 Kelly Chung 2005/06/14 00:00:00 2005/08/13 00:00:00.... .... 199 Douglas Grant 2008/01/13 00:00:00 2008/02/03 00:00:00 183 Girard Geoni 2008/02/03 00:00:00 A2.123456789SELECT employee_id , emp_name , hire_date , LEAD(hire_date) OVER (PARTITION BY job_id ORDER BY hire_date) AS retire_date FROM employees WHERE job_id = &#x27;SH_CLERK&#x27; ORDER BY hire_date; ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” í‡´ì‚¬ì¼ì(retire_date)ëŠ”ì…ì‚¬ì¼ìë¡œ ì •ë ¬í–ˆì„ ë•Œ ë‹¤ìŒ ì‚¬ì›ì˜ ì…ì‚¬ì¼ì(hire_date)ì™€ ê°™ë‹¤. ë”°ë¼ì„œ, ë‹¤ìŒ í–‰ì˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” LEAD(hire_date) í•¨ìˆ˜ë¥¼ í†µí•´ê° ì‚¬ì›ì˜ í‡´ì‚¬ì¼ì(retire_date)ë¥¼ ì‚°ì¶œí•  ìˆ˜ ìˆë‹¤. Q3.sales í…Œì´ë¸”ì—ëŠ” íŒë§¤ë°ì´í„°, customers í…Œì´ë¸”ì—ëŠ” ê³ ê°ì •ë³´ê°€ ìˆë‹¤.2001ë…„ 12ì›” íŒë§¤ë°ì´í„° ì¤‘ í˜„ì¬ì¼ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³ ê°ì˜ ë‚˜ì´ë¥¼ ê³„ì‚°í•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ ì—°ë ¹ëŒ€ë³„ ë§¤ì¶œê¸ˆì•¡ì„ ë³´ì—¬ì£¼ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ë³´ì. 12345678------------------------- ì—°ë ¹ëŒ€ ë§¤ì¶œê¸ˆì•¡-------------------------10ëŒ€ xxxxxx20ëŒ€ ....30ëŒ€ .... 40ëŒ€ ....------------------------- A3.12345678910111213141516WITH age_amt AS ( SELECT TRUNC((TO_CHAR(SYSDATE, &#x27;yyyy&#x27;) - b.cust_year_of_birth), -1) AS age_seg , SUM(a.amount_sold) AS amount FROM sales a , customers b WHERE a.sales_month = &#x27;200112&#x27; AND a.cust_id = b.cust_id GROUP BY TRUNC((TO_CHAR(SYSDATE, &#x27;yyyy&#x27;) - b.cust_year_of_birth), -1) )SELECT * FROM age_amt ORDER BY age_seg; ì„œë¸Œì¿¼ë¦¬ : í˜„ì¬ì¼ì ê¸°ì¤€ ê³ ê° ì—°ë ¹ëŒ€ë³„ ë§¤ì¶œì•¡ êµ¬í•˜ê¸° (age_amt) í˜„ì¬ì¼ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³ ê°ì˜ ë‚˜ì´ë¥¼ ê³„ì‚°í•œ ë‹¤ìŒ(TO_CHAR(SYSDATE, &#39;yyyy&#39;) - b.cust_year_of_birth)ê° ì—°ë ¹ëŒ€ë³„ amount_soldì˜ í•©ê³„ë¥¼ ê³„ì‚°í•˜ì˜€ìŒ 1234567891011SELECT TRUNC((TO_CHAR(SYSDATE, &#x27;yyyy&#x27;) - b.cust_year_of_birth), -1) AS age_seg , SUM(a.amount_sold) AS amount FROM sales a , customers b WHERE a.sales_month = &#x27;200112&#x27; AND a.cust_id = b.cust_id GROUP BY TRUNC((TO_CHAR(SYSDATE, &#x27;yyyy&#x27;) - b.cust_year_of_birth), -1) Q4.ì›”ë³„ë¡œ íŒë§¤ê¸ˆì•¡ì´ ê°€ì¥ í•˜ìœ„ì— ì†í•˜ëŠ” ëŒ€ë¥™ ëª©ë¡ì„ ë½‘ì•„ë³´ì.(ëŒ€ë¥™ëª©ë¡ì€ countries í…Œì´ë¸”ì˜ country_regionì— ìˆìœ¼ë©°, country_id ì»¬ëŸ¼ìœ¼ë¡œ customers í…Œì´ë¸”ê³¼ ì¡°ì¸ì„ í•´ì„œ êµ¬í•œë‹¤.) 1234567--------------------------------- ë§¤ì¶œì›” ì§€ì—­(ëŒ€ë¥™) ë§¤ì¶œê¸ˆì•¡ ---------------------------------199801 Oceania xxxxxx199803 Oceania xxxxxx...--------------------------------- A4.12345678910111213141516171819202122232425WITH basis AS ( SELECT a.sales_month , c.country_region , SUM(a.amount_sold) as amt FROM sales a , customers b , countries c WHERE a.cust_id = b.cust_id AND b.country_id = c.country_id GROUP BY a.sales_month, c.country_region ) , month_amt AS ( SELECT sales_month AS &quot;ë§¤ì¶œì›”&quot; , country_region AS &quot;ì§€ì—­(ëŒ€ë¥™)&quot; , amt AS &quot;ë§¤ì¶œê¸ˆì•¡&quot; , RANK() OVER (PARTITION BY sales_month ORDER BY amt) AS ranks FROM basis )SELECT &quot;ë§¤ì¶œì›”&quot;, &quot;ì§€ì—­(ëŒ€ë¥™)&quot;, &quot;ë§¤ì¶œê¸ˆì•¡&quot; FROM month_amt WHERE ranks = 1; ì„œë¸Œì¿¼ë¦¬ 1 : ì›”ë³„, ì§€ì—­ë³„ íŒë§¤ê¸ˆì•¡ í•©ê³„ êµ¬í•˜ê¸° (basis) sales, customers, countries ì¡°ì¸ ì›”ë³„, ì§€ì—­ë³„ í•©ê³„ : SUM(a.amount_sold) as amt 123456789SELECT a.sales_month , c.country_region , SUM(a.amount_sold) as amt FROM sales a , customers b , countries c WHERE a.cust_id = b.cust_id AND b.country_id = c.country_id GROUP BY a.sales_month, c.country_region ì„œë¸Œì¿¼ë¦¬ 2 : ì›”ë³„ë¡œ ê° ëŒ€ë¥™ì˜ íŒë§¤ê¸ˆì•¡ í•©ê³„ ìˆœìœ„ êµ¬í•˜ê¸° (month_amt) basis ì„œë¸Œì¿¼ë¦¬ì—ì„œ sales_month íŒŒí‹°ì…˜ë³„ amt ìˆœìœ„ê°’ ê³„ì‚° 1234567SELECT sales_month AS &quot;ë§¤ì¶œì›”&quot; , country_region AS &quot;ì§€ì—­(ëŒ€ë¥™)&quot; , amt AS &quot;ë§¤ì¶œê¸ˆì•¡&quot; , RANK() OVER (PARTITION BY sales_month ORDER BY amt) AS ranks FROM basis Q5.5ì¥ ì—°ìŠµë¬¸ì œ 5ë²ˆì˜ ì •ë‹µ ê²°ê³¼ë¥¼ ì´ìš©í•´ ë‹¤ìŒê³¼ ê°™ì´ ì§€ì—­ë³„, ëŒ€ì¶œì¢…ë¥˜ë³„, ì›”ë³„ ëŒ€ì¶œì”ì•¡ê³¼ ì§€ì—­ë³„ íŒŒí‹°ì…˜ì„ ë§Œë“¤ì–´ëŒ€ì¶œì¢…ë¥˜ë³„ ëŒ€ì¶œì”ì•¡ì˜ %ë¥¼ êµ¬í•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ë³´ì. 123456789------------------------------------------------------------------------------------------------ì§€ì—­ ëŒ€ì¶œì¢…ë¥˜ 201111 201112 201210 201211 201212 203110 201311------------------------------------------------------------------------------------------------ì„œìš¸ ê¸°íƒ€ëŒ€ì¶œ 73996.9( 36% )ì„œìš¸ ì£¼íƒë‹´ë³´ëŒ€ì¶œ 130105.9( 64% ) ë¶€ì‚°......------------------------------------------------------------------------------------------------- A5.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354WITH basis AS ( SELECT region, gubun , CASE WHEN period = &#x27;201111&#x27; THEN loan_jan_amt ELSE 0 END amt1 , CASE WHEN period = &#x27;201112&#x27; THEN loan_jan_amt ELSE 0 END amt2 , CASE WHEN period = &#x27;201210&#x27; THEN loan_jan_amt ELSE 0 END amt3 , CASE WHEN period = &#x27;201211&#x27; THEN loan_jan_amt ELSE 0 END amt4 , CASE WHEN period = &#x27;201212&#x27; THEN loan_jan_amt ELSE 0 END amt5 , CASE WHEN period = &#x27;201310&#x27; THEN loan_jan_amt ELSE 0 END amt6 , CASE WHEN period = &#x27;201311&#x27; THEN loan_jan_amt ELSE 0 END amt7 FROM kor_loan_status ) , sum_amt AS ( SELECT region, gubun , SUM(amt1) AS amt1 , SUM(amt2) AS amt2 , SUM(amt3) AS amt3 , SUM(amt4) AS amt4 , SUM(amt5) AS amt5 , SUM(amt6) AS amt6 , SUM(amt7) AS amt7 FROM basis GROUP BY region, gubun )SELECT region AS &quot;ì§€ì—­&quot;, gubun AS &quot;ëŒ€ì¶œì¢…ë¥˜&quot; , amt1 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt1) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201111&quot; , amt2 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt2) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201112&quot; , amt3 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt3) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201210&quot; , amt4 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt4) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201211&quot; , amt5 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt5) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201212&quot; , amt6 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt6) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201311&quot; , amt7 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt7) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201311&quot; FROM sum_amt ORDER BY region; ì„œë¸Œì¿¼ë¦¬ 1 : ì›”ë³„ ëŒ€ì¶œì”ì•¡ ë³€ìˆ˜ ë§Œë“¤ê¸° (basis) CASE WHEN ~ THEN ~ ELSE êµ¬ë¬¸ìœ¼ë¡œ ì›”ë³„ ëŒ€ì¶œì”ì•¡ ë³€ìˆ˜ ìƒì„± 12345678910111213141516SELECT region, gubun , CASE WHEN period = &#x27;201111&#x27; THEN loan_jan_amt ELSE 0 END amt1 , CASE WHEN period = &#x27;201112&#x27; THEN loan_jan_amt ELSE 0 END amt2 , CASE WHEN period = &#x27;201210&#x27; THEN loan_jan_amt ELSE 0 END amt3 , CASE WHEN period = &#x27;201211&#x27; THEN loan_jan_amt ELSE 0 END amt4 , CASE WHEN period = &#x27;201212&#x27; THEN loan_jan_amt ELSE 0 END amt5 , CASE WHEN period = &#x27;201310&#x27; THEN loan_jan_amt ELSE 0 END amt6 , CASE WHEN period = &#x27;201311&#x27; THEN loan_jan_amt ELSE 0 END amt7 FROM kor_loan_status ì„œë¸Œì¿¼ë¦¬ 2 : ì§€ì—­, êµ¬ë¶„ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì›”ë³„ í•©ê³„ ì‚°ì¶œ (sum_amt) 1234567SELECT region, gubun , SUM(amt1) AS amt1, SUM(amt2) AS amt2 , SUM(amt3) AS amt3, SUM(amt4) AS amt4 , SUM(amt5) AS amt5, SUM(amt6) AS amt6 , SUM(amt7) AS amt7 FROM basis GROUP BY region, gubun ë©”ì¸ ì¿¼ë¦¬ : ì§€ì—­ ë‚´ ëŒ€ì¶œì¢…ë¥˜ë³„ ëŒ€ì¶œì”ì•¡ì˜ ë¹„ìœ¨ ì‚°ì¶œ 1234567891011121314151617SELECT region AS &quot;ì§€ì—­&quot;, gubun AS &quot;ëŒ€ì¶œì¢…ë¥˜&quot; , amt1 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt1) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201111&quot; , amt2 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt2) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201112&quot; , amt3 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt3) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201210&quot; , amt4 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt4) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201211&quot; , amt5 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt5) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201212&quot; , amt6 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt6) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201311&quot; , amt7 || &#x27;(&#x27; || ROUND(RATIO_TO_REPORT(amt7) OVER (PARTITION BY region), 3) *100 || &#x27;%)&#x27; AS &quot;201311&quot; FROM sum_amt ORDER BY region","categories":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/tags/sql/"},{"name":"oracle","slug":"oracle","permalink":"http://gonekng.github.io/tags/oracle/"}],"author":"Jiwon Kang"},{"title":"SQL Developer ê¹ƒí—ˆë¸Œ ì—°ë™í•˜ê¸°","slug":"SQL/Conneting SQL Developer with Github","date":"2022-04-26T07:02:41.000Z","updated":"2022-11-16T15:25:13.586Z","comments":true,"path":"2022/04/26/SQL/Conneting SQL Developer with Github/","link":"","permalink":"http://gonekng.github.io/2022/04/26/SQL/Conneting%20SQL%20Developer%20with%20Github/","excerpt":"","text":"Step 1. Github ì¤€ë¹„ Githubì—ì„œ SQL Developerì™€ ì—°ë™í•  ìƒˆë¡œìš´ Public Repositoryë¥¼ ìƒì„±í•œë‹¤. Settings &gt; Developer settings ì—ì„œ ìƒˆë¡œìš´ Personal access tokenì„ ë°œê¸‰ë°›ëŠ”ë‹¤. ìƒˆë¡œ ìƒì„±í•œ Repositoryì˜ ì´ë¦„ì„ ì…ë ¥í•˜ê³  Select scopesì—ì„œ repoë¥¼ ì²´í¬í•œ í›„ í† í°ì„ ìƒì„±í•œë‹¤. ì´ë•Œ ìƒì„±ëœ í† í° ë²ˆí˜¸ëŠ” ë‹¤ì‹œ ì•Œ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì—, ë°œê¸‰ ì¦‰ì‹œ ë³µì‚¬í•˜ì—¬ ë‹¤ë¥¸ ê³³ì— ì €ì¥í•´ë‘ì–´ì•¼ í•¨ Step 2. SQL Developer Git ë³µì œ SQL Developerì—ì„œ íŒ€ &gt; Git &gt; ë³µì œ ë¥¼ í´ë¦­í•˜ì—¬ ë³µì œ ë§ˆë²•ì‚¬ë¥¼ ì‹¤í–‰í•œë‹¤. ë‹¤ìŒ ë²„íŠ¼ì„ í´ë¦­í•œë‹¤. ì•ì„œ ìƒì„±í•œ Repositoryì˜ URLì„ ì…ë ¥í•˜ê³  Github ì‚¬ìš©ì ì´ë¦„ ë° ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•œë‹¤. main ë¶„ê¸°ë¥¼ ì„ íƒí•œ í›„ ë‹¤ìŒ ë²„íŠ¼ì„ í´ë¦­í•œë‹¤. ë¡œì»¬ Git ì €ì¥ì†Œ ê²½ë¡œ ë° ì´ë¦„ì„ ì§€ì •í•œë‹¤. ì…ë ¥í•œ ì •ë³´ë¥¼ í™•ì¸í•œ í›„ ì™„ë£Œ ë²„íŠ¼ì„ í´ë¦­í•œë‹¤. Step 3. Git Push í…ŒìŠ¤íŠ¸ SQL Developerì—ì„œ íŒŒì¼ &gt; ìƒˆë¡œ ë§Œë“¤ê¸° &gt; ëª¨ë“  í•­ëª© ì„ í´ë¦­í•˜ì—¬ SQL íŒŒì¼ì„ ìƒì„±í•œë‹¤. ìƒˆë¡œìš´ íŒŒì¼ì˜ ì´ë¦„ì„ ì…ë ¥í•œ í›„ ë””ë ‰í† ë¦¬ì—ëŠ” Githubì™€ ì—°ê²°í•œ ë¡œì»¬ í´ë”ë¥¼ ì§€ì •í•œë‹¤. ê°„ë‹¨í•œ SQL ì¿¼ë¦¬ë¥¼ ì‘ì„±, ì‹¤í–‰, ì €ì¥í•œ ë‹¤ìŒ íŒ€ &gt; Git &gt; ëª¨ë‘ ì»¤ë°‹ ì„ í´ë¦­í•œë‹¤. ì‘ì„±ìì™€ ì»¤ë°‹í•œ ì‚¬ëŒì— ì´ë¦„ì„ ì…ë ¥í•œ ë‹¤ìŒ í™•ì¸ ë²„íŠ¼ì„ í´ë¦­í•œë‹¤. íŒ€ &gt; Git &gt; í‘¸ì‹œ ë¥¼ í´ë¦­í•˜ì—¬ í‘¸ì‹œ ë§ˆë²•ì‚¬ë¥¼ ì‹¤í–‰í•œë‹¤. í‘¸ì‹œ ë§ˆë²•ì‚¬ì˜ ì•ˆë‚´ì— ë”°ë¼ ì§„í–‰í•œë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí•  ê²½ìš° Step 2ì˜ Git ë³µì œ ë§ˆë²•ì‚¬ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ê³ , Github ë¹„ë°€ë²ˆí˜¸ì— ì•ì„œ ë°œê¸‰ë°›ì€ í† í° ë²ˆí˜¸ë¥¼ ì…ë ¥í•œë‹¤. Perform the push operation again and check that it is uploaded normally.","categories":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/categories/sql/"}],"tags":[{"name":"github","slug":"github","permalink":"http://gonekng.github.io/tags/github/"},{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/tags/sql/"},{"name":"oracle","slug":"oracle","permalink":"http://gonekng.github.io/tags/oracle/"}],"author":"Jiwon Kang"},{"title":"Oracle 19c Installation in Windows11","slug":"SQL/Oracle 19c Installation in Windows11","date":"2022-04-25T08:27:10.000Z","updated":"2022-11-16T15:15:02.904Z","comments":true,"path":"2022/04/25/SQL/Oracle 19c Installation in Windows11/","link":"","permalink":"http://gonekng.github.io/2022/04/25/SQL/Oracle%2019c%20Installation%20in%20Windows11/","excerpt":"","text":"Step 1. Install Oracle Database Run the setup file as administrator and follow the procedure below. If the following error occurs, go back to the beginning and change to â€˜Software Only Settingsâ€™. Creating and configuring a single instance database : Installing myoracle and database Software Only Settings : Installing myoracle only Run a cmd as administrator and enter the code below. (if you changed to â€˜Software Only Settingsâ€™.) C:\\sql_lecture\\WINDOWS.X64_193000_db_home&gt;**dbca** If the error above occurs again, proceed as follows. Step 2. Create Tablespace by SQL Plus Run SQL Plus as administrator and enter the username and password. Enter the SQL code below. 12# Create a new tablespaceCREATE TABLESPACE myts DATAFILE &#x27;C:\\sql_lecture\\oradata\\MYORACLE\\myts.dbf&#x27; SIZE 100M AUTOEXTEND ON NEXT 5M; 12# Create a new userCREATE USER ora_user IDENTIFIED BY jiwon DEFAULT TABLESPACE MYTS TEMPORARY TABLESPACE TEMP; 1234# Grant a DBA role to the userGRANT DBA TO ora_user;ê¶Œí•œì´ ë¶€ì—¬ë˜ì—ˆìŠµë‹ˆë‹¤. 1234# Connect to the database as the userconnect ora_user/jiwon;ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤. 123456# Print out the currently logged-in usernameselect user from dual;USER--------------------------------------------------------------------------------ORA_USER Step 3. Install SQL Developer Run the setup file. Click No if the warning below occurs. Run a CMD as administrator and enter the code below. C:\\WINDOWS\\system32&gt;lsnrctl status If an Unknown error occurs as described above, run the Net Configuration Assistant. If you input the code at the CMD again, the listener information is printed normally. Create a new Database Access. Tool &gt; Setting &gt; Database &gt; NLS Enter YYYY/MM/DD HH24:MI:SS in â€˜Time Record Formatâ€™. Write the query below and check the result. 1SELECT user from DUAL; Create a backup folder under the C drive and download expall.dmp and expcust.dmp URL : https://github.com/gilbutITbook/006696/tree/master/01ì¥ í™˜ê²½ì„¤ì • Run a CMD as administrator and enter the code below at the backup folder. 1imp ora_user/evan file=expall.dmp log=empall.log ignore=y grants=y rows=y indexes=y full=y 1imp ora_user/evan file=expcust.dmp log=expcust.log ignore=y grants=y rows=y indexes=y full=y Write the query below and check the result. 1SELECT table_name FROM user_tables; In SQL Plus, make sure that the user is created correctly.","categories":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/categories/sql/"}],"tags":[{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/tags/sql/"},{"name":"oracle","slug":"oracle","permalink":"http://gonekng.github.io/tags/oracle/"}],"author":"Jiwon Kang"},{"title":"Crawling Music Chart Top100","slug":"Python/Crawling/Crawling Music Chart Top100","date":"2022-04-22T08:10:19.000Z","updated":"2022-10-05T05:39:51.855Z","comments":true,"path":"2022/04/22/Python/Crawling/Crawling Music Chart Top100/","link":"","permalink":"http://gonekng.github.io/2022/04/22/Python/Crawling/Crawling%20Music%20Chart%20Top100/","excerpt":"","text":"Website Info Request URL : https://music.bugs.co.kr/chart Request Method : GET User-Agent: Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;100.0.4896.127 Safari&#x2F;537.36 Crawling Code step03_bugsTop100.py 12345678910111213141516171819202122232425262728293031323334353637383940import requestsimport warningsfrom bs4 import BeautifulSoupwarnings.filterwarnings(&#x27;ignore&#x27;)import pandas as pddef crawling(soup): chart = soup.find(&quot;table&quot;, class_=&quot;list trackList byChart&quot;) titles = [] artists = [] for p in chart.find_all(&quot;p&quot;, class_=&quot;title&quot;): titles.append(p.get_text()[1:-1]) for p in chart.find_all(&quot;p&quot;, class_=&quot;artist&quot;): artists.append(p.get_text()[1:-1]) return(titles, artists)def df_csv(tp): df = pd.DataFrame(&#123;&quot;title&quot; : tp[0], &quot;artist&quot; : tp[1]&#125;) print(df) df.to_csv(&quot;top100.csv&quot;, index=False) print(&quot;Crawling is done!&quot;)def main(): CUSTOM_HEADER = &#123; &#x27;user-agent&#x27; : &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36&#x27; &#125; url = &#x27;https://music.bugs.co.kr/chart&#x27; req = requests.get(url = url, headers=CUSTOM_HEADER) print(req.status_code) soup = BeautifulSoup(req.text, &#x27;html.parser&#x27;) print(type(soup)) df_csv(crawling(soup))if __name__ == &quot;__main__&quot;: main() top100.csv","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"crawling","slug":"python/crawling","permalink":"http://gonekng.github.io/categories/python/crawling/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"crawling","slug":"crawling","permalink":"http://gonekng.github.io/tags/crawling/"},{"name":"BeautifulSoup","slug":"BeautifulSoup","permalink":"http://gonekng.github.io/tags/BeautifulSoup/"}],"author":"Jiwon Kang"},{"title":"Crawling Headline News","slug":"Python/Crawling/Crawling Headline News","date":"2022-04-22T06:22:10.000Z","updated":"2022-10-05T05:39:51.695Z","comments":true,"path":"2022/04/22/Python/Crawling/Crawling Headline News/","link":"","permalink":"http://gonekng.github.io/2022/04/22/Python/Crawling/Crawling%20Headline%20News/","excerpt":"","text":"Check the Website Info Access Developer Tools of the website and enter the Nework tab. Type ctrl + R and enter the Doc tap. Enter a site and check the Headers tap with the site. Copy the value of referer and user-agent. Crawling Code step01_headlinenews.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445import warningsimport requestsfrom bs4 import BeautifulSoupwarnings.filterwarnings(&#x27;ignore&#x27;)import pandas as pddef crawling(soup): div = soup.find(&quot;div&quot;, class_=&quot;list_issue&quot;) print(type(div)) titles = [] urls = [] for a in div.find_all(&quot;a&quot;): titles.append(a.get_text()) urls.append(a[&#x27;href&#x27;]) results = (titles, urls) return(results)def df_csv(tp): df = pd.DataFrame(&#123;&quot;newstitle&quot; : tp[0], &quot;url&quot; : tp[1]&#125;) print(df) df.to_csv(&quot;headlinecrawling.csv&quot;, index=False) print(&quot;Crawling is done!&quot;)def main(): CUSTOM_HEADER = &#123; &#x27;referer&#x27; : &#x27;https://www.naver.com/&#x27;, &#x27;user-agent&#x27; : &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36&#x27; &#125; url = &#x27;https://www.naver.com/&#x27; req = requests.get(url = url, headers=CUSTOM_HEADER) print(req.status_code) # 200 : Good # 404 : URL Error # 503 : Server Down soup = BeautifulSoup(req.text, &#x27;html.parser&#x27;, from_encoding=&#x27;utf-8&#x27;) df_csv(crawling(soup))if __name__ == &quot;__main__&quot;: main()","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"crawling","slug":"python/crawling","permalink":"http://gonekng.github.io/categories/python/crawling/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"crawling","slug":"crawling","permalink":"http://gonekng.github.io/tags/crawling/"},{"name":"BeautifulSoup","slug":"BeautifulSoup","permalink":"http://gonekng.github.io/tags/BeautifulSoup/"}],"author":"Jiwon Kang"},{"title":"Crawling Data from Web","slug":"Python/Crawling/Crawling Data from Web","date":"2022-04-22T03:39:12.000Z","updated":"2022-10-05T05:39:51.545Z","comments":true,"path":"2022/04/22/Python/Crawling/Crawling Data from Web/","link":"","permalink":"http://gonekng.github.io/2022/04/22/Python/Crawling/Crawling%20Data%20from%20Web/","excerpt":"","text":"Step 1. Set virtual environment Create a new directory under the C drive and virtual environment. 123$ mkdir crawling &amp;&amp; cd crawling$ virtualenv venv$ sourve venv/Scipts/activate Install some required packages. 123$ pip install beautifulsoup4$ pip install numpy pandas matplotlib seaborn$ pip install requests Step 2. Crawling Practice 1 Create a HTML file index.html 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;titl&gt;test&lt;/titl&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;aaaaaaaa&lt;/h1&gt; &lt;h2&gt;dddd&lt;/h2&gt; &lt;div class=&quot;chapter01&quot;&gt; &lt;p&gt;Don&#x27;t Crawl here &lt;/p&gt; &lt;/div&gt; &lt;div class=&quot;chapter02&quot;&gt; &lt;p&gt;Just Crawling here&lt;/p&gt; &lt;/div&gt; &lt;div id=&quot;main&quot;&gt; &lt;p&gt; Crawling .................. &lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Create a python file main.py crawling text from index.html 12345678910111213141516from bs4 import BeautifulSoupdef main(): # Convert index.html to BeautifulSoup Object soup = BeautifulSoup(open(&quot;index.html&quot;, encoding=&#x27;UTF-8&#x27;), &quot;html.parser&quot;) print(type(soup)) print(soup.find(&quot;p&quot;)) print(&quot;----------------&quot;) print(soup.find_all(&quot;p&quot;)) print(&quot;----------------&quot;) print(soup.find(&quot;div&quot;, class_ = &quot;chapter02&quot;)) print(&quot;----------------&quot;) print(soup.find(&quot;div&quot;, id = &quot;main&quot;).find(&quot;p&quot;).get_text())if __name__ == &quot;__main__&quot;: main() Run the main.py and check the result printed. 1234567891011$ python main.py&lt;class &#x27;bs4.BeautifulSoup&#x27;&gt;&lt;p&gt;Don&#x27;t crawl here!&lt;/p&gt;----------------[&lt;p&gt;Don&#x27;t crawl here!&lt;/p&gt;, &lt;p&gt;Just Crawl here!&lt;/p&gt;, &lt;p&gt; Crawling .................. &lt;/p&gt;]----------------&lt;div class=&quot;chapter02&quot;&gt;&lt;p&gt;Just Crawl here!&lt;/p&gt;&lt;/div&gt;---------------- Step 3. Quick Start BeautifulSoup4 URL : https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start index2.html 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt; &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;and &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well. &lt;/p&gt; &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; temp1.py 1234from bs4 import BeautifulSoupsoup = BeautifulSoup(open(&quot;index2.html&quot;), &#x27;html.parser&#x27;)print(soup.prettify()) 123456789101112131415161718192021222324252627282930313233343536$ python temp1.py&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt; The Dormouse&#x27;s story &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;title&quot;&gt; &lt;b&gt; The Dormouse&#x27;s story &lt;/b&gt; &lt;/p&gt; &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; Elsie &lt;/a&gt; , &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt; Lacie &lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt; Tillie &lt;/a&gt; ; and they lived at the bottom of a well. &lt;/p&gt; &lt;p class=&quot;story&quot;&gt; ... &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; temp2.py 1234567891011121314151617181920from bs4 import BeautifulSoupsoup = BeautifulSoup(open(&quot;index2.html&quot;), &#x27;html.parser&#x27;)print(soup.title)print(&quot;----------------&quot;)print(soup.title.name)print(&quot;----------------&quot;)print(soup.title.string)print(&quot;----------------&quot;)print(soup.title.parent.name)print(&quot;----------------&quot;)print(soup.p)print(&quot;----------------&quot;)print(soup.p[&#x27;class&#x27;])print(&quot;----------------&quot;)print(soup.a)print(&quot;----------------&quot;)print(soup.find_all(&#x27;a&#x27;))print(&quot;----------------&quot;)print(soup.find(id=&quot;link3&quot;)) 12345678910111213141516171819$ python temp2.py&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;----------------title----------------The Dormouse&#x27;s story----------------head----------------&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;----------------[&#x27;title&#x27;]----------------&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;----------------[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]----------------&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; temp3.py 1234567from bs4 import BeautifulSoupsoup = BeautifulSoup(open(&quot;index2.html&quot;), &#x27;html.parser&#x27;)for link in soup.find_all(&#x27;a&#x27;): print(link.get(&#x27;href&#x27;))print(soup.get_text()) 1234567891011121314151617$ python temp3.pyhttp://example.com/elsiehttp://example.com/laciehttp://example.com/tillieThe Dormouse&#x27;s storyThe Dormouse&#x27;s story Once upon a time there were three little sisters; and their names were Elsie, Lacieand Tillie; and they lived at the bottom of a well....","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"crawling","slug":"python/crawling","permalink":"http://gonekng.github.io/categories/python/crawling/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"crawling","slug":"crawling","permalink":"http://gonekng.github.io/tags/crawling/"},{"name":"BeautifulSoup","slug":"BeautifulSoup","permalink":"http://gonekng.github.io/tags/BeautifulSoup/"}],"author":"Jiwon Kang"},{"title":"Spark Installation in WSL2","slug":"Setting/Spark Installation in WSL2","date":"2022-04-20T07:39:12.000Z","updated":"2022-10-17T07:24:35.040Z","comments":true,"path":"2022/04/20/Setting/Spark Installation in WSL2/","link":"","permalink":"http://gonekng.github.io/2022/04/20/Setting/Spark%20Installation%20in%20WSL2/","excerpt":"","text":"Step 1. Install required files Install java and spark file. (Skip if already installed.) 123$ sudo apt-get install openjdk-8-jdk$ sudo wget https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz$ sudo tar -xvzf spark-3.2.0-bin-hadoop3.2.tgz Step 2. Set environment variables Open .bashrc file and add the code below. 12345export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64export SPARK_HOME=/mnt/c/hadoop/spark-3.2.0-bin-hadoop3.2export PATH=$JAVA_HOME/bin:$PATHexport PATH=$SPARK_HOME/bin:$PATHexport PYSPARK_PYTHON=/usr/bin/python3 Update the code and make sure itâ€™s actually reflected. 1234source ~/.bashrcecho SPARK_HOME/mnt/c/hadoop/spark-3.2.0-bin-hadoop3.2 Step 3. Run Pyspark Run pyspark in the path. Run the code below in the CMD and check the result printed. 1234&gt;&gt;&gt; rd = sc.textFile(&quot;README.md&quot;)&gt;&gt;&gt; rd.count()109 Step 4. Deploy in Web browser. Create a new directory temp, and virtual environment. 12$ mkdir temp &amp;&amp; cd temp$ virtualenv venv Connect to virtual environment and install pyspark. 12$ source venv/bin/activate$ pip install pyspark Create a new directory and README.md file. 12$ mkdir data &amp;&amp; cd data$ vi README.md *This program just counts the number of lines containing â€˜aâ€™ and the number containing â€˜bâ€™ in a text file. Note that youâ€™ll need to replace YOUR_SPARK_HOME with the location where Spark is installed. As with the Scala and Java examples, we use a SparkSession to create Datasets. For applications that use custom classes or third-party libraries, we can also add code dependencies to spark-submit through its â€“py-files argument by packaging them into a .zip file (see spark-submit â€“help for details). SimpleApp is simple enough that we do not need to specify any code dependencies. We can run this application using the bin&#x2F;spark-submit script:* Back to temp and create SampleApp.py. 12$ cd ..$ vi SampleApp.py 123456789101112131415***# SampleApp.py***from pyspark.sql import SparkSessionlogFile = &quot;data/README.md&quot; # Should be some file on your systemspark = SparkSession.builder.appName(&quot;SimpleApp&quot;).getOrCreate()logData = spark.read.text(logFile).cache()numAs = logData.filter(logData.value.contains(&#x27;a&#x27;)).count()numBs = logData.filter(logData.value.contains(&#x27;b&#x27;)).count()print(&quot;Lines with a: %i, lines with b: %i&quot; % (numAs, numBs))input(&quot;Typing....&quot;)spark.stop() Run the SimpleApp.py 1$SPARK_HOME/bin/spark-submit --master local[4] SimpleApp.py Check the address below and copy it. Enter the corresponding address in the web browser and check the web UI.","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"},{"name":"spark","slug":"spark","permalink":"http://gonekng.github.io/tags/spark/"}],"author":"Jiwon Kang"},{"title":"Spark Installation on Windows11","slug":"Setting/Spark Installation on Windows11","date":"2022-04-19T02:50:39.000Z","updated":"2022-10-17T07:24:41.519Z","comments":true,"path":"2022/04/19/Setting/Spark Installation on Windows11/","link":"","permalink":"http://gonekng.github.io/2022/04/19/Setting/Spark%20Installation%20on%20Windows11/","excerpt":"","text":"Step 1. Install Java DK Download Windows Installer. URL : https://www.oracle.com/java/technologies/javase/javase8u211-later-archive-downloads.html Run the download file as an administrator. Modify the path as shown in the picture below. (Be careful not to include spaces in the path name.) Step 2. Install Spark Download Spark .tgz file. (Click the link in the images below.) URL : https://www.apache.org/dyn/closer.lua/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz Download WinRAR to unzip the .tgz compressed file, and run as an administrator. URL : https://www.rarlab.com/download.htm Open the Spark file with WinRAR and extract to the folder. Rename the folder to spark, and copy and paste under the C drive. Open spark\\conf\\log4j.properties file with memo pad, and change the log4j.rootCategory value from INFO to ERROR. Step 3. Install Winutils Download winutils.exe. (Check the version of Spark.) URL : â€£ Create a foler winutils\\bin, and copy and paste winutils.exe. Run a CMD as an administrator, and write the code below. 1234&gt; cd c:\\winutils\\bin&gt; winutils.exe chmod 777 \\tmp\\hive****ChangeFileModeByMask error (2): ??? ??? ?? ? ????. If the above error occurs, create the tmp\\hive folder under the C drive and run it again. Step 4. Setting environment variables Create a new user variable SPARK_HOME, and set the value as the path of spark folder. Create a new user variable JAVA_HOME, and set the value as the path of jdk folder. Create a new user variable HADOOP_HOME, and set the value as the path of winutils folder. Edit the Path variable Insert %SPARK_HOME%\\bin and %JAVA_HOME%\\bin. Create a new user variable PYSPARK_PYTHON, and set the value as PYTHON. Run a CMD as an administrator, and run pyspark in the c:\\spark path. Run the code below in the CMD and check the result printed. 1234&gt; rd = sc.textFile(&quot;README.md&quot;)&gt; rd.count()109 Create new user variables and set the value. PYSPARK_DRIVER_PYTHON ; jupyter PYSPARK_DRIVER_PYTHON_OPTS ; notebook Reference https://dschloe.github.io/python/python_edu&#x2F;00_settings&#x2F;spark_installation_windows_10&#x2F;","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"spark","slug":"spark","permalink":"http://gonekng.github.io/tags/spark/"}],"author":"Jiwon Kang"},{"title":"ElasticSearch and Kibana Setting in WSL 2","slug":"Setting/ElasticSearch and Kibana Setting in WSL 2","date":"2022-04-15T08:43:10.000Z","updated":"2022-10-17T07:24:05.101Z","comments":true,"path":"2022/04/15/Setting/ElasticSearch and Kibana Setting in WSL 2/","link":"","permalink":"http://gonekng.github.io/2022/04/15/Setting/ElasticSearch%20and%20Kibana%20Setting%20in%20WSL%202/","excerpt":"","text":"Step 1. Install Package Update the system package and install a package related to HTTPS. 12$ sudo apt update$ sudo apt install apt-transport-https Install Java and check the version of Java. 12345$ sudo apt install openjdk-11-jdk$ java -versionopenjdk 11.0.14.1 2022-02-08OpenJDK Runtime Environment (build 11.0.14.1+1-Ubuntu-0ubuntu1.20.04)OpenJDK 64-Bit Server VM (build 11.0.14.1+1-Ubuntu-0ubuntu1.20.04, mixed mode, sharing) Open the vi editor to set the java environment variable. 1$ sudo vi /etc/environment Insert the following sentence in vi editor. JAVA_HOME=&quot;/usr/lib/jvm/java-11-openjdk-amd64&quot; Update the environment variables and check the contents. 1234$ source /etc/environment$ echo $JAVA_HOME/usr/lib/jvm/java-11-openjdk-amd64 Step 2. Install ElasticSearch Check the GPG keys. 123$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key addOK Add a library and install ElasticSearch. 1234$ sudo sh -c &#x27;echo &quot;deb https://artifacts.elastic.co/packages/7.x/apt stable main&quot; &gt; /etc/apt/sources.list.d/elastic-7.x.list&#x27;$ sudo apt-get update$ sudo apt-get install elasticsearch Step 3. Start ElasticSearch Start EleasticSearch 1234$ sudo systemctl start elasticsearchSystem has not been booted with systemd as init system (PID 1). Can&#x27;t operate.Failed to connect to bus: Host is down If the above error is printed, add the following command. 12$ sudo -b unshare --pid --fork --mount-proc /lib/systemd/systemd --system-unit=basic.target$ sudo -E nsenter --all -t $(pgrep -xo systemd) runuser -P -l $USER -c &quot;exec $SHELL&quot; Enable the ElasticSearch and start the service. 123456$ sudo systemctl enable elasticsearchSynchronizing state of elasticsearch.service with SysV service script with /lib/systemd/systemd-sysv-install.Executing: /lib/systemd/systemd-sysv-install enable elasticsearch$ sudo systemctl start elasticsearch Ensure that the service is actually operational. 12345678910111213141516171819$ curl -X GET &quot;localhost:9200/&quot;&#123; &quot;name&quot; : &quot;DESKTOP-JM1I3QF&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;ma7ulQQ_RL-Y3ZNsjz0ZVw&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.17.2&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;deb&quot;, &quot;build_hash&quot; : &quot;de7261de50d90919ae53b0eff9413fd7e5307301&quot;, &quot;build_date&quot; : &quot;2022-03-28T15:12:21.446567561Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.11.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; Check whether it is printed well on the window screen. Step 4. Install and Start Kibana Install and enable Kibana service 12345$ sudo apt-get install kibana$ sudo systemctl enable kibanaSynchronizing state of kibana.service with SysV service script with /lib/systemd/systemd-sysv-install.Executing: /lib/systemd/systemd-sysv-install enable kibana Start Kibana service and check the status 1234567891011121314$ sudo systemctl start kibana$ sudo systemctl status kibanaâ— kibana.service - Kibana Loaded: loaded (/etc/systemd/system/kibana.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2022-04-14 11:53:07 KST; 21min ago Docs: https://www.elastic.co Main PID: 303 (node) Tasks: 11 (limit: 4646) Memory: 599.0M CGroup: /system.slice/kibana.service â””â”€303 /usr/share/kibana/bin/../node/bin/node /usr/share/kibana/bin/../src/cli/dis&gt;Apr 14 11:53:07 DESKTOP-JM1I3QF systemd[1]: Started Kibana. Step 5. Check Kibana WebUI Make sure it connects to ElasticSearch well URL : http://localhost:5601/ Reference https://dschloe.github.io/settings/elasticsearch_kibana_wsl2&#x2F; https://www.how2shout.com/how-to/install-uninstall-elasticsearch-ubuntu-19-04-18-04-16-04.html","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://gonekng.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"http://gonekng.github.io/tags/kibana/"}],"author":"Jiwon Kang"},{"title":"Link VSCode with Remote WSL","slug":"Setting/Link VSCode with Remote WSL","date":"2022-04-15T08:33:16.000Z","updated":"2022-10-17T07:24:54.604Z","comments":true,"path":"2022/04/15/Setting/Link VSCode with Remote WSL/","link":"","permalink":"http://gonekng.github.io/2022/04/15/Setting/Link%20VSCode%20with%20Remote%20WSL/","excerpt":"","text":"Step 1. Install VSCode URL : https://code.visualstudio.com/download Download the System Installer for each OS. Check â€˜Add to PATHâ€™ and reboot after installation. Step 2. Link Remote WSL Install Remote WSL in Extension tab of VSCode. (File tab â†’ Open Folder) Select the airflow-test folder that WSL installed. (Terminal â†’ New Terminal) Open a new terminal and add a WSL terminal. Activate the virtual environment in WSL terminal. Run a python code and check if it is printed well. ex) main.py Reference https://dschloe.github.io/settings/vscode_wsl2&#x2F;","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"},{"name":"vscode","slug":"vscode","permalink":"http://gonekng.github.io/tags/vscode/"}],"author":"Jiwon Kang"},{"title":"Establishing an Airflow Data Pipeline","slug":"Setting/Establishing an Airflow Data Pipeline","date":"2022-04-15T06:38:19.000Z","updated":"2022-10-17T07:24:14.706Z","comments":true,"path":"2022/04/15/Setting/Establishing an Airflow Data Pipeline/","link":"","permalink":"http://gonekng.github.io/2022/04/15/Setting/Establishing%20an%20Airflow%20Data%20Pipeline/","excerpt":"","text":"Step 01. Create a Virtual Data Create dags foler below (venv) airflow-test folder. 1234$ mkdir dags$ lsairflow-webserver.pid airflow.cfg airflow.db dags logs venv webserver_config.py Install the necessary libraries. 1$ pip3 install faker pandas Create data folder and write python file in the folder to create a virtual data. filename : step01_writecsv.py 123$ mkdir data$ cd data$ vi step01_writecsv.py 123456789101112131415161718192021***# step01_writecsv.py***from faker import Fakerimport csvoutput = open(&#x27;data.csv&#x27;,&#x27;w&#x27;)fake = Faker()header = [&#x27;name&#x27;,&#x27;age&#x27;,&#x27;street&#x27;,&#x27;city&#x27;,&#x27;state&#x27;,&#x27;zip&#x27;,&#x27;lng&#x27;,&#x27;lat&#x27;]mywriter = csv.writer(output)mywriter.writerow(header)for r in range(1000): mywriter.writerow([[fake.name](http://fake.name/)(), fake.random_int(min=18, max=80, step=1), fake.street_address(), fake.city(), fake.state(), fake.zipcode(), fake.longitude(), fake.latitude()])output.close() Run the file above and make sure that the data is well generated. 1234$ python3 step01_writecsv.py$ lsdata.csv step01_writecsv.py Step 2. Establish csv2join file Write code to build CSV and JSON transform files in dags folder. filename : csv2join.py 1$ vi csv2json.py 123456789101112131415161718192021222324252627282930313233343536***# csv2join.py***import datetime as dtfrom datetime import timedeltafrom airflow import DAGfrom airflow.operators.bash import BashOperatorfrom airflow.operators.python import PythonOperatorimport pandas as pddef csvToJson(): df=pd.read_csv(&#x27;data/data.csv&#x27;) for i,r in df.iterrows(): print(r[&#x27;name&#x27;]) df.to_json(&#x27;fromAirflow.json&#x27;,orient=&#x27;records&#x27;)default_args = &#123; &#x27;owner&#x27;: &#x27;evan&#x27;, &#x27;start_date&#x27;: dt.datetime(2020, 3, 18), &#x27;retries&#x27;: 1, &#x27;retry_delay&#x27;: dt.timedelta(minutes=5),&#125;with DAG(&#x27;MyCSVDAG&#x27;, default_args=default_args, schedule_interval=timedelta(minutes=5), # &#x27;0 * * * *&#x27;, ) as dag: print_starting = BashOperator(task_id=&#x27;starting&#x27;, bash_command=&#x27;echo &quot;I am reading the CSV now.....&quot;&#x27;) csvJson = PythonOperator(task_id=&#x27;convertCSVtoJson&#x27;, python_callable=csvToJson)print_starting &gt;&gt; csvJson Run the csv2json.py above. 1$ python3 csv2json.py Step 04. Run Webserver and Scheduler Simultaneously Open a separate terminal and run the webserver and scheduler. 12$ airflow webserver -p 8080$ airflow scheduler Check if it works normally in the Web UI. Reference https://dschloe.github.io/python/data_engineering&#x2F;ch03_reading_writing_file&#x2F;airflow_csv2json_sample&#x2F;","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"},{"name":"apache","slug":"apache","permalink":"http://gonekng.github.io/tags/apache/"},{"name":"airflow","slug":"airflow","permalink":"http://gonekng.github.io/tags/airflow/"}],"author":"Jiwon Kang"},{"title":"Apache-Airflow Setting in Windows11 (WSL 2)","slug":"Setting/Apache-Airflow Setting in Windows11 (WSL 2)","date":"2022-04-15T03:10:08.000Z","updated":"2022-10-17T07:23:56.143Z","comments":true,"path":"2022/04/15/Setting/Apache-Airflow Setting in Windows11 (WSL 2)/","link":"","permalink":"http://gonekng.github.io/2022/04/15/Setting/Apache-Airflow%20Setting%20in%20Windows11%20(WSL%202)/","excerpt":"","text":"Step 1. Create a virtual environment Install pip and virtualenv package 12$ sudo apt install python3-pip$ sudo pip3 install virtualenv Create a virtual environment in c:\\airflow-test folder 1234567$ virtualenv venvcreated virtual environment CPython3.8.10.final.0-64 in 29086mscreator CPython3Posix(dest=/mnt/c/airflow-test/venv, clear=False, no_vcs_ignore=False, global=False)seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/donumm/.local/share/virtualenv)added seed packages: pip==22.0.4, setuptools==62.1.0, wheel==0.37.1activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator Open .bashrc file and add the following code. 123$ vi ~/.bashrc*export AIRFLOW_HOME=/mnt/c/airflow-test* Update the code and make sure itâ€™s actually reflected. 1234$ source ~/.bashrc$ echo $AIRFLOW_HOME/mnt/c/airflow-test Connect to virtual environment. 1$ source venv/bin/activate â€» Airflow must be installed in the virtual environment and executed in the virtual environment. Step 4. Install Apache Airflow Install PostgreSQL, Slack, and Celery packages 1pip3 install &#x27;apache-airflow[postgres, slack, celery]&#x27; Initialize the DB to run the airflow. 1$ airflow db init Register an username and password of the airflow 12***# Create a new user***$ airflow users create --username airflow --password airflow --firstname Jiwon --lastname Kang --role Admin --email donumm64@gmail.co 123456***# Check the user list***$ airflow users listid | username | email | first_name | last_name | roles===+==========+====================+============+===========+======1 | donumm | donumm64@gmail.com | Jiwon | Kang | Admin Open airflow.cfg file, and change the value of load_examples from True to False. Reset the db in terminal. 123$ airflow db reset...Proceed? (y/n) Y Run the airflow webserver and scheduler. 12$ airflow webserver -p 8080$ airflow scheduler Connect the airflow webserver. URL : http://localhost:8080/login/ Reference https://dschloe.github.io/settings/apache_airflow_using_wsl2&#x2F;","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"},{"name":"apache","slug":"apache","permalink":"http://gonekng.github.io/tags/apache/"},{"name":"airflow","slug":"airflow","permalink":"http://gonekng.github.io/tags/airflow/"}],"author":"Jiwon Kang"},{"title":"WSL 2 Installation in Windows11","slug":"Setting/WSL 2 Installation in Windows11","date":"2022-04-15T02:43:19.000Z","updated":"2022-10-17T07:24:51.898Z","comments":true,"path":"2022/04/15/Setting/WSL 2 Installation in Windows11/","link":"","permalink":"http://gonekng.github.io/2022/04/15/Setting/WSL%202%20Installation%20in%20Windows11/","excerpt":"","text":"Step 1. Enable WSL-related features by DISM Run Windows Terminal as administrator Enable Microsoft-Windows-Subsystem-Linux Features 1$ dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart Enable the VirtualMachinePlatform feature Reboot if the operation is completed successfully. 1$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart Step 2. WSL2 Kernel Update Install the update file from the link below. URL : https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi Open Windows terminal and change WSL version to 2. 1$ wsl --set-default-version 2 Install Ubuntu, the most popular Linux distribution, and run as administrator. ![](&#x2F;images&#x2F;Setting&#x2F;wsl2&#x2F;Untitled 1.png) In Ubuntu, Set the username and password. Check the currently installed version with wsl -l -v 123$ wsl -l -v NAME STATE VERSION* Ubuntu Running 2 If it says version 1, execute the following command. 12345$ wsl --set-version Ubuntu 2ë³€í™˜ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...WSL 2ì™€ì˜ ì£¼ìš” ì°¨ì´ì ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [https://aka.ms/wsl2ë¥¼](https://aka.ms/wsl2%EB%A5%BC) ì°¸ì¡°í•˜ì„¸ìš”ë³€í™˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. Make sure that it says version 2. 123$ wsl -l -v NAME STATE VERSION* Ubuntu Running 2 Reference https://www.lainyzine.com/ko/article/how-to-install-wsl2-and-use-linux-on-windows-10/#google_vignette","categories":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"}],"tags":[{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"}],"author":"Jiwon Kang"},{"title":"ML Practice 9_3","slug":"Python/ML/ML_ch_9_3","date":"2022-04-08T03:27:01.000Z","updated":"2022-10-05T05:39:54.030Z","comments":true,"path":"2022/04/08/Python/ML/ML_ch_9_3/","link":"","permalink":"http://gonekng.github.io/2022/04/08/Python/ML/ML_ch_9_3/","excerpt":"","text":"LSTM(Long Short-Term Memory) When the sentence is long, the learning ability of RNN is poor. LSTM is designed to keep short-term memory long. 1234567891011from tensorflow.keras.datasets import imdbfrom sklearn.model_selection import train_test_split(train_input, train_target), (test_input, test_target) = imdb.load_data( num_words=500)train_input, val_input, train_target, val_target = train_test_split( train_input, train_target, test_size=0.2, random_state=42)train_input.shape, val_input.shape, train_target.shape, val_target.shape Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz 17465344/17464789 [==============================] - 0s 0us/step 17473536/17464789 [==============================] - 0s 0us/step ((20000,), (5000,), (20000,), (5000,)) 12345from tensorflow.keras.preprocessing.sequence import pad_sequencestrain_seq = pad_sequences(train_input, maxlen=100)val_seq = pad_sequences(val_input, maxlen=100)train_seq.shape, val_seq.shape ((20000, 100), (5000, 100)) 123456from tensorflow import kerasmodel = keras.Sequential()model.add(keras.layers.Embedding(500, 16, input_length=100))model.add(keras.layers.LSTM(8))model.add(keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;))model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 100, 16) 8000 lstm (LSTM) (None, 8) 800 dense (Dense) (None, 1) 9 ================================================================= Total params: 8,809 Trainable params: 8,809 Non-trainable params: 0 _________________________________________________________________ 123456789101112rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model.compile(optimizer=rmsprop, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-lstm-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/100 313/313 [==============================] - 16s 42ms/step - loss: 0.6925 - accuracy: 0.5433 - val_loss: 0.6916 - val_accuracy: 0.5986 Epoch 2/100 313/313 [==============================] - 20s 65ms/step - loss: 0.6902 - accuracy: 0.6076 - val_loss: 0.6883 - val_accuracy: 0.6470 Epoch 3/100 313/313 [==============================] - 16s 50ms/step - loss: 0.6842 - accuracy: 0.6512 - val_loss: 0.6783 - val_accuracy: 0.6680 Epoch 4/100 313/313 [==============================] - 14s 46ms/step - loss: 0.6591 - accuracy: 0.6861 - val_loss: 0.6237 - val_accuracy: 0.7128 Epoch 5/100 313/313 [==============================] - 14s 45ms/step - loss: 0.5975 - accuracy: 0.7211 - val_loss: 0.5842 - val_accuracy: 0.7220 Epoch 6/100 313/313 [==============================] - 16s 51ms/step - loss: 0.5716 - accuracy: 0.7355 - val_loss: 0.5643 - val_accuracy: 0.7408 Epoch 7/100 313/313 [==============================] - 14s 45ms/step - loss: 0.5510 - accuracy: 0.7534 - val_loss: 0.5470 - val_accuracy: 0.7458 Epoch 8/100 313/313 [==============================] - 17s 54ms/step - loss: 0.5328 - accuracy: 0.7619 - val_loss: 0.5319 - val_accuracy: 0.7564 Epoch 9/100 313/313 [==============================] - 14s 44ms/step - loss: 0.5147 - accuracy: 0.7739 - val_loss: 0.5130 - val_accuracy: 0.7724 Epoch 10/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4982 - accuracy: 0.7824 - val_loss: 0.5000 - val_accuracy: 0.7746 Epoch 11/100 313/313 [==============================] - 17s 53ms/step - loss: 0.4837 - accuracy: 0.7909 - val_loss: 0.4874 - val_accuracy: 0.7794 Epoch 12/100 313/313 [==============================] - 15s 47ms/step - loss: 0.4717 - accuracy: 0.7957 - val_loss: 0.4767 - val_accuracy: 0.7868 Epoch 13/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4620 - accuracy: 0.7990 - val_loss: 0.4696 - val_accuracy: 0.7892 Epoch 14/100 313/313 [==============================] - 15s 48ms/step - loss: 0.4534 - accuracy: 0.8033 - val_loss: 0.4662 - val_accuracy: 0.7908 Epoch 15/100 313/313 [==============================] - 15s 48ms/step - loss: 0.4470 - accuracy: 0.8067 - val_loss: 0.4606 - val_accuracy: 0.7946 Epoch 16/100 313/313 [==============================] - 15s 47ms/step - loss: 0.4414 - accuracy: 0.8067 - val_loss: 0.4558 - val_accuracy: 0.7924 Epoch 17/100 313/313 [==============================] - 14s 45ms/step - loss: 0.4366 - accuracy: 0.8087 - val_loss: 0.4516 - val_accuracy: 0.7972 Epoch 18/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4329 - accuracy: 0.8098 - val_loss: 0.4485 - val_accuracy: 0.7968 Epoch 19/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4301 - accuracy: 0.8088 - val_loss: 0.4461 - val_accuracy: 0.7962 Epoch 20/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4274 - accuracy: 0.8093 - val_loss: 0.4456 - val_accuracy: 0.7988 Epoch 21/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4248 - accuracy: 0.8102 - val_loss: 0.4429 - val_accuracy: 0.7994 Epoch 22/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4225 - accuracy: 0.8106 - val_loss: 0.4481 - val_accuracy: 0.7960 Epoch 23/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4211 - accuracy: 0.8117 - val_loss: 0.4417 - val_accuracy: 0.7974 Epoch 24/100 313/313 [==============================] - 12s 39ms/step - loss: 0.4198 - accuracy: 0.8116 - val_loss: 0.4393 - val_accuracy: 0.8010 Epoch 25/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4180 - accuracy: 0.8127 - val_loss: 0.4464 - val_accuracy: 0.7890 Epoch 26/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4173 - accuracy: 0.8130 - val_loss: 0.4400 - val_accuracy: 0.8002 Epoch 27/100 313/313 [==============================] - 12s 39ms/step - loss: 0.4161 - accuracy: 0.8123 - val_loss: 0.4370 - val_accuracy: 0.8018 Epoch 28/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4154 - accuracy: 0.8131 - val_loss: 0.4375 - val_accuracy: 0.8010 Epoch 29/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4143 - accuracy: 0.8127 - val_loss: 0.4361 - val_accuracy: 0.8020 Epoch 30/100 313/313 [==============================] - 14s 45ms/step - loss: 0.4131 - accuracy: 0.8136 - val_loss: 0.4370 - val_accuracy: 0.8022 Epoch 31/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4129 - accuracy: 0.8134 - val_loss: 0.4360 - val_accuracy: 0.8022 Epoch 32/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4126 - accuracy: 0.8141 - val_loss: 0.4355 - val_accuracy: 0.8014 Epoch 33/100 313/313 [==============================] - 12s 39ms/step - loss: 0.4117 - accuracy: 0.8134 - val_loss: 0.4358 - val_accuracy: 0.8040 Epoch 34/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4112 - accuracy: 0.8134 - val_loss: 0.4346 - val_accuracy: 0.7986 Epoch 35/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4106 - accuracy: 0.8134 - val_loss: 0.4353 - val_accuracy: 0.7978 Epoch 36/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4100 - accuracy: 0.8144 - val_loss: 0.4346 - val_accuracy: 0.7976 Epoch 37/100 313/313 [==============================] - 12s 39ms/step - loss: 0.4100 - accuracy: 0.8128 - val_loss: 0.4342 - val_accuracy: 0.8052 Epoch 38/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4092 - accuracy: 0.8141 - val_loss: 0.4350 - val_accuracy: 0.8052 Epoch 39/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4090 - accuracy: 0.8138 - val_loss: 0.4334 - val_accuracy: 0.8028 Epoch 40/100 313/313 [==============================] - 13s 40ms/step - loss: 0.4083 - accuracy: 0.8152 - val_loss: 0.4325 - val_accuracy: 0.7992 Epoch 41/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4080 - accuracy: 0.8156 - val_loss: 0.4358 - val_accuracy: 0.7960 Epoch 42/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4075 - accuracy: 0.8149 - val_loss: 0.4322 - val_accuracy: 0.8016 Epoch 43/100 313/313 [==============================] - 12s 39ms/step - loss: 0.4069 - accuracy: 0.8134 - val_loss: 0.4327 - val_accuracy: 0.8014 Epoch 44/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4067 - accuracy: 0.8155 - val_loss: 0.4333 - val_accuracy: 0.8042 Epoch 45/100 313/313 [==============================] - 12s 40ms/step - loss: 0.4063 - accuracy: 0.8140 - val_loss: 0.4331 - val_accuracy: 0.8022 12345678import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() dropout &#x3D; 0.3 12345model2 = keras.Sequential()model2.add(keras.layers.Embedding(500, 16, input_length=100))model2.add(keras.layers.LSTM(8, dropout=0.3))model2.add(keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;))model2.summary() Model: &quot;sequential_1&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_1 (Embedding) (None, 100, 16) 8000 lstm_1 (LSTM) (None, 8) 800 dense_1 (Dense) (None, 1) 9 ================================================================= Total params: 8,809 Trainable params: 8,809 Non-trainable params: 0 _________________________________________________________________ 123456789101112rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model2.compile(optimizer=rmsprop, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-dropout-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model2.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/100 313/313 [==============================] - 18s 48ms/step - loss: 0.6925 - accuracy: 0.5239 - val_loss: 0.6913 - val_accuracy: 0.5654 Epoch 2/100 313/313 [==============================] - 13s 42ms/step - loss: 0.6895 - accuracy: 0.5954 - val_loss: 0.6872 - val_accuracy: 0.6314 Epoch 3/100 313/313 [==============================] - 13s 42ms/step - loss: 0.6816 - accuracy: 0.6561 - val_loss: 0.6736 - val_accuracy: 0.6828 Epoch 4/100 313/313 [==============================] - 13s 42ms/step - loss: 0.6444 - accuracy: 0.7018 - val_loss: 0.6027 - val_accuracy: 0.7116 Epoch 5/100 313/313 [==============================] - 13s 43ms/step - loss: 0.5789 - accuracy: 0.7199 - val_loss: 0.5620 - val_accuracy: 0.7352 Epoch 6/100 313/313 [==============================] - 14s 44ms/step - loss: 0.5517 - accuracy: 0.7405 - val_loss: 0.5403 - val_accuracy: 0.7526 Epoch 7/100 313/313 [==============================] - 14s 44ms/step - loss: 0.5317 - accuracy: 0.7545 - val_loss: 0.5219 - val_accuracy: 0.7598 Epoch 8/100 313/313 [==============================] - 13s 43ms/step - loss: 0.5117 - accuracy: 0.7681 - val_loss: 0.5049 - val_accuracy: 0.7702 Epoch 9/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4968 - accuracy: 0.7747 - val_loss: 0.4917 - val_accuracy: 0.7760 Epoch 10/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4844 - accuracy: 0.7829 - val_loss: 0.4814 - val_accuracy: 0.7864 Epoch 11/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4741 - accuracy: 0.7871 - val_loss: 0.4728 - val_accuracy: 0.7892 Epoch 12/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4667 - accuracy: 0.7912 - val_loss: 0.4679 - val_accuracy: 0.7870 Epoch 13/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4584 - accuracy: 0.7942 - val_loss: 0.4614 - val_accuracy: 0.7932 Epoch 14/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4530 - accuracy: 0.7968 - val_loss: 0.4590 - val_accuracy: 0.7942 Epoch 15/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4499 - accuracy: 0.7979 - val_loss: 0.4546 - val_accuracy: 0.7956 Epoch 16/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4458 - accuracy: 0.7995 - val_loss: 0.4517 - val_accuracy: 0.7988 Epoch 17/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4415 - accuracy: 0.7990 - val_loss: 0.4481 - val_accuracy: 0.7984 Epoch 18/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4374 - accuracy: 0.8018 - val_loss: 0.4468 - val_accuracy: 0.7994 Epoch 19/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4342 - accuracy: 0.8030 - val_loss: 0.4516 - val_accuracy: 0.7964 Epoch 20/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4325 - accuracy: 0.8054 - val_loss: 0.4431 - val_accuracy: 0.8024 Epoch 21/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4305 - accuracy: 0.8057 - val_loss: 0.4400 - val_accuracy: 0.7996 Epoch 22/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4279 - accuracy: 0.8037 - val_loss: 0.4388 - val_accuracy: 0.7964 Epoch 23/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4250 - accuracy: 0.8075 - val_loss: 0.4392 - val_accuracy: 0.8014 Epoch 24/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4253 - accuracy: 0.8062 - val_loss: 0.4361 - val_accuracy: 0.7966 Epoch 25/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4241 - accuracy: 0.8077 - val_loss: 0.4357 - val_accuracy: 0.8008 Epoch 26/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4219 - accuracy: 0.8077 - val_loss: 0.4342 - val_accuracy: 0.8008 Epoch 27/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4205 - accuracy: 0.8097 - val_loss: 0.4331 - val_accuracy: 0.8002 Epoch 28/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4195 - accuracy: 0.8098 - val_loss: 0.4327 - val_accuracy: 0.7988 Epoch 29/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4197 - accuracy: 0.8058 - val_loss: 0.4326 - val_accuracy: 0.8006 Epoch 30/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4172 - accuracy: 0.8076 - val_loss: 0.4335 - val_accuracy: 0.7954 Epoch 31/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4160 - accuracy: 0.8116 - val_loss: 0.4308 - val_accuracy: 0.8012 Epoch 32/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4161 - accuracy: 0.8108 - val_loss: 0.4319 - val_accuracy: 0.7986 Epoch 33/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4140 - accuracy: 0.8119 - val_loss: 0.4304 - val_accuracy: 0.8006 Epoch 34/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4146 - accuracy: 0.8110 - val_loss: 0.4299 - val_accuracy: 0.7984 Epoch 35/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4140 - accuracy: 0.8101 - val_loss: 0.4293 - val_accuracy: 0.8008 Epoch 36/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4132 - accuracy: 0.8122 - val_loss: 0.4293 - val_accuracy: 0.7994 Epoch 37/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4127 - accuracy: 0.8110 - val_loss: 0.4307 - val_accuracy: 0.7980 Epoch 38/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4137 - accuracy: 0.8112 - val_loss: 0.4286 - val_accuracy: 0.8046 Epoch 39/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4127 - accuracy: 0.8109 - val_loss: 0.4277 - val_accuracy: 0.8040 Epoch 40/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4103 - accuracy: 0.8106 - val_loss: 0.4284 - val_accuracy: 0.8052 Epoch 41/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4105 - accuracy: 0.8106 - val_loss: 0.4281 - val_accuracy: 0.8002 Epoch 42/100 313/313 [==============================] - 13s 41ms/step - loss: 0.4111 - accuracy: 0.8137 - val_loss: 0.4284 - val_accuracy: 0.7982 1234567fig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() return_squences &#x3D; True 123456model3 = keras.Sequential()model3.add(keras.layers.Embedding(500, 16, input_length=100))model3.add(keras.layers.LSTM(8, dropout=0.3, return_sequences=True))model3.add(keras.layers.LSTM(8, dropout=0.3))model3.add(keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;))model3.summary() Model: &quot;sequential_2&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_2 (Embedding) (None, 100, 16) 8000 lstm_2 (LSTM) (None, 100, 8) 800 lstm_3 (LSTM) (None, 8) 544 dense_2 (Dense) (None, 1) 9 ================================================================= Total params: 9,353 Trainable params: 9,353 Non-trainable params: 0 _________________________________________________________________ 123456789101112rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model3.compile(optimizer=rmsprop, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-2rnn-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model3.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/100 313/313 [==============================] - 29s 81ms/step - loss: 0.6908 - accuracy: 0.5653 - val_loss: 0.6870 - val_accuracy: 0.6378 Epoch 2/100 313/313 [==============================] - 25s 79ms/step - loss: 0.6632 - accuracy: 0.6561 - val_loss: 0.6162 - val_accuracy: 0.6984 Epoch 3/100 313/313 [==============================] - 24s 78ms/step - loss: 0.5830 - accuracy: 0.7079 - val_loss: 0.5565 - val_accuracy: 0.7352 Epoch 4/100 313/313 [==============================] - 24s 78ms/step - loss: 0.5463 - accuracy: 0.7387 - val_loss: 0.5279 - val_accuracy: 0.7536 Epoch 5/100 313/313 [==============================] - 25s 79ms/step - loss: 0.5207 - accuracy: 0.7556 - val_loss: 0.5072 - val_accuracy: 0.7636 Epoch 6/100 313/313 [==============================] - 25s 79ms/step - loss: 0.5026 - accuracy: 0.7671 - val_loss: 0.4941 - val_accuracy: 0.7730 Epoch 7/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4910 - accuracy: 0.7728 - val_loss: 0.4812 - val_accuracy: 0.7818 Epoch 8/100 313/313 [==============================] - 31s 100ms/step - loss: 0.4813 - accuracy: 0.7782 - val_loss: 0.4747 - val_accuracy: 0.7810 Epoch 9/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4730 - accuracy: 0.7832 - val_loss: 0.4661 - val_accuracy: 0.7878 Epoch 10/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4657 - accuracy: 0.7869 - val_loss: 0.4612 - val_accuracy: 0.7896 Epoch 11/100 313/313 [==============================] - 25s 78ms/step - loss: 0.4614 - accuracy: 0.7872 - val_loss: 0.4589 - val_accuracy: 0.7898 Epoch 12/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4568 - accuracy: 0.7886 - val_loss: 0.4547 - val_accuracy: 0.7934 Epoch 13/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4519 - accuracy: 0.7911 - val_loss: 0.4577 - val_accuracy: 0.7874 Epoch 14/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4484 - accuracy: 0.7945 - val_loss: 0.4498 - val_accuracy: 0.7930 Epoch 15/100 313/313 [==============================] - 25s 78ms/step - loss: 0.4472 - accuracy: 0.7955 - val_loss: 0.4498 - val_accuracy: 0.7914 Epoch 16/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4447 - accuracy: 0.7983 - val_loss: 0.4468 - val_accuracy: 0.7968 Epoch 17/100 313/313 [==============================] - 25s 78ms/step - loss: 0.4441 - accuracy: 0.7944 - val_loss: 0.4444 - val_accuracy: 0.7968 Epoch 18/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4418 - accuracy: 0.7990 - val_loss: 0.4442 - val_accuracy: 0.7950 Epoch 19/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4375 - accuracy: 0.8007 - val_loss: 0.4477 - val_accuracy: 0.7936 Epoch 20/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4365 - accuracy: 0.8027 - val_loss: 0.4416 - val_accuracy: 0.7964 Epoch 21/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4354 - accuracy: 0.8012 - val_loss: 0.4415 - val_accuracy: 0.7944 Epoch 22/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4341 - accuracy: 0.8014 - val_loss: 0.4408 - val_accuracy: 0.7972 Epoch 23/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4345 - accuracy: 0.8008 - val_loss: 0.4390 - val_accuracy: 0.7960 Epoch 24/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4315 - accuracy: 0.8037 - val_loss: 0.4412 - val_accuracy: 0.7912 Epoch 25/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4305 - accuracy: 0.8049 - val_loss: 0.4397 - val_accuracy: 0.7928 Epoch 26/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4294 - accuracy: 0.8051 - val_loss: 0.4382 - val_accuracy: 0.7990 Epoch 27/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4281 - accuracy: 0.8025 - val_loss: 0.4378 - val_accuracy: 0.7954 Epoch 28/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4277 - accuracy: 0.8035 - val_loss: 0.4375 - val_accuracy: 0.7952 Epoch 29/100 313/313 [==============================] - 25s 78ms/step - loss: 0.4255 - accuracy: 0.8067 - val_loss: 0.4365 - val_accuracy: 0.7984 Epoch 30/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4254 - accuracy: 0.8055 - val_loss: 0.4360 - val_accuracy: 0.7990 Epoch 31/100 313/313 [==============================] - 25s 78ms/step - loss: 0.4248 - accuracy: 0.8065 - val_loss: 0.4350 - val_accuracy: 0.8000 Epoch 32/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4247 - accuracy: 0.8051 - val_loss: 0.4352 - val_accuracy: 0.8006 Epoch 33/100 313/313 [==============================] - 25s 80ms/step - loss: 0.4240 - accuracy: 0.8061 - val_loss: 0.4358 - val_accuracy: 0.7958 Epoch 34/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4239 - accuracy: 0.8051 - val_loss: 0.4348 - val_accuracy: 0.8020 Epoch 35/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4240 - accuracy: 0.8066 - val_loss: 0.4340 - val_accuracy: 0.7998 Epoch 36/100 313/313 [==============================] - 24s 78ms/step - loss: 0.4230 - accuracy: 0.8044 - val_loss: 0.4358 - val_accuracy: 0.8024 Epoch 37/100 313/313 [==============================] - 25s 78ms/step - loss: 0.4227 - accuracy: 0.8061 - val_loss: 0.4334 - val_accuracy: 0.7994 Epoch 38/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4207 - accuracy: 0.8063 - val_loss: 0.4337 - val_accuracy: 0.8000 Epoch 39/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4194 - accuracy: 0.8075 - val_loss: 0.4349 - val_accuracy: 0.8012 Epoch 40/100 313/313 [==============================] - 25s 80ms/step - loss: 0.4203 - accuracy: 0.8073 - val_loss: 0.4326 - val_accuracy: 0.8018 Epoch 41/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4208 - accuracy: 0.8064 - val_loss: 0.4347 - val_accuracy: 0.8036 Epoch 42/100 313/313 [==============================] - 25s 80ms/step - loss: 0.4196 - accuracy: 0.8066 - val_loss: 0.4371 - val_accuracy: 0.8006 Epoch 43/100 313/313 [==============================] - 25s 79ms/step - loss: 0.4196 - accuracy: 0.8066 - val_loss: 0.4358 - val_accuracy: 0.8018 1234567fig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() GRU(Gated Recurrent Unit) 12345model4 = keras.Sequential()model4.add(keras.layers.Embedding(500, 16, input_length=100))model4.add(keras.layers.GRU(8))model4.add(keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;))model4.summary() Model: &quot;sequential_3&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_3 (Embedding) (None, 100, 16) 8000 gru (GRU) (None, 8) 624 dense_3 (Dense) (None, 1) 9 ================================================================= Total params: 8,633 Trainable params: 8,633 Non-trainable params: 0 _________________________________________________________________ 123456789101112rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model4.compile(optimizer=rmsprop, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-gru-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model4.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/100 313/313 [==============================] - 16s 45ms/step - loss: 0.6925 - accuracy: 0.5303 - val_loss: 0.6916 - val_accuracy: 0.5616 Epoch 2/100 313/313 [==============================] - 13s 43ms/step - loss: 0.6905 - accuracy: 0.5642 - val_loss: 0.6895 - val_accuracy: 0.5804 Epoch 3/100 313/313 [==============================] - 13s 43ms/step - loss: 0.6875 - accuracy: 0.5913 - val_loss: 0.6861 - val_accuracy: 0.5956 Epoch 4/100 313/313 [==============================] - 14s 43ms/step - loss: 0.6826 - accuracy: 0.6100 - val_loss: 0.6803 - val_accuracy: 0.6116 Epoch 5/100 313/313 [==============================] - 13s 42ms/step - loss: 0.6747 - accuracy: 0.6278 - val_loss: 0.6712 - val_accuracy: 0.6314 Epoch 6/100 313/313 [==============================] - 13s 43ms/step - loss: 0.6611 - accuracy: 0.6477 - val_loss: 0.6548 - val_accuracy: 0.6538 Epoch 7/100 313/313 [==============================] - 13s 42ms/step - loss: 0.6369 - accuracy: 0.6689 - val_loss: 0.6239 - val_accuracy: 0.6790 Epoch 8/100 313/313 [==============================] - 13s 42ms/step - loss: 0.5868 - accuracy: 0.7036 - val_loss: 0.5557 - val_accuracy: 0.7230 Epoch 9/100 313/313 [==============================] - 13s 42ms/step - loss: 0.5165 - accuracy: 0.7487 - val_loss: 0.5120 - val_accuracy: 0.7520 Epoch 10/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4907 - accuracy: 0.7675 - val_loss: 0.4945 - val_accuracy: 0.7624 Epoch 11/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4746 - accuracy: 0.7786 - val_loss: 0.4819 - val_accuracy: 0.7712 Epoch 12/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4622 - accuracy: 0.7870 - val_loss: 0.4729 - val_accuracy: 0.7780 Epoch 13/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4530 - accuracy: 0.7927 - val_loss: 0.4647 - val_accuracy: 0.7824 Epoch 14/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4451 - accuracy: 0.7976 - val_loss: 0.4613 - val_accuracy: 0.7862 Epoch 15/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4388 - accuracy: 0.8009 - val_loss: 0.4538 - val_accuracy: 0.7864 Epoch 16/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4342 - accuracy: 0.8044 - val_loss: 0.4503 - val_accuracy: 0.7912 Epoch 17/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4302 - accuracy: 0.8057 - val_loss: 0.4499 - val_accuracy: 0.7906 Epoch 18/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4265 - accuracy: 0.8094 - val_loss: 0.4460 - val_accuracy: 0.7964 Epoch 19/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4239 - accuracy: 0.8113 - val_loss: 0.4442 - val_accuracy: 0.7972 Epoch 20/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4214 - accuracy: 0.8130 - val_loss: 0.4434 - val_accuracy: 0.7978 Epoch 21/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4195 - accuracy: 0.8127 - val_loss: 0.4436 - val_accuracy: 0.7994 Epoch 22/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4180 - accuracy: 0.8145 - val_loss: 0.4415 - val_accuracy: 0.7968 Epoch 23/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4164 - accuracy: 0.8141 - val_loss: 0.4401 - val_accuracy: 0.8006 Epoch 24/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4151 - accuracy: 0.8149 - val_loss: 0.4401 - val_accuracy: 0.7978 Epoch 25/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4136 - accuracy: 0.8159 - val_loss: 0.4398 - val_accuracy: 0.7988 Epoch 26/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4128 - accuracy: 0.8171 - val_loss: 0.4394 - val_accuracy: 0.7962 Epoch 27/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4116 - accuracy: 0.8181 - val_loss: 0.4384 - val_accuracy: 0.7980 Epoch 28/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4111 - accuracy: 0.8163 - val_loss: 0.4378 - val_accuracy: 0.8012 Epoch 29/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4102 - accuracy: 0.8189 - val_loss: 0.4378 - val_accuracy: 0.7974 Epoch 30/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4096 - accuracy: 0.8183 - val_loss: 0.4380 - val_accuracy: 0.7978 Epoch 31/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4087 - accuracy: 0.8187 - val_loss: 0.4376 - val_accuracy: 0.7978 Epoch 32/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4080 - accuracy: 0.8183 - val_loss: 0.4387 - val_accuracy: 0.7976 Epoch 33/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4076 - accuracy: 0.8184 - val_loss: 0.4352 - val_accuracy: 0.8018 Epoch 34/100 313/313 [==============================] - 13s 42ms/step - loss: 0.4065 - accuracy: 0.8183 - val_loss: 0.4359 - val_accuracy: 0.7948 Epoch 35/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4060 - accuracy: 0.8185 - val_loss: 0.4350 - val_accuracy: 0.7974 Epoch 36/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4059 - accuracy: 0.8194 - val_loss: 0.4426 - val_accuracy: 0.7946 Epoch 37/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4048 - accuracy: 0.8208 - val_loss: 0.4329 - val_accuracy: 0.8018 Epoch 38/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4044 - accuracy: 0.8197 - val_loss: 0.4335 - val_accuracy: 0.7998 Epoch 39/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4040 - accuracy: 0.8202 - val_loss: 0.4327 - val_accuracy: 0.8010 Epoch 40/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4039 - accuracy: 0.8199 - val_loss: 0.4325 - val_accuracy: 0.8042 Epoch 41/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4031 - accuracy: 0.8197 - val_loss: 0.4316 - val_accuracy: 0.8024 Epoch 42/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4025 - accuracy: 0.8213 - val_loss: 0.4316 - val_accuracy: 0.8004 Epoch 43/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4020 - accuracy: 0.8198 - val_loss: 0.4320 - val_accuracy: 0.7986 Epoch 44/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4016 - accuracy: 0.8214 - val_loss: 0.4311 - val_accuracy: 0.8020 Epoch 45/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4011 - accuracy: 0.8214 - val_loss: 0.4301 - val_accuracy: 0.8040 Epoch 46/100 313/313 [==============================] - 13s 43ms/step - loss: 0.4001 - accuracy: 0.8210 - val_loss: 0.4306 - val_accuracy: 0.8008 Epoch 47/100 313/313 [==============================] - 14s 43ms/step - loss: 0.4001 - accuracy: 0.8224 - val_loss: 0.4375 - val_accuracy: 0.7950 Epoch 48/100 313/313 [==============================] - 14s 43ms/step - loss: 0.3998 - accuracy: 0.8222 - val_loss: 0.4306 - val_accuracy: 0.8018 1234567fig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 9_2","slug":"Python/ML/ML_ch_9_2","date":"2022-04-08T02:57:20.000Z","updated":"2022-10-05T05:39:53.919Z","comments":true,"path":"2022/04/08/Python/ML/ML_ch_9_2/","link":"","permalink":"http://gonekng.github.io/2022/04/08/Python/ML/ML_ch_9_2/","excerpt":"","text":"Text Normalization: Pre-processing text for use as input data Cleansing í…ìŠ¤íŠ¸ ë¶„ì„ì— ë°©í•´ë˜ëŠ” ë¶ˆí•„ìš”í•œ ë¬¸ì ë° ê¸°í˜¸ë¥¼ ì‚¬ì „ì— ì œê±° ex) HTML, XML íƒœê·¸ ì œê±° Tokenization Sentence Tokenization- ë¬¸ì¥, ë§ˆì¹¨í‘œ, ê°œí–‰ë¬¸ì ë“± ë¬¸ì¥ ë§ˆì§€ë§‰ì„ ëœ»í•˜ëŠ” ê¸°í˜¸ë¥¼ ë”°ë¼ ë¶„ë¦¬- ë¬¸ì¥ì´ ê°€ì§€ëŠ” ì˜ë¯¸ê°€ ì‹œë§¨í‹±ì ìœ¼ë¡œ ì¤‘ìš”í•œ ìš”ì†Œì¼ ë•Œ ì‚¬ìš© Word Tokenization- ê³µë°±, ì½¤ë§ˆ, ë§ˆì¹¨í‘œ, ê°œí–‰ë¬¸ì ë“±ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ë¶„ë¦¬ Stop word elimination í•„ìˆ˜ ë¬¸ë²• ìš”ì†Œì´ë‚˜ ë¬¸ë§¥ì ìœ¼ë¡œ í° ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´(ex. is, the, a, will)ê°€ í…ìŠ¤íŠ¸ì— ë¹ˆë²ˆí•˜ê²Œ ë‚˜íƒ€ë‚˜ë©´ ì¤‘ìš”í•œ ë‹¨ì–´ë¡œ ì¸ì§€ë  ìˆ˜ ìˆì–´ì„œ ì‚¬ì „ ì œê±°ê°€ í•„ìš”í•¨ Stemming Lemmatization IMDB Review Classification with RNN a dataset that categorizes IMDB reviews as positive and negative based on comments 123from tensorflow.keras.datasets import imdb(train_input, train_target), (test_input, test_target) = imdb.load_data( num_words=500) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz 17465344/17464789 [==============================] - 0s 0us/step 17473536/17464789 [==============================] - 0s 0us/step Datasets are made of a one-dimensional array, because the length of the text is different 1print(train_input.shape, test_input.shape) (25000,) (25000,) 123print(len(train_input[0]))print(len(train_input[1]))print(len(train_input[2])) 218 189 141 1print(train_input[0]) [1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32] Target 0: negative review Target 1: positive review 1print(train_target[:20]) [1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1] Split data12345from sklearn.model_selection import train_test_splittrain_input, val_input, train_target, val_target = train_test_split( train_input, train_target, test_size=0.2, random_state=42)train_input.shape, val_input.shape, train_target.shape, val_target.shape ((20000,), (5000,), (20000,), (5000,)) Visualize data mean and median of the number of words in each review 123import numpy as nplengths = np.array([len(x) for x in train_input])print(np.mean(lengths), np.median(lengths)) 239.00925 178.0 123456import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.hist(lengths)ax.set_xlabel(&quot;length&quot;)ax.set_ylabel(&quot;frequency&quot;)plt.show() Use only 100 words that are much shorter than the median Use padding to match the length of each review to 100 1234from tensorflow.keras.preprocessing.sequence import pad_sequencestrain_seq = pad_sequences(train_input, maxlen=100) # cut the front part of sequencesprint(train_seq.shape) # the number of data = 2000, length of each data = 100 (20000, 100) 1print(train_seq[0]) [ 10 4 20 9 2 364 352 5 45 6 2 2 33 269 8 2 142 2 5 2 17 73 17 204 5 2 19 55 2 2 92 66 104 14 20 93 76 2 151 33 4 58 12 188 2 151 12 215 69 224 142 73 237 6 2 7 2 2 188 2 103 14 31 10 10 451 7 2 5 2 80 91 2 30 2 34 14 20 151 50 26 131 49 2 84 46 50 37 80 79 6 2 46 7 14 20 10 10 470 158] 1print(train_input[0][-10:]) [6, 2, 46, 7, 14, 20, 10, 10, 470, 158] 1print(train_seq[5]) [ 0 0 0 0 1 2 195 19 49 2 2 190 4 2 352 2 183 10 10 13 82 79 4 2 36 71 269 8 2 25 19 49 7 4 2 2 2 2 2 10 10 48 25 40 2 11 2 2 40 2 2 5 4 2 2 95 14 238 56 129 2 10 10 21 2 94 364 352 2 2 11 190 24 484 2 7 94 205 405 10 10 87 2 34 49 2 7 2 2 2 2 2 290 2 46 48 64 18 4 2] 1val_seq = pad_sequences(val_input, maxlen=100) RNN Model 100 : Length of each text data 500 : Numer of words 1234from tensorflow import kerasmodel = keras.Sequential()model.add(keras.layers.SimpleRNN(8, input_shape=(100,500)))model.add(keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;)) one-hot encoding 12train_oh = keras.utils.to_categorical(train_seq)print(train_oh.shape) (20000, 100, 500) 1print(train_oh[0][0][:12]) [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] 1print(np.sum(train_oh[0][0])) 1.0 12val_oh = keras.utils.to_categorical(val_seq)print(val_oh.shape) (5000, 100, 500) model structure 1model.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= simple_rnn (SimpleRNN) (None, 8) 4072 dense (Dense) (None, 1) 9 ================================================================= Total params: 4,081 Trainable params: 4,081 Non-trainable params: 0 _________________________________________________________________ model fitting 123456789101112rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model.compile(optimizer=rmsprop, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-simplernn-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model.fit(train_oh, train_target, epochs=100, batch_size=64, validation_data=(val_oh, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/100 313/313 [==============================] - 47s 135ms/step - loss: 0.6977 - accuracy: 0.5094 - val_loss: 0.6916 - val_accuracy: 0.5338 Epoch 2/100 313/313 [==============================] - 41s 131ms/step - loss: 0.6828 - accuracy: 0.5623 - val_loss: 0.6780 - val_accuracy: 0.5792 Epoch 3/100 313/313 [==============================] - 72s 230ms/step - loss: 0.6685 - accuracy: 0.6031 - val_loss: 0.6649 - val_accuracy: 0.6114 Epoch 4/100 313/313 [==============================] - 57s 183ms/step - loss: 0.6525 - accuracy: 0.6366 - val_loss: 0.6478 - val_accuracy: 0.6438 Epoch 5/100 313/313 [==============================] - 41s 131ms/step - loss: 0.6280 - accuracy: 0.6789 - val_loss: 0.6241 - val_accuracy: 0.6850 Epoch 6/100 313/313 [==============================] - 41s 131ms/step - loss: 0.6086 - accuracy: 0.7050 - val_loss: 0.6063 - val_accuracy: 0.7042 Epoch 7/100 313/313 [==============================] - 42s 134ms/step - loss: 0.5897 - accuracy: 0.7224 - val_loss: 0.5904 - val_accuracy: 0.7158 Epoch 8/100 313/313 [==============================] - 41s 131ms/step - loss: 0.5732 - accuracy: 0.7354 - val_loss: 0.5774 - val_accuracy: 0.7188 Epoch 9/100 313/313 [==============================] - 54s 174ms/step - loss: 0.5576 - accuracy: 0.7492 - val_loss: 0.5626 - val_accuracy: 0.7364 Epoch 10/100 313/313 [==============================] - 41s 132ms/step - loss: 0.5432 - accuracy: 0.7583 - val_loss: 0.5500 - val_accuracy: 0.7444 Epoch 11/100 313/313 [==============================] - 43s 137ms/step - loss: 0.5301 - accuracy: 0.7650 - val_loss: 0.5391 - val_accuracy: 0.7480 Epoch 12/100 313/313 [==============================] - 51s 164ms/step - loss: 0.5188 - accuracy: 0.7713 - val_loss: 0.5304 - val_accuracy: 0.7608 Epoch 13/100 313/313 [==============================] - 40s 129ms/step - loss: 0.5078 - accuracy: 0.7771 - val_loss: 0.5276 - val_accuracy: 0.7526 Epoch 14/100 313/313 [==============================] - 42s 133ms/step - loss: 0.4980 - accuracy: 0.7824 - val_loss: 0.5108 - val_accuracy: 0.7698 Epoch 15/100 313/313 [==============================] - 45s 143ms/step - loss: 0.4889 - accuracy: 0.7865 - val_loss: 0.5043 - val_accuracy: 0.7708 Epoch 16/100 313/313 [==============================] - 42s 135ms/step - loss: 0.4807 - accuracy: 0.7901 - val_loss: 0.4944 - val_accuracy: 0.7752 Epoch 17/100 313/313 [==============================] - 41s 132ms/step - loss: 0.4730 - accuracy: 0.7957 - val_loss: 0.4903 - val_accuracy: 0.7758 Epoch 18/100 313/313 [==============================] - 42s 135ms/step - loss: 0.4661 - accuracy: 0.7979 - val_loss: 0.4878 - val_accuracy: 0.7744 Epoch 19/100 313/313 [==============================] - 40s 129ms/step - loss: 0.4602 - accuracy: 0.7994 - val_loss: 0.4813 - val_accuracy: 0.7808 Epoch 20/100 313/313 [==============================] - 40s 127ms/step - loss: 0.4543 - accuracy: 0.8031 - val_loss: 0.4756 - val_accuracy: 0.7804 Epoch 21/100 313/313 [==============================] - 40s 128ms/step - loss: 0.4492 - accuracy: 0.8030 - val_loss: 0.4719 - val_accuracy: 0.7816 Epoch 22/100 313/313 [==============================] - 41s 132ms/step - loss: 0.4448 - accuracy: 0.8059 - val_loss: 0.4724 - val_accuracy: 0.7800 Epoch 23/100 313/313 [==============================] - 41s 132ms/step - loss: 0.4412 - accuracy: 0.8077 - val_loss: 0.4671 - val_accuracy: 0.7852 Epoch 24/100 313/313 [==============================] - 42s 134ms/step - loss: 0.4374 - accuracy: 0.8097 - val_loss: 0.4642 - val_accuracy: 0.7894 Epoch 25/100 313/313 [==============================] - 41s 132ms/step - loss: 0.4338 - accuracy: 0.8113 - val_loss: 0.4635 - val_accuracy: 0.7862 Epoch 26/100 313/313 [==============================] - 40s 127ms/step - loss: 0.4304 - accuracy: 0.8121 - val_loss: 0.4596 - val_accuracy: 0.7900 Epoch 27/100 313/313 [==============================] - 40s 127ms/step - loss: 0.4278 - accuracy: 0.8130 - val_loss: 0.4588 - val_accuracy: 0.7928 Epoch 28/100 313/313 [==============================] - 40s 128ms/step - loss: 0.4255 - accuracy: 0.8135 - val_loss: 0.4585 - val_accuracy: 0.7930 Epoch 29/100 313/313 [==============================] - 41s 132ms/step - loss: 0.4229 - accuracy: 0.8149 - val_loss: 0.4619 - val_accuracy: 0.7888 Epoch 30/100 313/313 [==============================] - 41s 130ms/step - loss: 0.4205 - accuracy: 0.8156 - val_loss: 0.4560 - val_accuracy: 0.7950 Epoch 31/100 313/313 [==============================] - 41s 130ms/step - loss: 0.4182 - accuracy: 0.8163 - val_loss: 0.4575 - val_accuracy: 0.7922 Epoch 32/100 313/313 [==============================] - 40s 128ms/step - loss: 0.4168 - accuracy: 0.8195 - val_loss: 0.4564 - val_accuracy: 0.7910 Epoch 33/100 313/313 [==============================] - 42s 133ms/step - loss: 0.4143 - accuracy: 0.8180 - val_loss: 0.4573 - val_accuracy: 0.7872 1234567fig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() 1print(train_seq.nbytes, train_oh.nbytes) 8000000 4000000000 Word Embedding: Replace each word with a real number vector of fixed size. It solves memory inefficiencies in one-hot encoding. Since it receives an integer data as an input, train_seq can be used. 1234model2 = keras.Sequential()model2.add(keras.layers.Embedding(500, 16, input_length=100))model2.add(keras.layers.SimpleRNN(8, input_shape=(100,500)))model2.add(keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;)) 1model2.summary() Model: &quot;sequential_1&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding (Embedding) (None, 100, 16) 8000 simple_rnn_1 (SimpleRNN) (None, 8) 200 dense_1 (Dense) (None, 1) 9 ================================================================= Total params: 8,209 Trainable params: 8,209 Non-trainable params: 0 _________________________________________________________________ 123456789101112rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)model2.compile(optimizer=rmsprop, loss=&#x27;binary_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-simplernn-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)history = model2.fit(train_seq, train_target, epochs=100, batch_size=64, validation_data=(val_seq, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/100 313/313 [==============================] - 52s 162ms/step - loss: 0.6938 - accuracy: 0.5105 - val_loss: 0.6909 - val_accuracy: 0.5236 Epoch 2/100 313/313 [==============================] - 51s 162ms/step - loss: 0.6747 - accuracy: 0.5947 - val_loss: 0.6529 - val_accuracy: 0.6548 Epoch 3/100 313/313 [==============================] - 53s 169ms/step - loss: 0.6280 - accuracy: 0.6870 - val_loss: 0.6142 - val_accuracy: 0.6996 Epoch 4/100 313/313 [==============================] - 52s 166ms/step - loss: 0.5937 - accuracy: 0.7228 - val_loss: 0.5887 - val_accuracy: 0.7214 Epoch 5/100 313/313 [==============================] - 52s 165ms/step - loss: 0.5699 - accuracy: 0.7440 - val_loss: 0.5712 - val_accuracy: 0.7298 Epoch 6/100 313/313 [==============================] - 51s 163ms/step - loss: 0.5495 - accuracy: 0.7571 - val_loss: 0.5569 - val_accuracy: 0.7476 Epoch 7/100 313/313 [==============================] - 51s 164ms/step - loss: 0.5361 - accuracy: 0.7618 - val_loss: 0.5451 - val_accuracy: 0.7444 Epoch 8/100 313/313 [==============================] - 52s 166ms/step - loss: 0.5230 - accuracy: 0.7689 - val_loss: 0.5360 - val_accuracy: 0.7514 Epoch 9/100 313/313 [==============================] - 53s 168ms/step - loss: 0.5127 - accuracy: 0.7724 - val_loss: 0.5302 - val_accuracy: 0.7510 Epoch 10/100 313/313 [==============================] - 52s 165ms/step - loss: 0.5043 - accuracy: 0.7758 - val_loss: 0.5213 - val_accuracy: 0.7554 Epoch 11/100 313/313 [==============================] - 52s 167ms/step - loss: 0.4956 - accuracy: 0.7806 - val_loss: 0.5188 - val_accuracy: 0.7544 Epoch 12/100 313/313 [==============================] - 53s 170ms/step - loss: 0.4899 - accuracy: 0.7823 - val_loss: 0.5170 - val_accuracy: 0.7604 Epoch 13/100 313/313 [==============================] - 53s 170ms/step - loss: 0.4858 - accuracy: 0.7839 - val_loss: 0.5110 - val_accuracy: 0.7604 Epoch 14/100 313/313 [==============================] - 52s 166ms/step - loss: 0.4809 - accuracy: 0.7873 - val_loss: 0.5086 - val_accuracy: 0.7626 Epoch 15/100 313/313 [==============================] - 53s 168ms/step - loss: 0.4763 - accuracy: 0.7897 - val_loss: 0.5061 - val_accuracy: 0.7658 Epoch 16/100 313/313 [==============================] - 53s 169ms/step - loss: 0.4733 - accuracy: 0.7912 - val_loss: 0.5111 - val_accuracy: 0.7576 Epoch 17/100 313/313 [==============================] - 54s 172ms/step - loss: 0.4692 - accuracy: 0.7901 - val_loss: 0.5097 - val_accuracy: 0.7556 Epoch 18/100 313/313 [==============================] - 54s 173ms/step - loss: 0.4676 - accuracy: 0.7922 - val_loss: 0.4955 - val_accuracy: 0.7692 Epoch 19/100 313/313 [==============================] - 54s 171ms/step - loss: 0.4653 - accuracy: 0.7943 - val_loss: 0.4997 - val_accuracy: 0.7694 Epoch 20/100 313/313 [==============================] - 54s 172ms/step - loss: 0.4656 - accuracy: 0.7929 - val_loss: 0.4959 - val_accuracy: 0.7700 Epoch 21/100 313/313 [==============================] - 54s 172ms/step - loss: 0.4618 - accuracy: 0.7964 - val_loss: 0.4962 - val_accuracy: 0.7676 1234567fig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 9_1","slug":"Python/ML/ML_ch_9_1","date":"2022-04-08T01:23:11.000Z","updated":"2022-10-05T05:39:53.837Z","comments":true,"path":"2022/04/08/Python/ML/ML_ch_9_1/","link":"","permalink":"http://gonekng.github.io/2022/04/08/Python/ML/ML_ch_9_1/","excerpt":"","text":"Sequential data meaningful in order such as text data, time series data Requires the function to remember previously entered data Text data text mining (representatively, sentimental analysis) natural language processing (using chatbot) basic deep learning algorithm : RNN, LSTM tensorflow: https://wikidocs.net/book/2155 pytorch: https://wikidocs.net/32471 RNN (Recurrent Neural Network) the contrary of feedfoward neural network Fully connected layer + Loop that circulates the processing flow of previous data timestep : a step in processing a sample activation : default tanh (S-shape, -1 to 1) 1 Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 8_2","slug":"Python/ML/ML_ch_8_2","date":"2022-04-07T02:47:21.000Z","updated":"2022-10-05T05:39:53.765Z","comments":true,"path":"2022/04/07/Python/ML/ML_ch_8_2/","link":"","permalink":"http://gonekng.github.io/2022/04/07/Python/ML/ML_ch_8_2/","excerpt":"","text":"Prepare Fashion Mnist Data12345678from tensorflow import kerasfrom sklearn.model_selection import train_test_split(train_input, train_target), (test_input, test_target) =\\ keras.datasets.fashion_mnist.load_data()train_scaled = train_input.reshape(-1, 28, 28, 1)/255.0 # standardization (0~255 -&gt; 0~1)train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step 40960/29515 [=========================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 0s 0us/step 26435584/26421880 [==============================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 16384/5148 [===============================================================================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step 4431872/4422102 [==============================] - 0s 0us/step Create CNN Model1234567891011121314model = keras.Sequential()model.add(keras.layers.Conv2D(32, kernel_size=3, activation=&#x27;relu&#x27;, padding=&#x27;same&#x27;, input_shape=(28,28,1))) # convolution layer (32 kernels of 3*3 size)model.add(keras.layers.MaxPooling2D(2)) # pooling layer (max pooling of 2*2 size)model.add(keras.layers.Conv2D(64, kernel_size=3, activation=&#x27;relu&#x27;, padding=&#x27;same&#x27;)) # convolution layer (64 kernels of 3*3 size)model.add(keras.layers.MaxPooling2D(2)) # pooling layer (max pooling of 2*2 size)model.add(keras.layers.Flatten()) # the two-dimensional input array into one dimensionmodel.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;)) # hidden layermodel.add(keras.layers.Dropout(0.4)) # drop out 40%model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) # output layermodel.summary() Model: &quot;sequential&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d (Conv2D) (None, 28, 28, 32) 320 max_pooling2d (MaxPooling2D (None, 14, 14, 32) 0 ) conv2d_1 (Conv2D) (None, 14, 14, 64) 18496 max_pooling2d_1 (MaxPooling (None, 7, 7, 64) 0 2D) flatten (Flatten) (None, 3136) 0 dense (Dense) (None, 100) 313700 dropout (Dropout) (None, 100) 0 dense_1 (Dense) (None, 10) 1010 ================================================================= Total params: 333,526 Trainable params: 333,526 Non-trainable params: 0 _________________________________________________________________ 1keras.utils.plot_model(model) 1keras.utils.plot_model(model, show_shapes=True) Compile and Fit123456789101112# optimizer: adammodel.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)# callback and early stoppingcheckpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-cnn-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)history = model.fit(train_scaled, train_target, epochs=20, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) Epoch 1/20 1500/1500 [==============================] - 65s 43ms/step - loss: 0.5331 - accuracy: 0.8090 - val_loss: 0.3290 - val_accuracy: 0.8807 Epoch 2/20 1500/1500 [==============================] - 69s 46ms/step - loss: 0.3533 - accuracy: 0.8729 - val_loss: 0.2771 - val_accuracy: 0.8973 Epoch 3/20 1500/1500 [==============================] - 64s 43ms/step - loss: 0.3032 - accuracy: 0.8901 - val_loss: 0.2525 - val_accuracy: 0.9049 Epoch 4/20 1500/1500 [==============================] - 64s 43ms/step - loss: 0.2691 - accuracy: 0.9030 - val_loss: 0.2521 - val_accuracy: 0.9081 Epoch 5/20 1500/1500 [==============================] - 63s 42ms/step - loss: 0.2445 - accuracy: 0.9096 - val_loss: 0.2351 - val_accuracy: 0.9107 Epoch 6/20 1500/1500 [==============================] - 66s 44ms/step - loss: 0.2262 - accuracy: 0.9150 - val_loss: 0.2259 - val_accuracy: 0.9162 Epoch 7/20 1500/1500 [==============================] - 65s 43ms/step - loss: 0.2075 - accuracy: 0.9229 - val_loss: 0.2284 - val_accuracy: 0.9153 Epoch 8/20 1500/1500 [==============================] - 63s 42ms/step - loss: 0.1921 - accuracy: 0.9276 - val_loss: 0.2376 - val_accuracy: 0.9173 Validation and Predict loss function (visualize train loss and validation loss) 12345678import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.plot(history.history[&#x27;loss&#x27;])ax.plot(history.history[&#x27;val_loss&#x27;])ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;loss&#x27;)ax.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() The epoch 6 appears to be optimal. 1model.evaluate(val_scaled, val_target) # same as output of epoch 6 375/375 [==============================] - 5s 12ms/step - loss: 0.2259 - accuracy: 0.9162 [0.22585801780223846, 0.9161666631698608] Confirm prediction of the first sample 123fig, ax = plt.subplots()ax.imshow(val_scaled[0].reshape(28,28), cmap=&#x27;gray_r&#x27;)plt.show() 1234# The fit(), predict(), and evaluate() all expect the first dimension of the input to be the batch dimension.# Slicing, unlike indexing, maintains the entire dimension even if there is one element.preds = model.predict(val_scaled[0:1])print(preds) [[1.88540562e-13 1.07813886e-17 3.65283819e-17 1.44768129e-14 7.86518068e-17 2.58884016e-15 2.82545543e-15 2.49630367e-13 1.00000000e+00 1.07822686e-14]] 12345fig, ax = plt.subplots()ax.bar(range(1,11),preds[0])ax.set_xlabel(&#x27;class&#x27;)ax.set_ylabel(&#x27;prob.&#x27;)plt.show() 12345classes = [&#x27;t-shirt&#x27;, &#x27;pants&#x27;, &#x27;sweater&#x27;, &#x27;dress&#x27;, &#x27;coat&#x27;, &#x27;sandal&#x27;, &#x27;shirt&#x27;, &#x27;sneakers&#x27;, &#x27;bag&#x27;, &#x27;boots&#x27;]import numpy as npprint(classes[np.argmax(preds)]) bag Model Test12test_scaled = test_input.reshape(-1,28,28,1)/255.0model.evaluate(test_scaled, test_target) 313/313 [==============================] - 4s 13ms/step - loss: 0.2519 - accuracy: 0.9093 [0.25190481543540955, 0.9093000292778015] GPU check in Google Colab12345678&#x27;&#x27;&#x27;import tensorflow as tfdevice_name = tf.test.gpu_device_name()if device_name != &#x27;/device:GPU:0&#x27;: raise SystemError(&#x27;GPU device not found&#x27;)print(&#x27;Found GPU at: &#123;&#125;&#x27;.format(device_name))&#x27;&#x27;&#x27; 123456789101112131415&#x27;&#x27;&#x27;import tensorflow as tfmodel.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-cnn-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)with tf.device(&#x27;/device:GPU:0&#x27;): history = model.fit(train_scaled, train_target, epochs=10, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb])&#x27;&#x27;&#x27; Visualize CNN12model = keras.models.load_model(&#x27;best-cnn-model.h5&#x27;)model.layers [&lt;keras.layers.convolutional.Conv2D at 0x7f1fc8314c10&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7f1fc82d34d0&gt;, &lt;keras.layers.convolutional.Conv2D at 0x7f1fc82d3490&gt;, &lt;keras.layers.pooling.MaxPooling2D at 0x7f1fc8393f10&gt;, &lt;keras.layers.core.flatten.Flatten at 0x7f1fc8332050&gt;, &lt;keras.layers.core.dense.Dense at 0x7f1fc83954d0&gt;, &lt;keras.layers.core.dropout.Dropout at 0x7f1fc8395110&gt;, &lt;keras.layers.core.dense.Dense at 0x7f1fc83f0710&gt;] check weights of the first convolution layer 12conv = model.layers[0]print(conv.weights[0].shape, conv.weights[1].shape) (3, 3, 1, 32) (32,) 12conv_weights = conv.weights[0].numpy()print(conv_weights.mean(), conv_weights.std()) -0.010425919 0.21259554 12345fig, ax = plt.subplots()ax.hist(conv_weights.reshape(-1,1))ax.set_xlabel(&#x27;weight&#x27;)ax.set_ylabel(&#x27;count&#x27;)plt.show() 1234567# 32 kernels of 3*3 sizefig, ax = plt.subplots(2, 16, figsize=(15,2))for i in range(2): for j in range(16): ax[i,j].imshow(conv_weights[:,:,0,i*16+j], vmin=-0.5, vmax=0.5) ax[i,j].axis(&#x27;off&#x27;)plt.show() Compare to empty CNN which is untrained 12345no_training_model = keras.Sequential()no_training_model.add(keras.layers.Conv2D(32, kernel_size=3, activation=&#x27;relu&#x27;, padding=&#x27;same&#x27;, input_shape=(28,28,1)))no_training_conv = no_training_model.layers[0]print(no_training_conv.weights[0].shape) (3, 3, 1, 32) 12no_training_weights = no_training_conv.weights[0].numpy()print(no_training_weights.mean(), no_training_weights.std()) -0.008161874 0.08076286 12345fig, ax = plt.subplots()ax.hist(no_training_weights.reshape(-1,1))ax.set_xlabel(&#x27;weight&#x27;)ax.set_ylabel(&#x27;count&#x27;)plt.show() It shows a relatively even distributionbecause tensorflow randomly select a value from an equal distribution at first. 123456fig, ax = plt.subplots(2, 16, figsize=(15,2))for i in range(2): for j in range(16): ax[i,j].imshow(no_training_weights[:,:,0,i*16+j], vmin=-0.5, vmax=0.5) ax[i,j].axis(&#x27;off&#x27;)plt.show() Visualize Feature Map feature map of the first convolution layer 12345print(model.input)conv_acti = keras.Model(model.input, model.layers[0].output) # functional API(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()plt.imshow(train_input[0], cmap=&#x27;gray_r&#x27;)plt.show() KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=&#39;conv2d_input&#39;), name=&#39;conv2d_input&#39;, description=&quot;created by layer &#39;conv2d_input&#39;&quot;) 123inputs = train_input[0:1].reshape(-1, 28, 28, 1)/255.0feature_maps = conv_acti.predict(inputs)print(feature_maps.shape) (1, 28, 28, 32) 123456fig, ax = plt.subplots(4, 8, figsize=(15,8))for i in range(4): for j in range(8): ax[i,j].imshow(feature_maps[0,:,:,i*8+j]) ax[i,j].axis(&#x27;off&#x27;)plt.show() feature map of the second convolution layer 123456789101112conv2_acti = keras.Model(model.input, model.layers[2].output)feature_maps = conv2_acti.predict(train_input[0:1].reshape(-1, 28, 28, 1)/255.0)print(feature_maps.shape)fig, axs = plt.subplots(8, 8, figsize=(12,12))for i in range(8): for j in range(8): axs[i, j].imshow(feature_maps[0,:,:,i*8 + j]) axs[i, j].axis(&#x27;off&#x27;)plt.show() (1, 14, 14, 64) Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 8_1","slug":"Python/ML/ML_ch_8_1","date":"2022-04-06T02:26:18.000Z","updated":"2022-10-05T05:39:53.685Z","comments":true,"path":"2022/04/06/Python/ML/ML_ch_8_1/","link":"","permalink":"http://gonekng.github.io/2022/04/06/Python/ML/ML_ch_8_1/","excerpt":"","text":"CNN(Convolution Neural Network) Neural network operations can also be applied to two-dimensional arrays by CNN. Neuron in CNN is called filter or kernel. 12from tensorflow import keraskeras.layers.Conv2D(10, kernel_size=(3,3), activation=&quot;relu&quot;) &lt;keras.layers.convolutional.Conv2D at 0x7effd27dea10&gt; Padding &amp; StridePadding : Filling the border of the input array with virtual elements To prevent the loss of the original features of the image even if you resize the array, Same padding : Padding to zero around the input to make the input and feature map the same size Valid padding : Convolution only in a pure input array without padding Stride : Size of the filter moving over the input layer (default 1)1keras.layers.Conv2D(10, kernel_size=(3,3), activation=&#x27;relu&#x27;, padding=&#x27;same&#x27;, strides=1) &lt;keras.layers.convolutional.Conv2D at 0x7effceb4fb10&gt; Pooling Reducing the size of the feature map while maintaining the original features of the image Max pooling, Average pooling, etc 1keras.layers.MaxPooling2D(2, strides=2, padding=&quot;valid&quot;) &lt;keras.layers.pooling.MaxPooling2D at 0x7effce850fd0&gt; 1keras.layers.AveragePooling2D(2, strides=2, padding=&quot;valid&quot;) &lt;keras.layers.pooling.AveragePooling2D at 0x7effcea305d0&gt; Overall process in CNN Input Image Data CNN Layer kernel_size, padding, stride activation function Calculate each feature map Pooling Layer Maxpooling &#x2F; Averagepooling final feature map Repeat the above process Fully Connected Layer Calculate classification predictions (Softmax) Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"Pipeline Tutorial","slug":"Python/Tutorial/Pipeline_tutorial","date":"2022-04-06T01:05:01.000Z","updated":"2022-10-05T05:39:54.302Z","comments":true,"path":"2022/04/06/Python/Tutorial/Pipeline_tutorial/","link":"","permalink":"http://gonekng.github.io/2022/04/06/Python/Tutorial/Pipeline_tutorial/","excerpt":"","text":"Pipeline : ë°ì´í„° ëˆ„ìˆ˜(Data Leakge) ë°©ì§€ë¥¼ ìœ„í•œ ëª¨ë¸ë§ ê¸°ë²• Pycaret, MLOps (Pipeline í˜•íƒœë¡œ êµ¬ì¶•) ë¨¸ì‹ ëŸ¬ë‹ ì½”ë“œì˜ ìë™í™” ë° ìš´ì˜ ê°€ëŠ¥ ê¸°ì¡´ ë°©ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° -&gt; ë°ì´í„° ì „ì²˜ë¦¬ -&gt; íŠ¹ì„± ê³µí•™ -&gt; ë°ì´í„°ì…‹ ë¶„ë¦¬ -&gt; ëª¨ë¸ë§ -&gt; í‰ê°€ íŒŒì´í”„ë¼ì¸ ë°©ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° -&gt; ë°ì´í„° ì „ì²˜ë¦¬ -&gt; ë°ì´í„°ì…‹ ë¶„ë¦¬ -&gt; íŒŒì´í”„ë¼ì¸ êµ¬ì¶•(í”¼ì²˜ê³µí•™, ëª¨ë¸ë§) -&gt; í‰ê°€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°1234import pandas as pdimport numpy as npdata = pd.read_csv(&#x27;https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/daily-bike-share.csv&#x27;)data.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 731 entries, 0 to 730 Data columns (total 14 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 instant 731 non-null int64 1 dteday 731 non-null object 2 season 731 non-null int64 3 yr 731 non-null int64 4 mnth 731 non-null int64 5 holiday 731 non-null int64 6 weekday 731 non-null int64 7 workingday 731 non-null int64 8 weathersit 731 non-null int64 9 temp 731 non-null float64 10 atemp 731 non-null float64 11 hum 731 non-null float64 12 windspeed 731 non-null float64 13 rentals 731 non-null int64 dtypes: float64(4), int64(9), object(1) memory usage: 80.1+ KB 12345from sklearn.model_selection import train_test_splitX = data.drop(&#x27;rentals&#x27;,axis=1)y = data[&#x27;rentals&#x27;]X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123) Pipeline êµ¬ì¶•ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸12345678910111213141516171819202122232425262728293031323334353637from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoderfrom sklearn.impute import SimpleImputerfrom sklearn.compose import ColumnTransformerfrom sklearn.pipeline import Pipeline# ìˆ˜ì¹˜í˜• ë°ì´í„°numeric_transformer = Pipeline(steps=[ (&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;mean&#x27;)) ,(&#x27;scaler&#x27;, StandardScaler())])# ì„œì—´í˜• ë°ì´í„°ordinal_transformer = Pipeline(steps=[ (&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;constant&#x27;)) ,(&#x27;ordEncoder&#x27;, OrdinalEncoder())])# ëª…ëª©í˜• ë°ì´í„°onehot_transformer = Pipeline(steps=[ (&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;constant&#x27;)) ,(&#x27;oheEncoder&#x27;, OneHotEncoder()) ])# ìˆ˜ì¹˜í˜• ë°ì´í„° ë° Categorical ë°ì´í„° ì»¬ëŸ¼ ë¶„ë¦¬numeric_features = [&#x27;temp&#x27;, &#x27;atemp&#x27;, &#x27;hum&#x27;, &#x27;windspeed&#x27;]ordinal_features = [&#x27;holiday&#x27;, &#x27;weekday&#x27;, &#x27;workingday&#x27;, &#x27;weathersit&#x27;]onehot_features = [&#x27;season&#x27;, &#x27;mnth&#x27;]# numeric_features = data.select_dtypes(include=[&#x27;int64&#x27;, &#x27;float64&#x27;]).columns# categorical_features = data.select_dtypes(include=[&#x27;object&#x27;]).drop([&#x27;Loan_Status&#x27;], axis=1).columnspreprocessor = ColumnTransformer( transformers=[ (&#x27;numeric&#x27;, numeric_transformer, numeric_features) , (&#x27;ord_categorical&#x27;, ordinal_transformer, ordinal_features) , (&#x27;ohe_categorical&#x27;, onehot_transformer, onehot_features)]) ëª¨ë¸ ì ìš© íŒŒì´í”„ë¼ì¸123456789from sklearn.ensemble import RandomForestRegressorpipeline = Pipeline(steps = [ (&#x27;preprocessor&#x27;, preprocessor) # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ,(&#x27;regressor&#x27;, RandomForestRegressor()) # ëª¨ë¸ ì—°ê²° ])rf_model = pipeline.fit(X_train, y_train)print(rf_model) Pipeline(steps=[(&#39;preprocessor&#39;, ColumnTransformer(transformers=[(&#39;numeric&#39;, Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer()), (&#39;scaler&#39;, StandardScaler())]), [&#39;temp&#39;, &#39;atemp&#39;, &#39;hum&#39;, &#39;windspeed&#39;]), (&#39;ord_categorical&#39;, Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;)), (&#39;ordEncoder&#39;, OrdinalEncoder())]), [&#39;holiday&#39;, &#39;weekday&#39;, &#39;workingday&#39;, &#39;weathersit&#39;]), (&#39;ohe_categorical&#39;, Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;)), (&#39;oheEncoder&#39;, OneHotEncoder())]), [&#39;season&#39;, &#39;mnth&#39;])])), (&#39;regressor&#39;, RandomForestRegressor())]) ëª¨ë¸ í‰ê°€123from sklearn.metrics import r2_scorepredictions = rf_model.predict(X_val)print (r2_score(y_val, predictions)) 0.7654903256614782 ë‹¤ì¤‘ ëª¨í˜• ê°œë°œ1234567891011121314151617181920from sklearn.ensemble import RandomForestRegressorfrom sklearn.tree import DecisionTreeRegressorfrom sklearn.linear_model import LinearRegressionregressors = [ RandomForestRegressor(), DecisionTreeRegressor(), LinearRegression()]# regressors = [pipe_rf, pipe_dt]for regressor in regressors: pipeline = Pipeline(steps = [ (&#x27;preprocessor&#x27;, preprocessor) ,(&#x27;regressor&#x27;,regressor) ]) model = pipeline.fit(X_train, y_train) predictions = model.predict(X_val) print(regressor) print(f&#x27;Model r2 score:&#123;r2_score(predictions, y_val)&#125;&#x27;) RandomForestRegressor() Model r2 score:0.7447806201844671 DecisionTreeRegressor() Model r2 score:0.5885371412997458 LinearRegression() Model r2 score:0.5703227526319388","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"},{"name":"pipeline","slug":"pipeline","permalink":"http://gonekng.github.io/tags/pipeline/"}],"author":"Jiwon Kang"},{"title":"ML Practice 7_3","slug":"Python/ML/ML_ch_7_3","date":"2022-04-05T03:14:17.000Z","updated":"2022-10-05T05:39:53.612Z","comments":true,"path":"2022/04/05/Python/ML/ML_ch_7_3/","link":"","permalink":"http://gonekng.github.io/2022/04/05/Python/ML/ML_ch_7_3/","excerpt":"","text":"Create DNN Model12345678910from tensorflow import kerasfrom sklearn.model_selection import train_test_split(train_input, train_target), (test_input, test_target) = \\ keras.datasets.fashion_mnist.load_data()train_scaled = train_input / 255.0train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz 32768/29515 [=================================] - 0s 0us/step 40960/29515 [=========================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz 26427392/26421880 [==============================] - 0s 0us/step 26435584/26421880 [==============================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz 16384/5148 [===============================================================================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz 4423680/4422102 [==============================] - 0s 0us/step 4431872/4422102 [==============================] - 0s 0us/step Define function of create model 1234567891011def model_fn(a_layer=None): model = keras.Sequential() model.add(keras.layers.Flatten(input_shape=(28,28))) model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;)) if a_layer: model.add(a_layer) model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) return model model = model_fn()model.summary &lt;bound method Model.summary of &lt;keras.engine.sequential.Sequential object at 0x7f9181716750&gt;&gt; Loss Curve12model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)history = model.fit(train_scaled, train_target, epochs = 5, verbose = 0) verbose default 1: print the indicator along with the progress bar per epoch. verbose 2: print the indicator without the progress bar per epoch. verbose 0: print none 123print(history) # classprint(history.history) # dictionaryprint(history.history.keys()) &lt;keras.callbacks.History object at 0x7f917bab27d0&gt; &#123;&#39;loss&#39;: [0.5360119342803955, 0.3935061991214752, 0.3552784025669098, 0.33411645889282227, 0.31946054100990295], &#39;accuracy&#39;: [0.8113541603088379, 0.8598541617393494, 0.8732083439826965, 0.8820000290870667, 0.8862708210945129]&#125; dict_keys([&#39;loss&#39;, &#39;accuracy&#39;]) loss curve (epoch 5) 123456import matplotlib.pyplot as pltplt.plot(history.history[&#x27;loss&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.show() accuracy curve (epoch 5) 1234plt.plot(history.history[&#x27;accuracy&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;accuracy&#x27;)plt.show() loss curve (epoch 20) 12345678model = model_fn()model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)history = model.fit(train_scaled, train_target, epochs=20, verbose=0)plt.plot(history.history[&#x27;loss&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.show() Validation Loss123456789101112model = model_fn()model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)history = model.fit(train_scaled, train_target, epochs=20, verbose=1, validation_data=(val_scaled, val_target))plt.plot(history.history[&#x27;loss&#x27;])plt.plot(history.history[&#x27;val_loss&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() Epoch 1/20 1500/1500 [==============================] - 6s 4ms/step - loss: 0.5344 - accuracy: 0.8118 - val_loss: 0.4414 - val_accuracy: 0.8471 Epoch 2/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3950 - accuracy: 0.8577 - val_loss: 0.3638 - val_accuracy: 0.8668 Epoch 3/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3573 - accuracy: 0.8702 - val_loss: 0.3754 - val_accuracy: 0.8682 Epoch 4/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3365 - accuracy: 0.8791 - val_loss: 0.3783 - val_accuracy: 0.8701 Epoch 5/20 1500/1500 [==============================] - 5s 4ms/step - loss: 0.3191 - accuracy: 0.8865 - val_loss: 0.3576 - val_accuracy: 0.8772 Epoch 6/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3085 - accuracy: 0.8898 - val_loss: 0.3556 - val_accuracy: 0.8806 Epoch 7/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2982 - accuracy: 0.8948 - val_loss: 0.3736 - val_accuracy: 0.8807 Epoch 8/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2910 - accuracy: 0.8976 - val_loss: 0.3443 - val_accuracy: 0.8869 Epoch 9/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2841 - accuracy: 0.8998 - val_loss: 0.3757 - val_accuracy: 0.8832 Epoch 10/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2755 - accuracy: 0.9031 - val_loss: 0.4034 - val_accuracy: 0.8766 Epoch 11/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2700 - accuracy: 0.9059 - val_loss: 0.4085 - val_accuracy: 0.8792 Epoch 12/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2655 - accuracy: 0.9075 - val_loss: 0.3936 - val_accuracy: 0.8835 Epoch 13/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2589 - accuracy: 0.9105 - val_loss: 0.4122 - val_accuracy: 0.8812 Epoch 14/20 1500/1500 [==============================] - 5s 4ms/step - loss: 0.2545 - accuracy: 0.9116 - val_loss: 0.4056 - val_accuracy: 0.8842 Epoch 15/20 1500/1500 [==============================] - 6s 4ms/step - loss: 0.2506 - accuracy: 0.9137 - val_loss: 0.4048 - val_accuracy: 0.8815 Epoch 16/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2454 - accuracy: 0.9159 - val_loss: 0.4132 - val_accuracy: 0.8808 Epoch 17/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2410 - accuracy: 0.9177 - val_loss: 0.4343 - val_accuracy: 0.8831 Epoch 18/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2356 - accuracy: 0.9190 - val_loss: 0.4574 - val_accuracy: 0.8767 Epoch 19/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2326 - accuracy: 0.9201 - val_loss: 0.4499 - val_accuracy: 0.8817 Epoch 20/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.2284 - accuracy: 0.9204 - val_loss: 0.4834 - val_accuracy: 0.8751 There is a large difference in loss between training data and verification data. This is a typical overfitting model. 12345678910111213model = model_fn()model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)history = model.fit(train_scaled, train_target, epochs=20, verbose=1, validation_data=(val_scaled, val_target))plt.plot(history.history[&#x27;loss&#x27;])plt.plot(history.history[&#x27;val_loss&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() Epoch 1/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.5231 - accuracy: 0.8183 - val_loss: 0.4741 - val_accuracy: 0.8357 Epoch 2/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3940 - accuracy: 0.8576 - val_loss: 0.3736 - val_accuracy: 0.8671 Epoch 3/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3557 - accuracy: 0.8703 - val_loss: 0.3567 - val_accuracy: 0.8712 Epoch 4/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3273 - accuracy: 0.8796 - val_loss: 0.3398 - val_accuracy: 0.8790 Epoch 5/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3091 - accuracy: 0.8872 - val_loss: 0.3324 - val_accuracy: 0.8803 Epoch 6/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2904 - accuracy: 0.8925 - val_loss: 0.3194 - val_accuracy: 0.8842 Epoch 7/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2802 - accuracy: 0.8967 - val_loss: 0.3333 - val_accuracy: 0.8796 Epoch 8/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2679 - accuracy: 0.9010 - val_loss: 0.3265 - val_accuracy: 0.8830 Epoch 9/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2588 - accuracy: 0.9040 - val_loss: 0.3298 - val_accuracy: 0.8858 Epoch 10/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2482 - accuracy: 0.9068 - val_loss: 0.3282 - val_accuracy: 0.8840 Epoch 11/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2413 - accuracy: 0.9094 - val_loss: 0.3098 - val_accuracy: 0.8889 Epoch 12/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2315 - accuracy: 0.9131 - val_loss: 0.3250 - val_accuracy: 0.8867 Epoch 13/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2260 - accuracy: 0.9141 - val_loss: 0.3164 - val_accuracy: 0.8911 Epoch 14/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2181 - accuracy: 0.9185 - val_loss: 0.3511 - val_accuracy: 0.8774 Epoch 15/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2128 - accuracy: 0.9200 - val_loss: 0.3397 - val_accuracy: 0.8817 Epoch 16/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2059 - accuracy: 0.9222 - val_loss: 0.3219 - val_accuracy: 0.8903 Epoch 17/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2021 - accuracy: 0.9240 - val_loss: 0.3423 - val_accuracy: 0.8859 Epoch 18/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.1952 - accuracy: 0.9277 - val_loss: 0.3313 - val_accuracy: 0.8916 Epoch 19/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.1918 - accuracy: 0.9272 - val_loss: 0.3396 - val_accuracy: 0.8871 Epoch 20/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.1879 - accuracy: 0.9295 - val_loss: 0.3354 - val_accuracy: 0.8904 Overfitting has decreased a little, but it is still necessary to improve. Dropout Basically, it is a principle to calculate all parameters. Neurons without some output are excluded from the calculation. 12model = model_fn(keras.layers.Dropout(0.3)) # drop out 30%model.summary() Model: &quot;sequential_5&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten_5 (Flatten) (None, 784) 0 dense_10 (Dense) (None, 100) 78500 dropout (Dropout) (None, 100) 0 dense_11 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 123456789101112model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)history = model.fit(train_scaled, train_target, epochs=20, verbose=1, validation_data=(val_scaled, val_target))plt.plot(history.history[&#x27;loss&#x27;])plt.plot(history.history[&#x27;val_loss&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() Epoch 1/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.5967 - accuracy: 0.7907 - val_loss: 0.4495 - val_accuracy: 0.8294 Epoch 2/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.4413 - accuracy: 0.8409 - val_loss: 0.4071 - val_accuracy: 0.8472 Epoch 3/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.4044 - accuracy: 0.8547 - val_loss: 0.3616 - val_accuracy: 0.8674 Epoch 4/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3833 - accuracy: 0.8603 - val_loss: 0.3605 - val_accuracy: 0.8651 Epoch 5/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3688 - accuracy: 0.8646 - val_loss: 0.3423 - val_accuracy: 0.8750 Epoch 6/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3542 - accuracy: 0.8696 - val_loss: 0.3479 - val_accuracy: 0.8744 Epoch 7/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3439 - accuracy: 0.8725 - val_loss: 0.3449 - val_accuracy: 0.8752 Epoch 8/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3356 - accuracy: 0.8763 - val_loss: 0.3356 - val_accuracy: 0.8802 Epoch 9/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3280 - accuracy: 0.8796 - val_loss: 0.3361 - val_accuracy: 0.8801 Epoch 10/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3212 - accuracy: 0.8781 - val_loss: 0.3394 - val_accuracy: 0.8734 Epoch 11/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3200 - accuracy: 0.8813 - val_loss: 0.3327 - val_accuracy: 0.8763 Epoch 12/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3115 - accuracy: 0.8852 - val_loss: 0.3325 - val_accuracy: 0.8776 Epoch 13/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3061 - accuracy: 0.8860 - val_loss: 0.3216 - val_accuracy: 0.8860 Epoch 14/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3034 - accuracy: 0.8860 - val_loss: 0.3193 - val_accuracy: 0.8864 Epoch 15/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2961 - accuracy: 0.8880 - val_loss: 0.3198 - val_accuracy: 0.8846 Epoch 16/20 1500/1500 [==============================] - 4s 2ms/step - loss: 0.2913 - accuracy: 0.8900 - val_loss: 0.3310 - val_accuracy: 0.8823 Epoch 17/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2870 - accuracy: 0.8933 - val_loss: 0.3162 - val_accuracy: 0.8848 Epoch 18/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2838 - accuracy: 0.8931 - val_loss: 0.3321 - val_accuracy: 0.8838 Epoch 19/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2829 - accuracy: 0.8935 - val_loss: 0.3320 - val_accuracy: 0.8840 Epoch 20/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2814 - accuracy: 0.8942 - val_loss: 0.3218 - val_accuracy: 0.8882 Overfitting has improved a lot. Save and Load Model123456model = model_fn(keras.layers.Dropout(0.3))model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)history = model.fit(train_scaled, train_target, epochs=10, verbose=0, validation_data=(val_scaled, val_target)) save_weights() : method of saving the parameters of a model save() : method of saving both the parameters and structure of a model â€˜.h5â€™ : HDF5 format 12model.save_weights(&#x27;model-weights.h5&#x27;)model.save(&#x27;model-whole.h5&#x27;) 1!ls -al *.h5 -rw-r--r-- 1 root root 982664 Apr 5 02:37 best-model.h5 -rw-r--r-- 1 root root 333448 Apr 5 02:42 model-weights.h5 -rw-r--r-- 1 root root 982664 Apr 5 02:42 model-whole.h5 load previously saved parameters 12model = model_fn(keras.layers.Dropout(0.3))model.load_weights(&#x27;model-weights.h5&#x27;) 1234# Returns the largest value in the predict method resultimport numpy as npval_labels = np.argmax(model.predict(val_scaled), axis=-1)print(np.mean(val_labels == val_target)) 0.8825833333333334 load previously saved model 12model = keras.models.load_model(&#x27;model-whole.h5&#x27;)model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8826 [0.3247545063495636, 0.8825833201408386] Callback12345678910model = model_fn(keras.layers.Dropout(0.3))model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-model.h5&#x27;, save_best_only=True)model.fit(train_scaled, train_target, epochs=20, verbose=1, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb]) Epoch 1/20 1500/1500 [==============================] - 5s 3ms/step - loss: 0.5955 - accuracy: 0.7909 - val_loss: 0.4305 - val_accuracy: 0.8437 Epoch 2/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.4369 - accuracy: 0.8436 - val_loss: 0.3847 - val_accuracy: 0.8572 Epoch 3/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.4027 - accuracy: 0.8533 - val_loss: 0.3737 - val_accuracy: 0.8633 Epoch 4/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3833 - accuracy: 0.8607 - val_loss: 0.3648 - val_accuracy: 0.8628 Epoch 5/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3675 - accuracy: 0.8662 - val_loss: 0.3481 - val_accuracy: 0.8703 Epoch 6/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3544 - accuracy: 0.8710 - val_loss: 0.3434 - val_accuracy: 0.8758 Epoch 7/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3435 - accuracy: 0.8736 - val_loss: 0.3388 - val_accuracy: 0.8781 Epoch 8/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3360 - accuracy: 0.8759 - val_loss: 0.3333 - val_accuracy: 0.8760 Epoch 9/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3261 - accuracy: 0.8777 - val_loss: 0.3333 - val_accuracy: 0.8755 Epoch 10/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3203 - accuracy: 0.8808 - val_loss: 0.3319 - val_accuracy: 0.8807 Epoch 11/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3154 - accuracy: 0.8822 - val_loss: 0.3275 - val_accuracy: 0.8794 Epoch 12/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3063 - accuracy: 0.8849 - val_loss: 0.3206 - val_accuracy: 0.8842 Epoch 13/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3024 - accuracy: 0.8871 - val_loss: 0.3239 - val_accuracy: 0.8815 Epoch 14/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3002 - accuracy: 0.8882 - val_loss: 0.3249 - val_accuracy: 0.8838 Epoch 15/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2928 - accuracy: 0.8911 - val_loss: 0.3237 - val_accuracy: 0.8827 Epoch 16/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2891 - accuracy: 0.8911 - val_loss: 0.3216 - val_accuracy: 0.8839 Epoch 17/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2854 - accuracy: 0.8918 - val_loss: 0.3301 - val_accuracy: 0.8844 Epoch 18/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2834 - accuracy: 0.8942 - val_loss: 0.3315 - val_accuracy: 0.8833 Epoch 19/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2776 - accuracy: 0.8959 - val_loss: 0.3381 - val_accuracy: 0.8790 Epoch 20/20 1500/1500 [==============================] - 4s 3ms/step - loss: 0.2758 - accuracy: 0.8965 - val_loss: 0.3273 - val_accuracy: 0.8830 &lt;keras.callbacks.History at 0x7f916df86590&gt; 12model = keras.models.load_model(&#x27;best-model.h5&#x27;)model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8842 [0.32058343291282654, 0.8842499852180481] early stopping : to stop training before overfitting begins 12345678910model = model_fn(keras.layers.Dropout(0.3))model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)checkpoint_cb = keras.callbacks.ModelCheckpoint(&#x27;best-model.h5&#x27;, save_best_only=True)early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)history = model.fit(train_scaled, train_target, epochs=20, verbose=0, validation_data=(val_scaled, val_target), callbacks=[checkpoint_cb, early_stopping_cb]) 1print(early_stopping_cb.stopped_epoch) 5 123456plt.plot(history.history[&#x27;loss&#x27;])plt.plot(history.history[&#x27;val_loss&#x27;])plt.xlabel(&#x27;epoch&#x27;)plt.ylabel(&#x27;loss&#x27;)plt.legend([&#x27;train&#x27;, &#x27;val&#x27;])plt.show() It stopped early in 5 epoch, and the issue of overfitting was solved. Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 7_2","slug":"Python/ML/ML_ch_7_2","date":"2022-04-05T01:20:01.000Z","updated":"2022-10-05T05:39:53.531Z","comments":true,"path":"2022/04/05/Python/ML/ML_ch_7_2/","link":"","permalink":"http://gonekng.github.io/2022/04/05/Python/ML/ML_ch_7_2/","excerpt":"","text":"Prepare Dataset123from tensorflow import keras(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data() 1234567from sklearn.model_selection import train_test_splittrain_scaled = train_input / 255.0train_scaled = train_scaled.reshape(-1, 28*28)train_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) DNN Layer12345# hidden layer dense1 = keras.layers.Dense(100, activation=&#x27;sigmoid&#x27;, input_shape=(784,))# output layer dense2 = keras.layers.Dense(10, activation=&#x27;softmax&#x27;) 12model = keras.Sequential([dense1, dense2])model.summary() Model: &quot;sequential_3&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_9 (Dense) (None, 100) 78500 dense_10 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ Another way to add layers123456model = keras.Sequential([ keras.layers.Dense(12, activation=&#x27;sigmoid&#x27;, input_shape=(16,), name=&#x27;hidden&#x27;), keras.layers.Dense(10, activation=&#x27;softmax&#x27;, name=&#x27;hidden_2&#x27;), keras.layers.Dense(1, activation=&#x27;softmax&#x27;, name=&#x27;output&#x27;)], name=&#x27;fashion MNIST&#x27;)model.summary() Model: &quot;fashion MNIST&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= hidden (Dense) (None, 12) 204 hidden_2 (Dense) (None, 10) 130 output (Dense) (None, 1) 11 ================================================================= Total params: 345 Trainable params: 345 Non-trainable params: 0 _________________________________________________________________ 1234model = keras.Sequential()model.add(keras.layers.Dense(100, activation=&#x27;sigmoid&#x27;, input_shape=(784,)))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;))model.summary() Model: &quot;sequential_4&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_11 (Dense) (None, 100) 78500 dense_12 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 12model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.5627 - accuracy: 0.8077 Epoch 2/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.4080 - accuracy: 0.8529 Epoch 3/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3740 - accuracy: 0.8660 Epoch 4/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3508 - accuracy: 0.8720 Epoch 5/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3345 - accuracy: 0.8810 &lt;keras.callbacks.History at 0x7fcf5e9c8810&gt; Relu function12345model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;))model.summary() Model: &quot;sequential_6&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten_2 (Flatten) (None, 784) 0 dense_16 (Dense) (None, 100) 78500 dense_17 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 1model.summary() Model: &quot;sequential_6&quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten_2 (Flatten) (None, 784) 0 dense_16 (Dense) (None, 100) 78500 dense_17 (Dense) (None, 10) 1010 ================================================================= Total params: 79,510 Trainable params: 79,510 Non-trainable params: 0 _________________________________________________________________ 123456(train_input, train_target), (test_input, test_target) =\\ keras.datasets.fashion_mnist.load_data()train_scaled = train_input / 255.0train_scaled, val_scaled, train_target, val_traget = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) 12model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.5362 - accuracy: 0.8096 Epoch 2/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3953 - accuracy: 0.8578 Epoch 3/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3570 - accuracy: 0.8722 Epoch 4/5 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3360 - accuracy: 0.8808 Epoch 5/5 1500/1500 [==============================] - 6s 4ms/step - loss: 0.3200 - accuracy: 0.8871 &lt;keras.callbacks.History at 0x7fcf5e813250&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3565 - accuracy: 0.8775 [0.35651248693466187, 0.8774999976158142] Optimizer a variety of gradient descent algorithms provided by Keras Optimizer have to consider both step direction and width direction : GD, SGD, Momentum, NAG width : GD, SGD, Adagrad, RMSProp direction &amp; width : Adam (generally, the best performance) SGDLearning rate: default 0.011234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) 123model.compile(optimizer=&#x27;sgd&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.8096 - accuracy: 0.7362 Epoch 2/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.5421 - accuracy: 0.8163 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4886 - accuracy: 0.8329 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4604 - accuracy: 0.8426 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4404 - accuracy: 0.8490 &lt;keras.callbacks.History at 0x7fcf5e524250&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 1ms/step - loss: 0.4474 - accuracy: 0.8464 [0.44738978147506714, 0.8464166522026062] Learning rate: 0.11234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) 1234sgd = keras.optimizers.SGD(learning_rate=0.1)model.compile(optimizer=sgd, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.5663 - accuracy: 0.7985 Epoch 2/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4148 - accuracy: 0.8493 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3765 - accuracy: 0.8620 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3503 - accuracy: 0.8707 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3315 - accuracy: 0.8777 &lt;keras.callbacks.History at 0x7fcf5e614e90&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3469 - accuracy: 0.8744 [0.3468727171421051, 0.8744166493415833] Nesterov momentum1234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) 1234sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)model.compile(optimizer=sgd, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.5365 - accuracy: 0.8099 Epoch 2/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4051 - accuracy: 0.8562 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3659 - accuracy: 0.8690 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3448 - accuracy: 0.8737 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3255 - accuracy: 0.8802 &lt;keras.callbacks.History at 0x7fcf5e1de1d0&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8718 [0.36112430691719055, 0.871833324432373] Adagrad1234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) 1234adagrad = keras.optimizers.Adagrad()model.compile(optimizer=adagrad, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 1.1751 - accuracy: 0.6441 Epoch 2/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.7733 - accuracy: 0.7556 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.6848 - accuracy: 0.7837 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.6372 - accuracy: 0.7972 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.6071 - accuracy: 0.8053 &lt;keras.callbacks.History at 0x7fcf5e480390&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 1ms/step - loss: 0.6081 - accuracy: 0.8025 [0.6081421375274658, 0.8025000095367432] RMSprop1234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) 1234rmsprop = keras.optimizers.RMSprop()model.compile(optimizer=rmsprop, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.5261 - accuracy: 0.8139 Epoch 2/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3931 - accuracy: 0.8598 Epoch 3/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.3556 - accuracy: 0.8733 Epoch 4/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3349 - accuracy: 0.8806 Epoch 5/5 1500/1500 [==============================] - 4s 3ms/step - loss: 0.3173 - accuracy: 0.8869 &lt;keras.callbacks.History at 0x7fcf5e374710&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8742 [0.3816753029823303, 0.8741666674613953] Adam1234model = keras.Sequential()model.add(keras.layers.Flatten(input_shape=(28,28)))model.add(keras.layers.Dense(100, activation=&#x27;relu&#x27;))model.add(keras.layers.Dense(10, activation=&#x27;softmax&#x27;)) 123model.compile(optimizer=&#x27;adam&#x27;, loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;)model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.5273 - accuracy: 0.8153 Epoch 2/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3943 - accuracy: 0.8584 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3522 - accuracy: 0.8727 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.3264 - accuracy: 0.8815 Epoch 5/5 1500/1500 [==============================] - 5s 3ms/step - loss: 0.3074 - accuracy: 0.8882 &lt;keras.callbacks.History at 0x7fcf5e47b050&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8788 [0.33555400371551514, 0.8788333535194397] Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 7_1","slug":"Python/ML/ML_ch_7_1","date":"2022-04-04T01:25:10.000Z","updated":"2022-10-05T05:39:53.444Z","comments":true,"path":"2022/04/04/Python/ML/ML_ch_7_1/","link":"","permalink":"http://gonekng.github.io/2022/04/04/Python/ML/ML_ch_7_1/","excerpt":"","text":"Fashion MNISTDeep Learning Library tensorflow : https://www.tensorflow.org/ pytorch : https://pytorch.org/ 12import tensorflowprint(tensorflow.__version__) 2.8.0 Load Data12from tensorflow import keras(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data() 60,000 images, which is 28 * 28 size 12print(train_input.shape, train_target.shape)print(test_input.shape, test_target.shape) (60000, 28, 28) (60000,) (10000, 28, 28) (10000,) image visualization 123456import matplotlib.pyplot as pltfig, axs = plt.subplots(1, 10, figsize=(10, 10))for i in range(10): axs[i].imshow(train_input[i], cmap=&quot;gray_r&quot;) axs[i].axis(&#x27;off&#x27;)plt.show() list of target values 1print([train_target[i] for i in range(10)]) [9, 0, 0, 3, 0, 2, 7, 2, 5, 5] real target values 6,000 images per label. 12import numpy as npprint(np.unique(train_target, return_counts=True)) (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])) Classify by Logistic Regression123train_scaled = train_input / 255.0train_scaled = train_scaled.reshape(-1, 28*28)print(train_scaled.shape) (60000, 784) 1234567from sklearn.model_selection import cross_validatefrom sklearn.linear_model import SGDClassifiersc = SGDClassifier(loss=&#x27;log&#x27;, max_iter=10, random_state=42)scores = cross_validate(sc, train_scaled, train_target, n_jobs=-1)print(np.mean(scores[&#x27;test_score&#x27;])) # 0.82 0.8243124999999999 Is it reasonable to apply a linear or nonlinear model to unstructured data? : No One alternative is artificial neural networks. Is it reasonable to apply artificial neural networks and deep learning models to structured data? : No Classify by Artificial Neural Network1234from sklearn.model_selection import train_test_splittrain_scaled, val_scaled, train_target, val_target = train_test_split( train_scaled, train_target, test_size=0.2, random_state=42) 12print(train_scaled.shape, train_target.shape)print(val_scaled.shape, val_target.shape) (48000, 784) (48000,) (12000, 784) (12000,) A dense connection is called a fully connected layer. Specify activation functions to be applied to neuronal output binary classification : Sigmoid function multi classification : Softmax function specifying the type of loss function binary classification : binary_crossentropy multi classification : catogorical_crossentropy The integer target value should be one-hot encoded as 0, 1, 2, etc.but it can distort the operation of the artificial neural network. In tensorflow, by using sparse_categorical_crossentropy as a loss function, an integer target value can be used as it is. 123dense = keras.layers.Dense(10, activation = &quot;softmax&quot;, input_shape=(784, ))model = keras.Sequential(dense)model.compile(loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=&#x27;accuracy&#x27;) 1print(train_target[:10]) [7 3 5 8 6 9 3 3 9 9] 1model.fit(train_scaled, train_target, epochs=5) Epoch 1/5 1500/1500 [==============================] - 4s 2ms/step - loss: 0.6125 - accuracy: 0.7900 Epoch 2/5 1500/1500 [==============================] - 2s 2ms/step - loss: 0.4797 - accuracy: 0.8402 Epoch 3/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4562 - accuracy: 0.8479 Epoch 4/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4457 - accuracy: 0.8524 Epoch 5/5 1500/1500 [==============================] - 3s 2ms/step - loss: 0.4365 - accuracy: 0.8549 &lt;keras.callbacks.History at 0x7efd2ea9ded0&gt; 1model.evaluate(val_scaled, val_target) 375/375 [==============================] - 1s 1ms/step - loss: 0.4553 - accuracy: 0.8475 [0.45534512400627136, 0.8475000262260437] Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 6_3","slug":"Python/ML/ML_ch_6_3","date":"2022-03-31T08:05:57.000Z","updated":"2022-10-05T05:39:53.364Z","comments":true,"path":"2022/03/31/Python/ML/ML_ch_6_3/","link":"","permalink":"http://gonekng.github.io/2022/03/31/Python/ML/ML_ch_6_3/","excerpt":"","text":"Dimensionaliy Reduction: Decreasing the size of the data by selecting some features that best represent the data To prevent overfitting and improve model performance PCA(Principal Component Analysis), LDA(Linear Discriminant Analysis), etc PCA principal component(PC) axis of data with the highest variance when projected on an axis expressed as a linear combination of existing variables Generally, it can be found as many as the features of the data as possible. To explain the overall variation with 2 to 3 principal component Import Data1234!wget https://bit.ly/fruits_300_data -O fruits_300.npyimport numpy as npfruits = np.load(&#x27;fruits_300.npy&#x27;)fruits_2d = fruits.reshape(-1, 100*100) --2022-03-31 06:10:20-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11 Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-03-31 06:10:20-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 192.30.255.112 Connecting to github.com (github.com)|192.30.255.112|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-03-31 06:10:20-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: â€˜fruits_300.npyâ€™ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.04s 2022-03-31 06:10:21 (79.3 MB/s) - â€˜fruits_300.npyâ€™ saved [3000128/3000128] PCA Model1234from sklearn.decomposition import PCApca = PCA(n_components=50)pca.fit(fruits_2d)print(pca.components_.shape) (50, 10000) 1234567891011121314import matplotlib.pyplot as pltdef draw_fruits(arr, ratio=1): n = len(arr) # the number of sample rows = int(np.ceil(n/10)) cols = n if rows &lt; 2 else 10 fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False) for i in range(rows): for j in range(cols): if i*10 + j &lt; n: # n ê°œê¹Œì§€ë§Œ ê·¸ë¦½ë‹ˆë‹¤. axs[i, j].imshow(arr[i*10 + j], cmap=&#x27;gray_r&#x27;) axs[i, j].axis(&#x27;off&#x27;) plt.show() 1draw_fruits(pca.components_.reshape(-1, 100, 100)) 123print(fruits_2d.shape) # 10000 featuresfruits_pca = pca.transform(fruits_2d)print(fruits_pca.shape) # 50 features (300, 10000) (300, 50) reduced to 1&#x2F;200 compared to the original size of the data Reconstruction of original data1234fruits_inverse = pca.inverse_transform(fruits_pca)print(fruits_inverse.shape)fruits_reconstruct = fruits_inverse.reshape(-1, 100, 100)print(fruits_reconstruct.shape) (300, 10000) (300, 100, 100) 1draw_fruits(fruits_reconstruct[0:100]) 1draw_fruits(fruits_reconstruct[100:200]) 1draw_fruits(fruits_reconstruct[200:300]) Even though 10,000 features were reduced to 50, the original data were preserved fairly well. Explained Variance: How well the principal component represents the variance of the original data.1print(np.cumsum(pca.explained_variance_ratio_)) 0.9215624972723878 [0.42357017 0.52298772 0.58876636 0.62907807 0.66324682 0.69606011 0.72179277 0.7423424 0.75606517 0.76949289 0.78101436 0.79046031 0.79924263 0.8077096 0.8146401 0.82109198 0.82688094 0.83199296 0.83685678 0.84166025 0.8461386 0.85051178 0.85459218 0.85848695 0.86221133 0.86580421 0.86911888 0.87229685 0.87534014 0.87837793 0.8812672 0.88402533 0.88667509 0.88923363 0.89175254 0.8942257 0.89662179 0.89893062 0.90115012 0.90331513 0.90544476 0.90740924 0.90933715 0.91123892 0.91308592 0.91491101 0.91664894 0.91833369 0.91995394 0.9215625 ] 123fig, ax = plt.subplots()ax.plot(pca.explained_variance_ratio_)plt.show() The first 10 PC represent most variance of the data. Subsequent PC could hardly explain the variance of the data. Use with other algorithms. Logistic Regression of 3 classes 1234from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()target = np.array([0]*100 + [1]*100 + [2]*100) # create target values cross-validation with original data 1234from sklearn.model_selection import cross_validatescores = cross_validate(lr, fruits_2d, target)print(np.mean(scores[&#x27;test_score&#x27;]))print(np.mean(scores[&#x27;fit_time&#x27;])) 0.9966666666666667 1.511155652999878 cross-validation with reduced data in PCA 123scores = cross_validate(lr, fruits_pca, target)print(np.mean(scores[&#x27;test_score&#x27;]))print(np.mean(scores[&#x27;fit_time&#x27;])) 1.0 0.07492985725402831 Specify the variance ratio123pca = PCA(n_components=0.5)pca.fit(fruits_2d)print(pca.n_components_) # 2 PC needed 2 12fruits_pca = pca.transform(fruits_2d)print(fruits_pca.shape) (300, 2) 123scores = cross_validate(lr, fruits_pca, target)print(np.mean(scores[&#x27;test_score&#x27;]))print(np.mean(scores[&#x27;fit_time&#x27;])) 0.9933333333333334 0.03829236030578613 /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG, /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG, /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG, 12345from sklearn.cluster import KMeanskm = KMeans(n_clusters=3, random_state=42)km.fit(fruits_pca)print(np.unique(km.labels_, return_counts=True))# label 0: 110 / label 1: 99 / label 2: 91 (array([0, 1, 2], dtype=int32), array([110, 99, 91])) 1draw_fruits(fruits[km.labels_==0]) 1draw_fruits(fruits[km.labels_==1]) 1draw_fruits(fruits[km.labels_==2]) 123456fig, ax = plt.subplots()for label in range(3): data = fruits_pca[km.labels_==label] ax.scatter(data[:,0], data[:,1])ax.legend([&#x27;apple&#x27;,&#x27;banana&#x27;,&#x27;pineapple&#x27;])plt.show() Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 6_2","slug":"Python/ML/ML_ch_6_2","date":"2022-03-31T08:04:50.000Z","updated":"2022-10-05T05:39:53.285Z","comments":true,"path":"2022/03/31/Python/ML/ML_ch_6_2/","link":"","permalink":"http://gonekng.github.io/2022/03/31/Python/ML/ML_ch_6_2/","excerpt":"","text":"K-means Clustering Find mean of pixel value : cluster center, centroid Determine the centers of k clusters at random. Find the nearest cluster center from each sample and designate it as a sample of that cluster. Change the center of the cluster to the average value of the samples belonging to the cluster. Repeat 2~3 until there is no change in the center of the cluster. Import Data1!wget https://bit.ly/fruits_300_data -O fruits_300.npy --2022-03-31 02:09:21-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11 Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-03-31 02:09:21-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 140.82.114.3 Connecting to github.com (github.com)|140.82.114.3|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-03-31 02:09:22-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: â€˜fruits_300.npyâ€™ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.01s 2022-03-31 02:09:22 (223 MB/s) - â€˜fruits_300.npyâ€™ saved [3000128/3000128] 1234import numpy as npfruits = np.load(&#x27;fruits_300.npy&#x27;)print(fruits.shape) (300, 100, 100) 12fruits_2d = fruits.reshape(-1, 100*100)print(fruits_2d.shape) (300, 10000) KMeans Class123from sklearn.cluster import KMeanskm = KMeans(n_clusters=3, random_state=42)km.fit(fruits_2d) # no target KMeans(n_clusters=3, random_state=42) 1print(km.labels_) # labels : [0, 1, 2] [2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] 12print(np.unique(km.labels_, return_counts=True))# label 0: 111 samples / label 1: 98 samples / label 2: 91 samples (array([0, 1, 2], dtype=int32), array([111, 98, 91])) Images of each label1234567891011121314import matplotlib.pyplot as pltdef draw_fruits(arr, ratio=1): n = len(arr) # the number of sample rows = int(np.ceil(n/10)) cols = n if rows &lt; 2 else 10 fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False) for i in range(rows): for j in range(cols): if i*10 + j &lt; n: # n ê°œê¹Œì§€ë§Œ ê·¸ë¦½ë‹ˆë‹¤. axs[i, j].imshow(arr[i*10 + j], cmap=&#x27;gray_r&#x27;) axs[i, j].axis(&#x27;off&#x27;) plt.show() 1draw_fruits(fruits[km.labels_==0]) 1draw_fruits(fruits[km.labels_==1]) 1draw_fruits(fruits[km.labels_==2]) label 0: mostly pineapples label 1: mostly bananas label 2: mostly apples Centroid1print(km.cluster_centers_.shape) (6, 10000) (6, 100, 100) 1draw_fruits(km.cluster_centers_.reshape(-1, 100, 100), ratio=3) 1print(km.transform(fruits_2d[100:101])) # two-dimension array input required [[3393.8136117 8837.37750892 5267.70439881]] 1print(km.predict(fruits_2d[100:101])) [0] 1draw_fruits(fruits[100:101]) Finding the best K (Elbow method) inertia : sum of squares of the distance between centroid and each sample As K increases, inertia decreases. Set the optimal K at the point where the inertia graph is bent. 1234567891011121314151617181920inertia = []for k in range(2,7): km = KMeans(n_clusters=k, random_state=42) km.fit(fruits_2d) inertia.append(km.inertia_)slope = []lst = []for idx, val in enumerate(inertia): if idx==0: slope.append(0) lst.append(0) else: slope.append(val - inertia[idx-1]) lst.append(slope[idx-1]-slope[idx])fig, ax = plt.subplots()ax.plot(range(2,7), inertia)ax.scatter(2+np.argmax(lst), inertia[np.argmax(lst)], marker=&quot;o&quot;, color=&quot;red&quot;)plt.show() Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 6_1","slug":"Python/ML/ML_ch_6_1","date":"2022-03-31T08:03:00.000Z","updated":"2022-10-05T05:39:53.204Z","comments":true,"path":"2022/03/31/Python/ML/ML_ch_6_1/","link":"","permalink":"http://gonekng.github.io/2022/03/31/Python/ML/ML_ch_6_1/","excerpt":"","text":"Unsupervised Learning No dependent variables and targets. (â†” Supervised Learning) Clustering (Multiple class) Must be many different types of data Linked to deep learning Dimensionality reduction Import Numpy Data1!wget https://bit.ly/fruits_300_data -O fruits_300.npy --2022-03-31 01:12:51-- https://bit.ly/fruits_300_data Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10 Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following] --2022-03-31 01:12:51-- https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy Resolving github.com (github.com)... 140.82.113.4 Connecting to github.com (github.com)|140.82.113.4|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following] --2022-03-31 01:12:51-- https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3000128 (2.9M) [application/octet-stream] Saving to: â€˜fruits_300.npyâ€™ fruits_300.npy 100%[===================&gt;] 2.86M --.-KB/s in 0.02s 2022-03-31 01:12:51 (157 MB/s) - â€˜fruits_300.npyâ€™ saved [3000128/3000128] 12345import numpy as np# 100 apples, 100 pineapples, 100 bananasfruits = np.load(&#x27;fruits_300.npy&#x27;)print(fruits.shape) (300, 100, 100) image samples of three dimensions dimension 1: the number of samples dimension 2: the height of image dimension 3: the width of image 300 pieces of image sample of 100 x 100 size. Visualize Image Data black-and-white photographs integer value from 0 to 255 1234import matplotlib.pyplot as pltplt.imshow(fruits[0], cmap=&#x27;gray&#x27;) # 0: black, 255: whiteplt.show() 12plt.imshow(fruits[0], cmap=&#x27;gray_r&#x27;) # 0: white, 255: blackplt.show() multiple images 1234fig, ax = plt.subplots(1,2)ax[0].imshow(fruits[100], cmap=&#x27;gray_r&#x27;)ax[1].imshow(fruits[200], cmap=&#x27;gray_r&#x27;)plt.show() Pixel value analysis12345# convert 100*100 images to one-dimensional array with a length of 10000apple = fruits[0:100].reshape(-1, 100*100)pineapple = fruits[100:200].reshape(-1, 100*100)banana = fruits[200:300].reshape(-1, 100*100)print(apple.shape, pineapple.shape, banana.shape) (100, 10000) (100, 10000) (100, 10000) average comparison of pixel values for each image 12345plt.hist(np.mean(apple, axis=1), alpha=0.8)plt.hist(np.mean(pineapple, axis=1), alpha=0.8)plt.hist(np.mean(banana, axis=1), alpha=0.8)plt.legend([&#x27;apple&#x27;,&#x27;pineapple&#x27;,&#x27;banana&#x27;])plt.show() 12345fig, ax = plt.subplots(1,3,figsize=(15,5))ax[0].bar(range(10000),np.mean(apple, axis=0))ax[1].bar(range(10000),np.mean(pineapple, axis=0))ax[2].bar(range(10000),np.mean(banana, axis=0))plt.show() representative image using pixel mean 123456789apple_mean = np.mean(apple, axis=0).reshape(100,100)pineapple_mean = np.mean(pineapple, axis=0).reshape(100,100)banana_mean = np.mean(banana, axis=0).reshape(100,100)fig, ax = plt.subplots(1,3,figsize=(15,5))ax[0].imshow(apple_mean, cmap=&#x27;gray_r&#x27;)ax[1].imshow(pineapple_mean, cmap=&#x27;gray_r&#x27;)ax[2].imshow(banana_mean, cmap=&#x27;gray_r&#x27;)plt.show() 100 images close to the average value 1234# MAE(Mean Absolute Error)abs_diff = np.abs(fruits - apple_mean)abs_mean = np.mean(abs_diff, axis=(1,2))print(abs_mean.shape) # one-dimensions array (300,) 1234567apple_index = np.argsort(abs_mean)[:100] # extract 100 indexes in the smallest order of MAEfig, ax = plt.subplots(10,10,figsize=(10,10))for i in range(10): for j in range(10): ax[i,j].imshow(fruits[apple_index[i*10+j]], cmap=&#x27;gray_r&#x27;) ax[i,j].axis(&#x27;off&#x27;) # remove axisplt.show() 33 48 70 57 87 12 78 59 1 74 86 38 50 92 69 27 68 30 66 24 76 98 15 84 47 90 3 94 53 23 14 71 32 7 73 36 55 77 21 10 17 39 99 95 11 35 65 6 61 22 56 89 2 13 80 0 97 4 58 34 40 43 75 82 54 16 31 49 93 37 63 64 41 28 67 25 96 8 83 46 19 79 72 5 85 29 20 60 81 9 45 51 88 62 91 26 52 18 44 42 Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice Tree plot Example","slug":"Python/ML/plot_tree_ex","date":"2022-03-31T03:40:40.000Z","updated":"2022-10-05T05:39:54.111Z","comments":true,"path":"2022/03/31/Python/ML/plot_tree_ex/","link":"","permalink":"http://gonekng.github.io/2022/03/31/Python/ML/plot_tree_ex/","excerpt":"","text":"Goal : To change the color of tree plot1!pip install -U matplotlib Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.3) Collecting matplotlib Downloading matplotlib-3.5.1-cp39-cp39-win_amd64.whl (7.2 MB) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1) Requirement already satisfied: numpy&gt;=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.20.3) Requirement already satisfied: pillow&gt;=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0) Requirement already satisfied: cycler&gt;=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0) Requirement already satisfied: fonttools&gt;=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0) Requirement already satisfied: pyparsing&gt;=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4) Requirement already satisfied: python-dateutil&gt;=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2) Requirement already satisfied: packaging&gt;=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (21.0) Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler&gt;=0.10-&gt;matplotlib) (1.16.0) Installing collected packages: matplotlib Attempting uninstall: matplotlib Found existing installation: matplotlib 3.4.3 Uninstalling matplotlib-3.4.3: ERROR: Could not install packages due to an OSError: [WinError 5] ì•¡ì„¸ìŠ¤ê°€ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤: &#39;c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\__pycache__\\\\pylab.cpython-39.pyc&#39; Consider using the `--user` option or check the permissions. Stackflow Ex.1234567891011121314151617181920212223242526from matplotlib import pyplot as pltfrom matplotlib.colors import ListedColormap, to_rgbimport numpy as npfrom sklearn import treeX = np.random.rand(50, 2) * np.r_[100, 50]y = X[:, 0] - X[:, 1] &gt; 20clf = tree.DecisionTreeClassifier(random_state=2021)clf = clf.fit(X, y)fig, ax = plt.subplots(figsize=(15, 10))colors = [&#x27;crimson&#x27;, &#x27;dodgerblue&#x27;]artists = tree.plot_tree(clf, feature_names=[&quot;X&quot;, &quot;y&quot;], class_names=colors, filled=True, rounded=True)for artist, impurity, value in zip(artists, clf.tree_.impurity, clf.tree_.value): # let the max value decide the color; whiten the color depending on impurity (gini) r, g, b = to_rgb(colors[np.argmax(value)]) f = impurity * 2 # for N colors: f = impurity * N/(N-1) if N&gt;1 else 0 artist.get_bbox_patch().set_facecolor((f + (1-f)*r, f + (1-f)*g, f + (1-f)*b)) artist.get_bbox_patch().set_edgecolor(&#x27;black&#x27;)plt.tight_layout()plt.show() Iris Ex.Tree plot1234567891011121314151617181920212223%matplotlib inline import sklearnprint(sklearn.__version__)import matplotlibprint(matplotlib.__version__)from sklearn.datasets import load_irisfrom sklearn import tree import matplotlib.pyplot as pltiris = load_iris()print(iris.data.shape, iris.target.shape)print(&quot;feature names&quot;, iris.feature_names)print(&quot;class names&quot;, iris.target_names)dt = tree.DecisionTreeClassifier(random_state=0)dt.fit(iris.data, iris.target)fig, ax = plt.subplots(figsize=(18, 10))ax = tree.plot_tree(dt, max_depth = 2, filled=True, feature_names = iris.feature_names, class_names = iris.target_names)plt.show() 0.24.2 3.4.3 (150, 4) (150,) feature names [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;] class names [&#39;setosa&#39; &#39;versicolor&#39; &#39;virginica&#39;] matplotlib.text.Annotation123456789%matplotlib inlinefig, ax = plt.subplots(figsize=(15, 10))ax = tree.plot_tree(dt, max_depth = 2, filled=True, feature_names = iris.feature_names, class_names = iris.target_names)for i in range(0, len(ax)): print(type(ax[i])) &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; &lt;class &#39;matplotlib.text.Annotation&#39;&gt; get_bbox_patch() method 123456789%matplotlib inlinefig, ax = plt.subplots(figsize=(15, 10))ax = tree.plot_tree(dt, max_depth = 2, filled=True, feature_names = iris.feature_names, class_names = iris.target_names)for i in range(0, len(ax)): print(ax[i].get_bbox_patch()) # get patch properties (facecolor, edgewidth,,,) FancyBboxPatch((0, 0), width=120.875, height=56.4) FancyBboxPatch((0, 0), width=87.875, height=44.8) FancyBboxPatch((0, 0), width=127.25, height=56.4) FancyBboxPatch((0, 0), width=131.625, height=56.4) FancyBboxPatch((0, 0), width=30, height=33.2) FancyBboxPatch((0, 0), width=30, height=33.2) FancyBboxPatch((0, 0), width=131.625, height=56.4) FancyBboxPatch((0, 0), width=30, height=33.2) FancyBboxPatch((0, 0), width=30, height=33.2) set_boxstyle() 12345678910111213%matplotlib inlinefig, ax = plt.subplots(figsize=(15, 10))ax = tree.plot_tree(dt, max_depth = 2, filled=True, feature_names = iris.feature_names, class_names = iris.target_names)for i in range(0, len(ax)): # set patch properties if i % 2 == 0: ax[i].get_bbox_patch().set_boxstyle(&quot;Rarrow&quot;, pad=0.3) else: ax[i].get_bbox_patch().set_boxstyle(&quot;Round&quot;, pad=0.3) Final ex.1234567import numpy as np colors = [&quot;indigo&quot;, &quot;violet&quot;, &quot;crimson&quot;]print(colors[np.argmax([[0., 0., 50.]])])print(colors[np.argmax([[50., 0., 0.]])])print(colors[np.argmax([[0., 50., 0.]])])print(colors[np.argmax([[50., 50., 50.]])]) crimson indigo violet indigo 12345678910111213141516171819202122232425from matplotlib.colors import to_rgb%matplotlib inlinefig, ax = plt.subplots(figsize=(15, 10))ax = tree.plot_tree(dt, max_depth = 3, filled=True, feature_names = iris.feature_names, class_names = iris.target_names)i = 0colors = [&quot;yellow&quot;, &quot;violet&quot;, &quot;lavenderblush&quot;]for artist, impurity, value in zip(ax, dt.tree_.impurity, dt.tree_.value): r, g, b = to_rgb(colors[np.argmax(value)]) # ì½”ë“œê°€ ê¸¸ì–´ì„œ ië¡œ ì¬ ì €ì¥ ip = impurity # print(ip + (1-ip)*r, ip + (1-ip)*g, ip + (1-ip)*b) if i % 2 == 0: # set_boxtyle ì ìš© ax[i].get_bbox_patch().set_boxstyle(&quot;round&quot;, pad=0.3) ax[i].get_bbox_patch().set_facecolor((ip + (1-ip)*r, ip + (1-ip)*g, ip + (1-ip)*b)) ax[i].get_bbox_patch().set_edgecolor(&#x27;black&#x27;) else: ax[i].get_bbox_patch().set_boxstyle(&quot;circle&quot;, pad=0.3) ax[i].get_bbox_patch().set_facecolor((ip + (1-ip)*r, ip + (1-ip)*g, ip + (1-ip)*b)) ax[i].get_bbox_patch().set_edgecolor(&#x27;black&#x27;) i = i+1 Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 5_3","slug":"Python/ML/ML_ch_5_3","date":"2022-03-30T07:48:30.000Z","updated":"2022-10-05T05:39:53.131Z","comments":true,"path":"2022/03/30/Python/ML/ML_ch_5_3/","link":"","permalink":"http://gonekng.github.io/2022/03/30/Python/ML/ML_ch_5_3/","excerpt":"","text":"Ensemble algorithm that performs best in dealing with structured data Bagging : A method of aggregating results by taking multiple bootstrap samples and training each model. (parallel learning) Random Forest Boosting : (sequential learning) GBM â€“&gt; XGBoost â€“&gt; LightGBM Random Forest Create decision trees randomly and make final predictions based on each treeâ€™s predictions. Classification : Average the probabilities for each class of each tree and uses the class with the highest probability as a prediction. Regression : Average the predictions of each tree. Bootstrap : method of sampling data by permitting duplication in a dataset 1234567891011import numpy as npimport pandas as pdwine = pd.read_csv(&#x27;https://bit.ly/wine_csv_data&#x27;)data = wine[[&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;]].to_numpy()target = wine[&#x27;class&#x27;].to_numpy()from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42) 12345from sklearn.model_selection import cross_validatefrom sklearn.ensemble import RandomForestClassifierrf = RandomForestClassifier(n_jobs=-1, random_state=42)scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)print(np.mean(scores[&#x27;train_score&#x27;]), np.mean(scores[&#x27;test_score&#x27;])) # overfitting 0.9973541965122431 0.8905151032797809 12rf.fit(train_input, train_target)print(rf.feature_importances_) [0.23167441 0.50039841 0.26792718] OOB(out of bag) Sample : remaining sample not included in bootstrap sample same effect as cross-validation using a verification set 123rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)rf.fit(train_input, train_target)print(rf.oob_score_) 0.8934000384837406 GBM(Gradient Boosting Machine) Correct errors in previous trees by using shallow trees. Adjust the speed (step width) through the learning rate parameter less likely to overfit but speed is slow 1234from sklearn.ensemble import GradientBoostingClassifiergb = GradientBoostingClassifier(random_state=42)scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)print(np.mean(scores[&#x27;train_score&#x27;]), np.mean(scores[&#x27;test_score&#x27;])) # good fitting 0.8881086892152563 0.8720430147331015 1234# n_estimators = 500 (default 100), learning rate = 0.2 (default 0.1)gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)print(np.mean(scores[&#x27;train_score&#x27;]), np.mean(scores[&#x27;test_score&#x27;])) # good fitting 0.9464595437171814 0.8780082549788999 Overall Flow of ML Data preprocessing, EDA, Visualization Design the entire flow as a basic model compare multiple models with default hyperparameter Cross-validation and Hyperparameter tuning Repeat the above process until finding the best result Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 5_2","slug":"Python/ML/ML_ch_5_2","date":"2022-03-30T06:40:40.000Z","updated":"2022-10-05T05:39:53.059Z","comments":true,"path":"2022/03/30/Python/ML/ML_ch_5_2/","link":"","permalink":"http://gonekng.github.io/2022/03/30/Python/ML/ML_ch_5_2/","excerpt":"","text":"Cross Validation: Repeated process of spliting validation set and evaluating model. Train set : Validation set : Test set &#x3D; 6 : 2 : 2 (generally) Test sets are not used in the model learning process. In Kagge competition, test sets are given separately. purpose : To make a good model A good model doesnâ€™t mean high-performance model. A good model means low-error and stable model. Because it takes a long time, it is useful when there is not much data. Prepare data1234import pandas as pdwine = pd.read_csv(&#x27;https://bit.ly/wine_csv_data&#x27;)data = wine[[&#x27;alcohol&#x27;,&#x27;sugar&#x27;,&#x27;pH&#x27;]].to_numpy()target = wine[[&#x27;class&#x27;]].to_numpy() 1234567from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42)sub_input, val_input, sub_target, val_target = train_test_split( train_input, train_target, test_size=0.2, random_state=42) 1sub_input.shape, val_input.shape, test_input.shape ((4157, 3), (1040, 3), (1300, 3)) Create model12345from sklearn.tree import DecisionTreeClassifierdt = DecisionTreeClassifier(random_state=42)dt.fit(sub_input, sub_target)print(dt.score(sub_input, sub_target))print(dt.score(val_input, val_target)) # overfitting 0.9971133028626413 0.864423076923077 Validate model1234from sklearn.model_selection import cross_validatescores = cross_validate(dt, train_input, train_target) # dictionary typefor item in scores.items(): print(item) (&#39;fit_time&#39;, array([0.01251197, 0.00755358, 0.0074594 , 0.00742102, 0.00734329])) (&#39;score_time&#39;, array([0.00133634, 0.00079608, 0.0007925 , 0.00083232, 0.00076413])) (&#39;test_score&#39;, array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])) 12import numpy as npprint(np.mean(scores[&#x27;test_score&#x27;])) 0.855300214703487 In cross-validation, a splitter must be specified to mix training sets. Regression model &gt; KFold Classification model &gt; StratifiedKFold 1234from sklearn.model_selection import StratifiedKFoldsplitter = StratifiedKFold(shuffle=True, random_state=42) # default : 5 foldscores = cross_validate(dt, train_input, train_target, cv=splitter)print(np.mean(scores[&#x27;test_score&#x27;])) 0.8539548012141852 123splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) # 10 foldscores = cross_validate(dt, train_input, train_target, cv=splitter)print(np.mean(scores[&#x27;test_score&#x27;])) 0.8574181117533719 Hyperparameter Tuning ex) max_depth&#x3D;3, accuracy&#x3D;0.84 Finding the best value by adjusting multiple parameters simultaneously. AutoML : technology that automatically performs hyperparameter tuning without intervention of person. Grid Search, Random Search Grid Search Perform hyperparameter tuning and cross-validation simultaneously Find the optimal hyperparameters based on all combinations of predetermined values. 12345678%%timefrom sklearn.model_selection import GridSearchCVparams = &#123; &#x27;min_impurity_decrease&#x27; : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]&#125;gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)gs.fit(train_input, train_target) CPU times: user 70.1 ms, sys: 6.06 ms, total: 76.1 ms Wall time: 183 ms 123dt = gs.best_estimator_print(dt)print(dt.score(train_input, train_target)) DecisionTreeClassifier(min_impurity_decrease=0.0001, random_state=42) 0.9615162593804117 12print(gs.cv_results_[&#x27;mean_test_score&#x27;])print(gs.best_params_) [0.86819297 0.86453617 0.86492226 0.86780891 0.86761605] &#123;&#39;min_impurity_decrease&#39;: 0.0001&#125; 123456789101112%%timefrom sklearn.model_selection import GridSearchCVparams = &#123; &#x27;min_impurity_decrease&#x27; : [0.0001, 0.0002, 0.0003, 0.0004, 0.0005], &#x27;max_depth&#x27; : [3, 4, 5, 6, 7]&#125;# Change the values in params and create a total of 5 models with each value.# n_jobs=-1 : to enable all cores in the systemgs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)gs.fit(train_input, train_target) CPU times: user 167 ms, sys: 4.85 ms, total: 172 ms Wall time: 585 ms 123dt = gs.best_estimator_print(dt)print(dt.score(train_input, train_target)) DecisionTreeClassifier(max_depth=7, min_impurity_decrease=0.0005, random_state=42) 0.8830094285164518 12print(gs.cv_results_[&#x27;mean_test_score&#x27;]) # 5*5=25print(gs.best_params_) [0.84125583 0.84125583 0.84125583 0.84125583 0.84125583 0.85337806 0.85337806 0.85337806 0.85337806 0.85318557 0.85780355 0.85799604 0.85857352 0.85857352 0.85838102 0.85645721 0.85799678 0.85876675 0.85972866 0.86088306 0.85607093 0.85761031 0.85799511 0.85991893 0.86280466] &#123;&#39;max_depth&#39;: 7, &#39;min_impurity_decrease&#39;: 0.0005&#125; The optimal value of â€˜min_impurity_decreaseâ€™ varies when the value of â€˜max_depthâ€™ changes. Random Search Find the optimal hyperparameters based on possible combinations within a predetermined range of values. Delivers probability distribution objects that can sample parameters. 1234567# randint : sampling int# uniform : sampling floatfrom scipy.stats import uniform, randintparams = &#123; &#x27;min_impurity_decrease&#x27; : uniform(0.0001, 0.001), &#x27;max_depth&#x27; : randint(20, 50)&#125; 123456%%timefrom sklearn.model_selection import RandomizedSearchCVgs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=-1, random_state=42)gs.fit(train_input, train_target) CPU times: user 629 ms, sys: 15.8 ms, total: 645 ms Wall time: 2.54 s 123dt = gs.best_estimator_print(dt)print(dt.score(train_input, train_target)) DecisionTreeClassifier(max_depth=29, min_impurity_decrease=0.000437615171403628, random_state=42) 0.8903213392341736 1print(gs.best_params_) &#123;&#39;max_depth&#39;: 29, &#39;min_impurity_decrease&#39;: 0.000437615171403628&#125; Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 5_1","slug":"Python/ML/ML_ch_5_1","date":"2022-03-30T06:10:20.000Z","updated":"2022-10-05T05:39:52.983Z","comments":true,"path":"2022/03/30/Python/ML/ML_ch_5_1/","link":"","permalink":"http://gonekng.github.io/2022/03/30/Python/ML/ML_ch_5_1/","excerpt":"","text":"Prepare Data Import wine data set class 0: red wine class 1: white wine 123import pandas as pdwine = pd.read_csv(&quot;https://bit.ly/wine_csv_data&quot;)print(wine.head()) alcohol sugar pH class 0 9.4 1.9 3.51 0.0 1 9.8 2.6 3.20 0.0 2 9.8 2.3 3.26 0.0 3 9.8 1.9 3.16 0.0 4 9.4 1.9 3.51 0.0 12# checking missing value and types of variablewine.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 6497 entries, 0 to 6496 Data columns (total 4 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 alcohol 6497 non-null float64 1 sugar 6497 non-null float64 2 pH 6497 non-null float64 3 class 6497 non-null float64 dtypes: float64(4) memory usage: 203.2 KB 1print(wine.describe()) # vary in scale of variables, in need of standardization alcohol sugar pH class count 6497.000000 6497.000000 6497.000000 6497.000000 mean 10.491801 5.443235 3.218501 0.753886 std 1.192712 4.757804 0.160787 0.430779 min 8.000000 0.600000 2.720000 0.000000 25% 9.500000 1.800000 3.110000 1.000000 50% 10.300000 3.000000 3.210000 1.000000 75% 11.300000 8.100000 3.320000 1.000000 max 14.900000 65.800000 4.010000 1.000000 Split data into training sets and test sets 12data = wine[[&#x27;alcohol&#x27;, &#x27;sugar&#x27;, &#x27;pH&#x27;]].to_numpy()target = wine[&#x27;class&#x27;].to_numpy() 12345from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( data, target, test_size=0.2, random_state=42)print(train_input.shape, test_input.shape) (5197, 3) (1300, 3) Standardize Data Decision tree does not require standardized preprocessing, but it is recommended to perform standardization basically. 12345from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) Logistic Regression Model12345from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()lr.fit(train_scaled, train_target)print(lr.score(train_scaled, train_target))print(lr.score(test_scaled, test_target)) 0.7808350971714451 0.7776923076923077 12print(lr.predict_proba(train_scaled[:5]))print(lr.predict(train_scaled[:5])) [[0.06189333 0.93810667] [0.21742616 0.78257384] [0.40703571 0.59296429] [0.45226659 0.54773341] [0.00530794 0.99469206]] [1. 1. 1. 1. 1.] 1print(lr.coef_, lr.intercept_) [[ 0.51270274 1.6733911 -0.68767781]] [1.81777902] Decision Tree Model: a non-parametric supervised learning method used for classification and regression to predict the value of a target variable by learning simple decision rules inferred from the data features Simple to understand and to interpret More likely to be overfitting the training set. New Algorithm Using Decision Tree Algorithms XGBoost, LightGBM, CatBoost, etc In particular, LightGBM is now widely used in practice. DecisionTreeClassifier12345from sklearn.tree import DecisionTreeClassifierdt = DecisionTreeClassifier(random_state=42)dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target))print(dt.score(test_scaled, test_target)) # appear to be overfitting 0.996921300750433 0.8592307692307692 12345678910import matplotlib.pyplot as pltfrom sklearn.tree import plot_treefig, ax = plt.subplots(figsize=(18,10))plot_tree(dt, filled=True, feature_names=[&#x27;alcohol&#x27;,&#x27;sugar&#x27;,&#x27;pH&#x27;])plt.show()# - conditions for testing : sugar# - impurity : gini# - samples : total number of samples# - value : number of samples by class Impurity(ë¶ˆìˆœë„) parameter criterion; default â€˜giniâ€™ gini &#x3D; 1 - (negative_prop^2 + positive_prop^2) best : 0 (pure node) worst : 0.5 (exactly half and half) entropy &#x3D; - negative_prop * log_2(negative_prop) - positive_prop * log_2(positive_prop) Information gain(ì •ë³´ ì´ë“) : impurity differences between parent node and child node Decision tree splits nodes to maximize information gain using impurity criteria. Pruning(ê°€ì§€ì¹˜ê¸°) In order to prevent overfitting the training set By specifying the maximum depth of a tree that can grow 1234dt = DecisionTreeClassifier(max_depth=3, random_state=42)dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target))print(dt.score(test_scaled, test_target)) # successful in reducing overfitting 0.8454877814123533 0.8415384615384616 123fig, ax = plt.subplots(figsize=(18,10))plot_tree(dt, filled=True, feature_names=[&#x27;alcohol&#x27;,&#x27;sugar&#x27;,&#x27;pH&#x27;])plt.show() 123456789# Tree Plot Image Downloadimport graphvizfrom sklearn import treedot_data = tree.export_graphviz( dt, out_file=None, feature_names = [&#x27;alcohol&#x27;,&#x27;sugar&#x27;,&#x27;pH&#x27;], filled=True)graph = graphviz.Source(dot_data, format=&quot;png&quot;) graph 1graph.render(&quot;decision_tree_graphivz&quot;) &#39;decision_tree_graphivz.png&#39; 12345678910111213141516# Customize color of nodesfrom matplotlib.colors import ListedColormap, to_rgbimport numpy as npplt.figure(figsize=(20, 15))artists = plot_tree(dt, filled = True, feature_names = [&#x27;alcohol&#x27;,&#x27;sugar&#x27;,&#x27;pH&#x27;])colors = [&#x27;blue&#x27;, &#x27;red&#x27;]for artist, impurity, value in zip(artists, dt.tree_.impurity, dt.tree_.value): r, g, b = to_rgb(colors[np.argmax(value)]) f = impurity * 2 artist.get_bbox_patch().set_facecolor((f + (1-f)*r, f + (1-f)*g, f + (1-f)*b)) artist.get_bbox_patch().set_edgecolor(&#x27;black&#x27;)plt.show() parameter min_impurity_decrease; default 0.0 Split nodes if this split induces a decrease of the impurity greater than or equal to this value. More likely to be asymmetric tree 12345678dt = DecisionTreeClassifier(min_impurity_decrease=0.0005, random_state=42)dt.fit(train_scaled, train_target)print(dt.score(train_scaled, train_target))print(dt.score(test_scaled, test_target))fig, ax = plt.subplots(figsize=(18, 10))plot_tree(dt, filled=True, feature_names=[&#x27;alcohol&#x27;,&#x27;sugar&#x27;,&#x27;pH&#x27;])plt.show() 0.8874350586877044 0.8615384615384616 Feature importance: an indicator of the degree to which each feature contributed to reducing impurities Multiply the information gain and the ratio of the total sample by each node, and add it up by feature. 1print(dt.feature_importances_) # Sugar is the most important feature. [0.12345626 0.86862934 0.0079144 ] Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 4_2","slug":"Python/ML/ML_ch_4_2","date":"2022-03-29T07:10:25.000Z","updated":"2022-10-05T05:39:52.900Z","comments":true,"path":"2022/03/29/Python/ML/ML_ch_4_2/","link":"","permalink":"http://gonekng.github.io/2022/03/29/Python/ML/ML_ch_4_2/","excerpt":"","text":"Gradient Descent(ê²½ì‚¬ í•˜ê°•ë²•): Algorithm for finding the minimum value of a loss function using a sample of a training set stochastic gradient descent(í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•; SGD) method of randomly selecting one sample from a training set minibatch gradient descent(ë¯¸ë‹ˆë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•) method of randomly selecting several samples from a training set batch gradient descent(ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•) method of selecting all the samples from a training set at once Sampling method is different from the existing model. (more detailed approach) It aims to correct errors by reducing the slope of the loss function SGDClassifier : Create a classification model using SGD. SGDRegressor : Create a regression model using SGD. Epoch : process of using the entire training set once Usage Deep learning algorithm (especially, image and text) Tree algorithm + Gradient Descent &#x3D; Boosting ex) LightGBM, Xgboost, Catboost Loss function(ì†ì‹¤ í•¨ìˆ˜) Cost function ë¹„ìš© í•¨ìˆ˜) Loss is the difference between the predicted value and the actual value of the model (equivalent to error) Loss function is a function that expresses loss of the model an indicator of how poorly a model processes data Loss function must be differentiable. Prepare Data12345# Importimport pandas as pdfish = pd.read_csv(&quot;https://bit.ly/fish_csv_data&quot;)fish_input = fish[[&#x27;Weight&#x27;, &#x27;Length&#x27;, &#x27;Diagonal&#x27;, &#x27;Height&#x27;, &#x27;Width&#x27;]].to_numpy()fish_target = fish[&#x27;Species&#x27;].to_numpy() 123456# Splitfrom sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state=42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((119, 5), (40, 5), (119,), (40,)) 1234567# Normalizefrom sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) â€» To prevent data leakage, make sure to convert the test set to the statistics learned from the training set.â€» Data leakage : containing the information you want to predict in the data used for model training SGD ClassifierFitting model set 2 parameter in SGD Classifier loss : specifying the type of loss function max_iter : specifying the number of epochs to be executed In the case of a multi-classification model, if loss is set as â€˜logâ€™, a binary classification model is created for each class. 123456from sklearn.linear_model import SGDClassifiersc = SGDClassifier(loss=&#x27;log&#x27;, max_iter=10, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.773109243697479 0.775 /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit. ConvergenceWarning, 1234# partial_fit() : continue training one epoch per callsc.partial_fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.8151260504201681 0.85 Finding appropriate epoch12345678910import numpy as npsc = SGDClassifier(loss=&#x27;log&#x27;, random_state=42)train_score = []test_score = []classes = np.unique(train_target)for _ in range(0, 300): # _ : temporal variable sc.partial_fit(train_scaled, train_target, classes=classes) train_score.append(sc.score(train_scaled, train_target)) test_score.append(sc.score(test_scaled, test_target)) 12345678import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.plot(train_score)ax.plot(test_score)ax.set_xlabel(&#x27;epoch&#x27;)ax.set_ylabel(&#x27;accuracy&#x27;)plt.show() In the early stages of epoch, the scores of training sets and test sets are low because they are underfitting. After epoch 100, the score difference between the training set and the test set gradually increases. Epoch 100 appears to be the most appropriate number of iterations. 123456# SGD classifier stops by itself, if performance does not improve during a certain epoch.# tol = None : to repeat unconditionally untill max_itersc = SGDClassifier(loss=&#x27;log&#x27;, max_iter=100, tol=None, random_state=42)sc.fit(train_scaled, train_target)print(sc.score(train_scaled, train_target))print(sc.score(test_scaled, test_target)) 0.957983193277311 0.925 Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 4_1","slug":"Python/ML/ML_ch_4_1","date":"2022-03-29T03:50:45.000Z","updated":"2022-10-05T05:39:52.815Z","comments":true,"path":"2022/03/29/Python/ML/ML_ch_4_1/","link":"","permalink":"http://gonekng.github.io/2022/03/29/Python/ML/ML_ch_4_1/","excerpt":"","text":"Prepare DataImport data set1234import pandas as pdfish = pd.read_csv(&#x27;https://bit.ly/fish_csv_data&#x27;)print(fish.head()) Species Weight Length Diagonal Height Width 0 Bream 242.0 25.4 30.0 11.5200 4.0200 1 Bream 290.0 26.3 31.2 12.4800 4.3056 2 Bream 340.0 26.5 31.1 12.3778 4.6961 3 Bream 363.0 29.0 33.5 12.7300 4.4555 4 Bream 430.0 29.0 34.0 12.4440 5.1340 1print(pd.unique(fish[&#x27;Species&#x27;])) [&#39;Bream&#39; &#39;Roach&#39; &#39;Whitefish&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Smelt&#39;] Convert to Numpy array123fish_input = fish[[&#x27;Weight&#x27;,&#x27;Length&#x27;,&#x27;Diagonal&#x27;,&#x27;Height&#x27;,&#x27;Width&#x27;]].to_numpy()print(fish_input.shape)print(fish_input[:3]) (159, 5) [[242. 25.4 30. 11.52 4.02 ] [290. 26.3 31.2 12.48 4.3056] [340. 26.5 31.1 12.3778 4.6961]] 12fish_target = fish[&#x27;Species&#x27;].to_numpy()print(fish_target.shape) (159,) Split and Standardize1234from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( fish_input, fish_target, random_state=42) 12345from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_input)train_scaled = ss.transform(train_input)test_scaled = ss.transform(test_input) 12print(train_input[:3])print(train_scaled[:3]) [[720. 35. 40.6 16.3618 6.09 ] [500. 45. 48. 6.96 4.896 ] [ 7.5 10.5 11.6 1.972 1.16 ]] [[ 0.91965782 0.60943175 0.81041221 1.85194896 1.00075672] [ 0.30041219 1.54653445 1.45316551 -0.46981663 0.27291745] [-1.0858536 -1.68646987 -1.70848587 -1.70159849 -2.0044758 ] [-0.79734143 -0.60880176 -0.67486907 -0.82480589 -0.27631471] [-0.71289885 -0.73062511 -0.70092664 -0.0802298 -0.7033869 ]] [[-0.88741352 -0.91804565 -1.03098914 -0.90464451 -0.80762518] [-1.06924656 -1.50842035 -1.54345461 -1.58849582 -1.93803151] [-0.54401367 0.35641402 0.30663259 -0.8135697 -0.65388895] [-0.34698097 -0.23396068 -0.22320459 -0.11905019 -0.12233464] [-0.68475132 -0.51509149 -0.58801052 -0.8998784 -0.50124996]] KNN ClassifierModel fitting1234567from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier(n_neighbors=3)kn.fit(train_scaled, train_target)print(kn.score(train_scaled, train_target))print(kn.score(test_scaled, test_target)) 0.8907563025210085 0.85 Multi-class Classfication1234import numpy as npproba = kn.predict_proba(test_scaled[:5])print(kn.classes_)print(np.round(proba, decimals=4)) [&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;] [[0. 0. 1. 0. 0. 0. 0. ] [0. 0. 0. 0. 0. 1. 0. ] [0. 0. 0. 1. 0. 0. 0. ] [0. 0. 0.6667 0. 0.3333 0. 0. ] [0. 0. 0.6667 0. 0.3333 0. 0. ]] 12distances, indexes = kn.kneighbors(test_scaled[3:4]) # Two-dimensional array must be inputprint(train_target[indexes]) [[&#39;Roach&#39; &#39;Perch&#39; &#39;Perch&#39;]] The probability calculated by the model is the ratio of the nearest neighbor. In this model(k&#x3D;3), the probability values are 0, 1&#x2F;3, 2&#x2F;3, and 1. If k is set as 5, the probability values may be 0, 0.2, 0.4, 0.6, 0.8 and 1. 123456kn = KNeighborsClassifier(n_neighbors=5)kn.fit(train_scaled, train_target)proba = kn.predict_proba(test_scaled[:5])print(kn.classes_)print(np.round(proba, decimals=4))print(kn.predict(test_scaled[:5])) [&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;] [[0. 0. 0.6 0. 0.4 0. 0. ] [0. 0. 0. 0. 0. 1. 0. ] [0. 0. 0.2 0.8 0. 0. 0. ] [0. 0. 0.8 0. 0.2 0. 0. ] [0. 0. 0.8 0. 0.2 0. 0. ]] [&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Perch&#39; &#39;Perch&#39;] Logistic Regression: Estimating a model with a regression equation for categorical dependent variables. Despite its name, a classification model rather than regression model Highly important model used as basic statistics (especially medical statistics) the basis of the machine learning classification model. early model of deep learning To overcome the linearity assumption problem of general regression equation Logit transformation : the log of the odds ratio Using the logit of Y as the dependent variable of the regression Sigmoid function also called a logistic function Convert the value z calculated by linear regression to a probability value between 0 and 1 z &lt; 0: the function approaches 0 z &gt; 0: the function approaches 1 z &#x3D; 0: the function value is 0.5 1234567891011import numpy as npimport matplotlib.pyplot as pltz = np.arange(-5, 5, 0.1)phi = 1 / (1 + np.exp(-z)) # sigmoid functionfig, ax = plt.subplots()ax.plot(z, phi)ax.set_xlabel(&#x27;z&#x27;, fontsize=12)ax.set_ylabel(&#x27;phi&#x27;, fontsize=12)ax.set_title(&quot;Sigmoid Function for Logistic Regression&quot;, fontsize=15)plt.show() Binary classification12345# Boolean Indexing: using a boolean vector to filter the data. # Choose only Bream and Smelt from the training set.bream_smelt_indexes = (train_target == &#x27;Bream&#x27;) | (train_target == &#x27;Smelt&#x27;)train_bream_smelt = train_scaled[bream_smelt_indexes]target_bream_smelt = train_target[bream_smelt_indexes] 12345678from sklearn.linear_model import LogisticRegressionlr = LogisticRegression()lr.fit(train_bream_smelt, target_bream_smelt)print(lr.classes_) # 0: Bream / 1: Smeltproba = lr.predict_proba(train_bream_smelt[:5])print(np.round(proba, decimals=3)) # 5 rows, 2 columnsprint(lr.predict(train_bream_smelt[:5])) [&#39;Bream&#39; &#39;Smelt&#39;] [[0.998 0.002] [0.027 0.973] [0.995 0.005] [0.986 0.014] [0.998 0.002]] [&#39;Bream&#39; &#39;Smelt&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;] 1print(lr.coef_, lr.intercept_) [[-0.4037798 -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132] z &#x3D; - 0.404 * Weight - 0. 576 * Length - 0.663 * Diagonal - 1.013 * Height - 0.732 * Width - 2.162 12decisions = lr.decision_function(train_bream_smelt[:5])print(decisions) # original z-value of positive class(Smelt) [-6.02927744 3.57123907 -5.26568906 -4.24321775 -6.0607117 ] 12from scipy.special import expitprint(expit(decisions)) # probability value through sigmoid function [0.00240145 0.97264817 0.00513928 0.01415798 0.00232731] Multi-class classification basically use iterative algorithms (max_iter, default 100) in this model, set max_iter as 1000 (for sufficient training) L2 Regularization based on the square value of the coefficient such as ridge regression hyperparameter; C ( default 1) the smaller the value, the greater the regulation. in this model, set C as 20 (in order to ease regulations a little) 1234lr = LogisticRegression(C=20, max_iter=1000)lr.fit(train_scaled, train_target)print(lr.score(train_scaled, train_target))print(lr.score(test_scaled, test_target)) 0.9327731092436975 0.925 1234print(lr.classes_)proba = lr.predict_proba(test_scaled[:5])print(np.round(proba, decimals=3)) # 5 rows, 7 columnsprint(lr.predict(test_scaled[:5])) [&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;] [[0. 0.014 0.841 0. 0.136 0.007 0.003] [0. 0.003 0.044 0. 0.007 0.946 0. ] [0. 0. 0.034 0.935 0.015 0.016 0. ] [0.011 0.034 0.306 0.007 0.567 0. 0.076] [0. 0. 0.904 0.002 0.089 0.002 0.001]] [&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Perch&#39;] 1print(lr.coef_.shape, lr.intercept_.shape) (7, 5) (7,) [[-1.49002087 -1.02912886 2.59345551 7.70357682 -1.2007011 ] [ 0.19618235 -2.01068181 -3.77976834 6.50491489 -1.99482722] [ 3.56279745 6.34357182 -8.48971143 -5.75757348 3.79307308] [-0.10458098 3.60319431 3.93067812 -3.61736674 -1.75069691] [-1.40061442 -6.07503434 5.25969314 -0.87220069 1.86043659] [-1.38526214 1.49214574 1.39226167 -5.67734118 -4.40097523] [ 0.62149861 -2.32406685 -0.90660867 1.71599038 3.6936908 ]] [-0.09205179 -0.26290885 3.25101327 -0.14742956 2.65498283 -6.78782948 1.38422358] The z value is calculated one by one for each class and classified into the class that outputs the highest value. Softmax function also called a normalized exponential function (because of using exponential functions) The outputs of several linear equations are compressed from 0 to 1, and the total sum is 1. e_sum &#x3D; e^z1 + e^z2 + â€¦ + e^z7 s1 &#x3D; e^z1&#x2F;e_sum, s2 &#x3D; e^z2&#x2F;e_sum, â€¦ , s7 &#x3D; e^z7&#x2F;e_sum 12decision = lr.decision_function(test_scaled[:5])print(np.round(decision, decimals=3)) # original z value [[ -6.498 1.032 5.164 -2.729 3.339 0.327 -0.634] [-10.859 1.927 4.771 -2.398 2.978 7.841 -4.26 ] [ -4.335 -6.233 3.174 6.487 2.358 2.421 -3.872] [ -0.683 0.453 2.647 -1.187 3.265 -5.753 1.259] [ -6.397 -1.993 5.816 -0.11 3.503 -0.112 -0.707]] 123from scipy.special import softmaxproba = softmax(decision, axis=1)print(np.round(proba, decimals=3)) # probability value through softmax function [[0. 0.014 0.841 0. 0.136 0.007 0.003] [0. 0.003 0.044 0. 0.007 0.946 0. ] [0. 0. 0.034 0.935 0.015 0.016 0. ] [0.011 0.034 0.306 0.007 0.567 0. 0.076] [0. 0. 0.904 0.002 0.089 0.002 0.001]] Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 3_3","slug":"Python/ML/ML_ch_3_3","date":"2022-03-28T15:34:50.000Z","updated":"2022-10-05T05:39:52.733Z","comments":true,"path":"2022/03/29/Python/ML/ML_ch_3_3/","link":"","permalink":"http://gonekng.github.io/2022/03/29/Python/ML/ML_ch_3_3/","excerpt":"","text":"Prepare Data123import pandas as pddf = pd.read_csv(&#x27;https://bit.ly/perch_csv_data&#x27;)perch_full = df.to_numpy() # Convert Pandas DataFrame to Numpy Array 12345678import numpy as npperch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0]) 1234from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( perch_full, perch_weight, random_state=42) Transform Dataâ€» Scikit-Learn Class Estimator(ì¶”ì •ê¸°; model class) : Fitting and predicting KNeighborsClassifier, LinearRegression, etc. common method : fit(), score(), predict() Transformer(ë³€í™˜ê¸°) and Pre-processors : transforming or imputing data PolynomialFeatures, StandardScaler, etc common method : fit(), transform() â€» Feature engineering(íŠ¹ì„± ê³µí•™) extracting new features using existing features existing features, square features of each, and features multiplied by each other. Import transformer1from sklearn.preprocessing import PolynomialFeatures Transform sample data case 1: Including a bias 123poly = PolynomialFeatures()poly.fit([[2,3]])print(poly.transform([[2,3]])) [[1. 2. 3. 4. 6. 9.]] &gt; existing features : 2, 3 &gt; new features : 1(for intercept), 4(2^2), 6(2*3), 9(3^2) case 2: Not including a bias (recommended) 123poly = PolynomialFeatures(include_bias=False)poly.fit([[2,3]])print(poly.transform([[2,3]])) [[2. 3. 4. 6. 9.]] &gt; existing features : 2, 3 &gt; new features : 4(2^2), 6(2*3), 9(3^2) Transform perch data1234567poly = PolynomialFeatures(include_bias=False)poly.fit(train_input)train_poly = poly.transform(train_input)print(train_input.shape) # have 3 featuresprint(train_poly.shape) # have 9 featuresprint(poly.get_feature_names_out()) (42, 3) (42, 9) [&#39;x0&#39; &#39;x1&#39; &#39;x2&#39; &#39;x0^2&#39; &#39;x0 x1&#39; &#39;x0 x2&#39; &#39;x1^2&#39; &#39;x1 x2&#39; &#39;x2^2&#39;] 123test_poly = poly.transform(test_input)print(test_input.shape) # have 3 featuresprint(test_poly.shape) # have 9 features (14, 3) (14, 9) Mutiple Regression same process as training a linear regression model linear regression using multiple features degree 212345from sklearn.linear_model import LinearRegressionlr = LinearRegression()lr.fit(train_poly, train_target)print(lr.score(train_poly, train_target))print(lr.score(test_poly, test_target)) 0.9903183436982124 0.9714559911594134 Multiple regression solves the linear modelâ€™s underfitting problem. The score for the training set is very high. degree 5123456poly = PolynomialFeatures(degree=5, include_bias=False)poly.fit(train_input)train_poly = poly.transform(train_input)test_poly = poly.transform(test_input)print(train_poly.shape)print(test_poly.shape) (42, 55) (14, 55) 123lr.fit(train_poly, train_target)print(lr.score(train_poly, train_target))print(lr.score(test_poly, test_target)) 0.9999999999991097 -144.40579242684848 The score for the training set is almost perfect. But the score for the testing set is extremely negative. The model appears to be too overfitting to the training set. Regularization(ê·œì œ) preventing the model from overfitting the training set linear regression model : reducing the size of the coefficient multiplied by the feature. hyperparameter: alpha parameter which has to be set in advance increase&#x2F;decrease in regulatory intensity adjusted to increase the performance of the model Conceptual understanding is important, but it doesnâ€™t mean much in practice. No guarantee of performance compared to working hours. More than 100 libraries in scikit-learn, and the types and numbers of hyperparameters vary. Better to use the existing hyperparameters, for unfamiliar models. Normalize feature scales using StandardScaler class in scikit-learn 1234567from sklearn.preprocessing import StandardScalerss = StandardScaler()ss.fit(train_poly)train_scaled = ss.transform(train_poly)test_scaled = ss.transform(test_poly)print(train_poly.shape)print(test_poly.shape) (42, 55) (14, 55) Ridge regression based on the square value of the coefficient 12345from sklearn.linear_model import Ridgeridge = Ridge()ridge.fit(train_scaled, train_target)print(ridge.score(train_scaled, train_target))print(ridge.score(test_scaled, test_target)) 0.9896101671037343 0.9790693977615397 Many features are used, but theyâ€™re not overfitting the training set and perform well on the test set. 123import matplotlib.pyplot as plttrain_score = []test_score = [] 123456alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]for alpha in alpha_list: ridge = Ridge(alpha=alpha) ridge.fit(train_scaled, train_target) train_score.append(ridge.score(train_scaled, train_target)) test_score.append(ridge.score(test_scaled, test_target)) 123456fig, ax = plt.subplots()ax.plot(np.log10(alpha_list), train_score)ax.plot(np.log10(alpha_list), test_score)ax.set_xlabel(&#x27;log10(alpha)&#x27;)ax.set_ylabel(&#x27;R^2&#x27;)plt.show() left side : overfitting right side : underfitting appropriate alpha : 0.1 1234ridge = Ridge(alpha=0.1)ridge.fit(train_scaled, train_target)print(ridge.score(train_scaled, train_target))print(ridge.score(test_scaled, test_target)) 0.9903815817570366 0.9827976465386926 Lasso regression based on the absolute value of the coefficient The coefficient can be completely zero. 12345from sklearn.linear_model import Lassolasso = Lasso()lasso.fit(train_scaled, train_target)print(lasso.score(train_scaled, train_target))print(lasso.score(test_scaled, test_target)) 0.989789897208096 0.9800593698421883 Many features are used, but theyâ€™re not overfitting the training set and perform well on the test set. 123456789train_score = []test_score = []alpha_list = [0.001, 0.01, 0.1, 1, 10, 100]for alpha in alpha_list: lasso = Lasso(alpha=alpha, max_iter=10000) lasso.fit(train_scaled, train_target) train_score.append(lasso.score(train_scaled, train_target)) test_score.append(lasso.score(test_scaled, test_target)) /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+04, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive /usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.297e+04, tolerance: 5.183e+02 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive 123456fig, ax = plt.subplots()ax.plot(np.log10(alpha_list), train_score)ax.plot(np.log10(alpha_list), test_score)ax.set_xlabel(&#x27;log10(alpha)&#x27;)ax.set_ylabel(&#x27;R^2&#x27;)plt.show() left side : overfitting right side : underfitting appropriate alpha : 10 1234lasso = Lasso(alpha=10)lasso.fit(train_scaled, train_target)print(lasso.score(train_scaled, train_target))print(lasso.score(test_scaled, test_target)) 0.9888067471131867 0.9824470598706695 1print(np.sum(lasso.coef_==0)) 40 40 coefficients became zero Of the 55 features, only 15 were finally used. Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 3_2","slug":"Python/ML/ML_ch_3_2","date":"2022-03-28T08:34:00.000Z","updated":"2022-10-05T05:39:52.607Z","comments":true,"path":"2022/03/28/Python/ML/ML_ch_3_2/","link":"","permalink":"http://gonekng.github.io/2022/03/28/Python/ML/ML_ch_3_2/","excerpt":"","text":"Data Set12345678910111213141516171819import numpy as npperch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] ) 12345from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state=42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((42,), (14,), (42,), (14,)) 1234train_input = train_input.reshape(-1,1)test_input = test_input.reshape(-1,1)print(train_input.shape, test_input.shape) (42, 1) (14, 1) KNN Regression12345from sklearn.neighbors import KNeighborsRegressorknr = KNeighborsRegressor(n_neighbors=3)knr.fit(train_input, train_target)knr.score(test_input, test_target) 0.9746459963987609 Predict a data 1 the weight of a 50-centimeter-long perch 1print(knr.predict([[50]])) [1033.33333333] 123456789import matplotlib.pyplot as pltdistances, indexes = knr.kneighbors([[50]])fig, ax = plt.subplots()ax.scatter(train_input, train_target)ax.scatter(train_input[indexes], train_target[indexes], marker=&quot;D&quot;) # 3 neighborsax.scatter(50, knr.predict([[50]]), marker=&#x27;^&#x27;) # new dataplt.show() Predict a data 2 the weight of a 100-centimeter-long perch 1print(knr.predict([[100]])) [1033.33333333] 1234567distances, indexes = knr.kneighbors([[100]])fig, ax = plt.subplots()ax.scatter(train_input, train_target)ax.scatter(train_input[indexes], train_target[indexes], marker=&quot;D&quot;) # 3 neighborsax.scatter(100, knr.predict([[100]]), marker=&#x27;^&#x27;) # new dataplt.show() Beyond the scope of the new training set, incorrect values can be predicted. No matter how big the length is, the weight doesnâ€™t increase anymore. â€» Machine learning models must be trained periodically. MLOps (Machine Learning &amp; Opearations) the essential skill for data scientist, ML engineer. Linear Regression in statistics: The process of finding causal relationships is more important. 4 assumptions (linearity, normality, independence, equal variance) in ML: Predicting results is more important. R-squared, MAE, RMSE, etc Predict a data123456from sklearn.linear_model import LinearRegressionlr = LinearRegression()lr.fit(train_input, train_target)print(lr.predict([[50]])) [1241.83860323] 12345fig, ax = plt.subplots()ax.scatter(train_input, train_target)ax.scatter(train_input[indexes], train_target[indexes], marker=&quot;D&quot;) # 3 neighborsax.scatter(50, lr.predict([[50]]), marker=&#x27;^&#x27;) # new dataplt.show() Regression equation coef_ : regression coefficient(weight) intercept_ : regression intercept $y &#x3D; a + bx$ coefficient &amp; intercept : model parameter Linear Regression is a model-based learning. KNN Regression is a case-based learning. 1print(lr.coef_, lr.intercept_) [39.01714496] -709.0186449535477 123456789101112fig, ax = plt.subplots()# scatter plot of training setax.scatter(train_input, train_target)# linear equation from 0 to 50ax.plot([0,50], [0*lr.coef_+lr.intercept_, 50*lr.coef_+lr.intercept_])ax.scatter(50, lr.predict([[50]]), marker=&quot;^&quot;)ax.set_label(&quot;length&quot;)ax.set_label(&quot;weight&quot;)plt.show() 12print(lr.score(train_input, train_target))print(lr.score(test_input, test_target)) # Underfitting 0.939846333997604 0.8247503123313558 The model is so simple that it is underfit overall. It seems that polynomial regression is needed. Polynomial Regression coef_ : regression coefficients(weights) intercept_ : regression intercept $y &#x3D; a + b_1x_1 + b_2x_2 + â€¦ + b_nx_n$ Predict a data1234# Broadcasting in Numpytrain_poly = np.column_stack((train_input ** 2, train_input))test_poly = np.column_stack((test_input ** 2, test_input))print(train_poly.shape, test_poly.shape) (42, 2) (14, 2) â€» Broadcasting in Numpy tutorial : https://numpy.org/doc/stable/user/basics.broadcasting.html 123lr2 = LinearRegression()lr2.fit(train_poly, train_target)print(lr2.predict([[50**2, 50]])) [1573.98423528] Regression equation1print(lr2.coef_, lr2.intercept_) [ 1.01433211 -21.55792498] 116.0502107827827 123456789point = np.arange(15,50)fig, ax = plt.subplots()ax.scatter(train_input, train_target)ax.plot(point, lr2.coef_[0]*point**2 + lr2.coef_[1]*point + lr2.intercept_)ax.scatter(50, lr2.predict([[50**2, 50]]), marker=&quot;^&quot;)ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() 12print(lr2.score(train_poly, train_target))print(lr2.score(test_poly, test_target)) # Underfitting 0.9706807451768623 0.9775935108325122 The model has improved a lot, but it is still underfit. It seems that a more complex model is needed. Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 3_1","slug":"Python/ML/ML_ch_3_1","date":"2022-03-28T08:33:50.000Z","updated":"2022-10-05T05:39:52.462Z","comments":true,"path":"2022/03/28/Python/ML/ML_ch_3_1/","link":"","permalink":"http://gonekng.github.io/2022/03/28/Python/ML/ML_ch_3_1/","excerpt":"","text":"Prepare DataData Set12345678910111213141516171819import numpy as npperch_length = np.array( [8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0, 21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7, 23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5, 27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0, 39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5, 44.0] )perch_weight = np.array( [5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0, 115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0, 150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0, 218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0, 556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0, 850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0, 1000.0] ) Visualize Data12345678import matplotlib.pyplot as plt# object orientationfig, ax = plt.subplots()ax.scatter(perch_length, perch_weight)ax.set_label(&quot;length&quot;)ax.set_label(&quot;weight&quot;)plt.show() KNN Regression low importance Split Data12345from sklearn.model_selection import train_test_splittrain_input, test_input, train_target, test_target = train_test_split( perch_length, perch_weight, random_state=42)train_input.shape, test_input.shape, train_target.shape, test_target.shape ((42,), (14,), (42,), (14,)) 12345# change data set to two-dimensional arraytrain_input = train_input.reshape(-1,1)test_input = test_input.reshape(-1,1)print(train_input.shape, test_input.shape) (42, 1) (14, 1) Model fitting12345from sklearn.neighbors import KNeighborsRegressorknr = KNeighborsRegressor()knr.fit(train_input, train_target)knr.score(test_input, test_target) # Coefficient of Determination (R-squared) 0.992809406101064 MAE Returns the average of absolute value errors between targets and predictions. 12from sklearn.metrics import mean_absolute_errortest_prediction = knr.predict(test_input) 12mae = mean_absolute_error(test_target, test_prediction)print(mae) # On average, about 19.2 grams different from the target. 19.157142857142862 Overfitting vs. Underfitting Overfitting: Good prediction from training data and poor prediction from testing data difficulty in finding and solving Underfitting: Poor prediction from training data and good prediction from testing data Or, poor prediction on both sides The amount of data is small or the model is too simple. 12print(knr.score(train_input, train_target))print(knr.score(test_input, test_target)) 0.9698823289099254 0.992809406101064 123456789# Set the number of neighbors to 3.knr.n_neighbors = 3knr.fit(train_input, train_target)print(knr.score(train_input, train_target))print(knr.score(test_input, test_target))test_prediction = knr.predict(test_input)mae = mean_absolute_error(test_target, test_prediction)print(mae) # On average, about 35.4 grams different from the target. 0.9804899950518966 0.9746459963987609 35.42380952380951 Conclusion k&#x3D;5 : R^2&#x3D; 0.99, MAE&#x3D;19.2 k&#x3D;3 : R^2&#x3D; 0.97, MAE&#x3D;35.4 Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 2_2","slug":"Python/ML/ML_ch_2_2","date":"2022-03-28T08:32:34.000Z","updated":"2022-10-05T05:39:52.304Z","comments":true,"path":"2022/03/28/Python/ML/ML_ch_2_2/","link":"","permalink":"http://gonekng.github.io/2022/03/28/Python/ML/ML_ch_2_2/","excerpt":"","text":"Prepare data with Numpy12345678fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 123import numpy as npfish_data = np.column_stack((fish_length, fish_weight))print(fish_data[:5]) [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ]] 12fish_target = np.concatenate((np.ones(35), np.zeros(14)))print(fish_target) [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] Split data with Scikit-learn1234from sklearn.model_selection import train_test_split# stratify: spliting data according to class proportionstrain_input, test_input, train_target, test_target = train_test_split(fish_data, fish_target, stratify=fish_target, random_state=42) 123print(train_input.shape, test_input.shape)print(train_target.shape, test_target.shape)print(test_target) (36, 2) (13, 2) (36,) (13,) [0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.] KNN 1KNN fitting1234from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier()kn.fit(train_input, train_target)kn.score(test_input, test_target) 1.0 Predicting new data1print(kn.predict([[25,150]])) # the actual data is a bream, but predicted to be smelt. [0.] 123456789import matplotlib.pyplot as plt# Scatter plot with new datafig, ax = plt.subplots()ax.scatter(train_input[:,0], train_input[:,1])ax.scatter(25, 150, marker=&quot;^&quot;)ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() 12345678910distances, indexes = kn.kneighbors([[25,150]]) # the nearest neighbors (default: 5)# Scatter plot with 5 nearest neighborsfig, ax = plt.subplots()ax.scatter(train_input[:,0], train_input[:,1])ax.scatter(25, 150, marker=&quot;^&quot;)ax.scatter(train_input[indexes,0], train_input[indexes,1], marker=&#x27;D&#x27;) # rhombus markerax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() 123456789# Scatter plot on the same scalefig, ax = plt.subplots()ax.scatter(train_input[:,0], train_input[:,1])ax.scatter(25, 150, marker=&quot;^&quot;)ax.scatter(train_input[indexes,0], train_input[indexes,1], marker=&#x27;D&#x27;) # rhombus markerax.set_xlim((0,1000)) # change the x scaleax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() KNN 2Data Preprocessing1234# standard scoremean = np.mean(train_input, axis=0) # axis=0 : for each featurestd = np.std(train_input, axis=0)train_scaled = (train_input - mean) / std # broadcasting in numpy 12345678# Scatter plot with standard scorenew = ([25, 150] - mean ) / stdfig, ax = plt.subplots()ax.scatter(train_scaled[:,0], train_scaled[:,1])ax.scatter(new[0], new[1], marker=&quot;^&quot;)ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() KNN fitting123test_scaled = (test_input - mean) / stdkn.fit(train_scaled, train_target)kn.score(test_scaled, test_target) # 1.0 Predicting new data1print(kn.predict([new])) # the actual data is a bream, and predicted to be bream. [1.] 12345678910distances, indexes = kn.kneighbors([new])# Scatter plot with 5 nearest neighborsfig, ax = plt.subplots()ax.scatter(train_scaled[:,0], train_scaled[:,1])ax.scatter(new[0], new[1], marker=&quot;^&quot;)ax.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker=&#x27;D&#x27;) # rhombus markerax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 2_1","slug":"Python/ML/ML_ch_2_1","date":"2022-03-28T08:31:35.000Z","updated":"2022-10-05T05:39:52.167Z","comments":true,"path":"2022/03/28/Python/ML/ML_ch_2_1/","link":"","permalink":"http://gonekng.github.io/2022/03/28/Python/ML/ML_ch_2_1/","excerpt":"","text":"ML AlgorithmSupervised Learning(ì§€ë„ í•™ìŠµ) Input(ì…ë ¥; independent variable) &amp; Target(íƒ€ê¹ƒ; dependent variable) Question with a correct answer Type 1: Classification(ë¶„ë¥˜) Type 2: Regression(ì˜ˆì¸¡) Feature(íŠ¹ì„±) &#x3D; independent variable(column) Unspervised Learning(ë¹„ì§€ë„ í•™ìŠµ) only Input, not Target Question without an answer algorithm automatically categorizes Data set12345678fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9] 12fish_data = [[l,w] for l, w in zip(fish_length, fish_weight)]fish_target = [1]*35 + [0]*14 # 1: bream, 0: smelt KNN 1Create KNN12from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier() Data Split train set &amp; test set 1234train_input = fish_data[:35]train_target = fish_target[:35]test_input = fish_data[35:]test_target = fish_target[35:] Model fitting12kn = kn.fit(train_input, train_target)kn.score(test_input, test_target) # Sampling bias 0.0 KNN 2Numpy array123456import numpy as npinput_arr = np.array(fish_data)target_arr = np.array(fish_target)input_arr.shape, target_arr.shape ((49, 2), (49,)) Data Shuffle and Split12345np.random.seed(42)index = np.arange(49)print(index)np.random.shuffle(index)print(index) [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48] [13 45 47 44 17 27 26 25 31 19 12 4 34 8 3 6 40 41 46 15 9 16 24 33 30 0 43 32 5 29 11 36 1 21 2 37 35 23 39 10 22 18 48 20 7 42 14 28 38] 1234train_input = input_arr[index[:35]]train_target = target_arr[index[:35]]test_input = input_arr[index[35:]]test_target = target_arr[index[35:]] Scatter Plot12345678import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.scatter(train_input[:,0],train_input[:,1])ax.scatter(test_input[:,0],test_input[:,1])ax.set_xlabel(&#x27;length&#x27;)ax.set_ylabel(&#x27;weight&#x27;)plt.show() Model fitting12kn = kn.fit(train_input, train_target)kn.score(test_input, test_target) 1.0 1print(kn.predict(test_input) == test_target) [ True True True True True True True True True True True True True True] Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"ML Practice 1_3","slug":"Python/ML/ML_ch_1_3","date":"2022-03-26T06:38:35.000Z","updated":"2022-10-05T05:39:52.024Z","comments":true,"path":"2022/03/26/Python/ML/ML_ch_1_3/","link":"","permalink":"http://gonekng.github.io/2022/03/26/Python/ML/ML_ch_1_3/","excerpt":"","text":"Market and Machine LearningClassify Bream and SmeltBream Data123456bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] 123456import matplotlib.pyplot as pltplt.scatter(bream_length, bream_weight)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() Smelt Data12345678smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]plt.scatter(bream_length, bream_weight)plt.scatter(smelt_length, smelt_weight)plt.xlabel(&#x27;length&#x27;)plt.ylabel(&#x27;weight&#x27;)plt.show() 1st ML Program12345length = bream_length + smelt_lengthweight = bream_weight + smelt_weightfish_data = [[l,w] for l, w in zip(length, weight)]print(fish_data) [[25.4, 242.0], [26.3, 290.0], [26.5, 340.0], [29.0, 363.0], [29.0, 430.0], [29.7, 450.0], [29.7, 500.0], [30.0, 390.0], [30.0, 450.0], [30.7, 500.0], [31.0, 475.0], [31.0, 500.0], [31.5, 500.0], [32.0, 340.0], [32.0, 600.0], [32.0, 600.0], [33.0, 700.0], [33.0, 700.0], [33.5, 610.0], [33.5, 650.0], [34.0, 575.0], [34.0, 685.0], [34.5, 620.0], [35.0, 680.0], [35.0, 700.0], [35.0, 725.0], [35.0, 720.0], [36.0, 714.0], [36.0, 850.0], [37.0, 1000.0], [38.5, 920.0], [38.5, 955.0], [39.5, 925.0], [41.0, 975.0], [41.0, 950.0], [9.8, 6.7], [10.5, 7.5], [10.6, 7.0], [11.0, 9.7], [11.2, 9.8], [11.3, 8.7], [11.8, 10.0], [11.8, 9.9], [12.0, 9.8], [12.2, 12.2], [12.4, 13.4], [13.0, 12.2], [14.3, 19.7], [15.0, 19.9]] 12fish_target = [1]*35 + [0]*14print(fish_target) [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] K-Nearest Neighbor12345from sklearn.neighbors import KNeighborsClassifierkn = KNeighborsClassifier()kn.fit(fish_data, fish_target)kn.score(fish_data, fish_target) 1.0 1kn.predict([[30,600]]) array([1]) 12print(kn._fit_X)print(kn._y) [[ 25.4 242. ] [ 26.3 290. ] [ 26.5 340. ] [ 29. 363. ] [ 29. 430. ] [ 29.7 450. ] [ 29.7 500. ] [ 30. 390. ] [ 30. 450. ] [ 30.7 500. ] [ 31. 475. ] [ 31. 500. ] [ 31.5 500. ] [ 32. 340. ] [ 32. 600. ] [ 32. 600. ] [ 33. 700. ] [ 33. 700. ] [ 33.5 610. ] [ 33.5 650. ] [ 34. 575. ] [ 34. 685. ] [ 34.5 620. ] [ 35. 680. ] [ 35. 700. ] [ 35. 725. ] [ 35. 720. ] [ 36. 714. ] [ 36. 850. ] [ 37. 1000. ] [ 38.5 920. ] [ 38.5 955. ] [ 39.5 925. ] [ 41. 975. ] [ 41. 950. ] [ 9.8 6.7] [ 10.5 7.5] [ 10.6 7. ] [ 11. 9.7] [ 11.2 9.8] [ 11.3 8.7] [ 11.8 10. ] [ 11.8 9.9] [ 12. 9.8] [ 12.2 12.2] [ 12.4 13.4] [ 13. 12.2] [ 14.3 19.7] [ 15. 19.9]] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 123kn49 = KNeighborsClassifier(n_neighbors=49)kn49.fit(fish_data, fish_target)kn49.score(fish_data, fish_target) 0.7142857142857143 123456for n in range(5, 50): kn.n_neighbors = n score = kn.score(fish_data, fish_target) if score &lt; 1: print(n, score) break 18 0.9795918367346939 Ref.) í˜¼ì ê³µë¶€í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹+ë”¥ëŸ¬ë‹ (ë°•í•´ì„ , í•œë¹›ë¯¸ë””ì–´)","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"}],"author":"Jiwon Kang"},{"title":"Visualization tutorial","slug":"Python/Tutorial/visual_tutorial_01","date":"2022-03-24T02:58:50.000Z","updated":"2022-10-05T05:39:54.854Z","comments":true,"path":"2022/03/24/Python/Tutorial/visual_tutorial_01/","link":"","permalink":"http://gonekng.github.io/2022/03/24/Python/Tutorial/visual_tutorial_01/","excerpt":"","text":"ë°ì´í„° ì‹œê°í™”ì˜ ê¸°ë³¸ ì¡°ê±´ ëª©ì ì— ë§ëŠ” ê·¸ë˜í”„ ì„ ì • ì„ í˜• ê·¸ë˜í”„, ë§‰ëŒ€ ê·¸ë˜í”„, ì‚°ì ë„, ë°•ìŠ¤í”Œë¡¯ ë“±ë“± í™˜ê²½ì— ë§ëŠ” ë„êµ¬ ì„ íƒ ì½”ë“œ ê¸°ë°˜ : R, Python í”„ë¡œê·¸ë¨ ê¸°ë°˜ : Excel, PowerBI, Tableau ë“±ë“± ë¬¸ë§¥(ë„ë©”ì¸)ì— ë§ëŠ” ìƒ‰ê³¼ ë„í˜• ì‚¬ìš© íŒŒì´ì¬ ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬Matplotlib ì •í˜• ë°ì´í„° &#x2F; ì´ë¯¸ì§€ ë°ì´í„° Pyplot API : Pyplot ëª¨ë“ˆì— ìˆëŠ” í•¨ìˆ˜ë¥¼ ê°ê° ë¶ˆëŸ¬ì™€ì„œ êµ¬í˜„ ì‚¬ìš©í•˜ê¸° í¸ë¦¬í•˜ë‚˜, ì„¸ë¶€ ì˜µì…˜ ì¡°ì •ì´ ì–´ë ¤ì›€ ê°ì²´ì§€í–¥ API : Matplotlibì— êµ¬í˜„ëœ ê°ì²´ì§€í–¥ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì§ì ‘ í™œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëŠ˜ì–´ë‚˜ê³ , ì½”ë“œê°€ ë³µì¡í•¨ ê·¸ë˜í”„ì˜ ë””í…Œì¼í•œ ì„¸ë¶€ ì˜µì…˜ ì¡°ì •ì´ ìš©ì´í•¨ ì¼ë°˜ì ìœ¼ë¡œ ë‘ APIë¥¼ í˜¼í•©í•˜ì—¬ ì‚¬ìš© Seaborn Matplotlibì— ì¢…ì†ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ Matplotlibì— ë¹„í•´ ì½”ë“œê°€ ê°„ê²°í•¨ í†µê³„ ê·¸ë˜í”„ êµ¬í˜„ì´ ë³´ë‹¤ ìš©ì´ ì„¸ë¶€ì ì¸ ì˜µì…˜ì€ Matplotlibì—ì„œ ì¡°ì • ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°1234import matplotlibimport seaborn as snsprint(&quot;matplotlib ver :&quot;, matplotlib.__version__)print(&quot;seaborn ver :&quot;, sns.__version__) matplotlib ver : 3.2.2 seaborn ver : 0.11.2 ì‹œê°í™” í…ŒìŠ¤íŠ¸12345678910111213141516import matplotlib.pyplot as pltdates = [ &#x27;2021-01-01&#x27;, &#x27;2021-01-02&#x27;, &#x27;2021-01-03&#x27;, &#x27;2021-01-04&#x27;, &#x27;2021-01-05&#x27;, &#x27;2021-01-06&#x27;, &#x27;2021-01-07&#x27;, &#x27;2021-01-08&#x27;, &#x27;2021-01-09&#x27;, &#x27;2021-01-10&#x27;]min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]# íŒŒì´ì¬ ì‹œê°í™” ìˆ˜í–‰ ì „ ê¸°ë³¸ ì„¤ì • (ìˆ«ìëŠ” ë³€ê²½ ê°€ëŠ¥)fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,6))ax.plot(dates, min_temperature, label = &quot;Min Temp.&quot;)ax.plot(dates, max_temperature, label = &quot;Max Temp.&quot;)ax.legend()plt.show() ì£¼ì‹ ë°ì´í„° ì˜ˆì œ1!pip install yfinance --upgrade --no-cache-dir Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.70) Requirement already satisfied: numpy&gt;=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5) Requirement already satisfied: pandas&gt;=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5) Requirement already satisfied: multitasking&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10) Requirement already satisfied: lxml&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.8.0) Requirement already satisfied: requests&gt;=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2.8.2) Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24.0-&gt;yfinance) (2018.9) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24.0-&gt;yfinance) (1.15.0) Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2.0.12) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (2021.10.8) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.26-&gt;yfinance) (1.24.3) 12345import yfinance as yfdata = yf.download(&quot;AAPL&quot;, start=&quot;2019-08-01&quot;, end=&quot;2022-03-23&quot;)ts = data[&#x27;Open&#x27;]print(ts.head())print(type(ts)) [*********************100%***********************] 1 of 1 completed Date 2019-08-01 53.474998 2019-08-02 51.382500 2019-08-05 49.497501 2019-08-06 49.077499 2019-08-07 48.852501 Name: Open, dtype: float64 &lt;class &#39;pandas.core.series.Series&#39;&gt; pyplot ëª¨ë“ˆ1234567import matplotlib.pyplot as pltplt.plot(ts)plt.title(&quot;Stock Market of AAPL&quot;)plt.xlabel(&quot;Date&quot;)plt.ylabel(&quot;Open Price&quot;)plt.show() ê°ì²´ì§€í–¥ ë¼ì´ë¸ŒëŸ¬ë¦¬123456789import matplotlib.pyplot as pltfig, ax = plt.subplots()ax.plot(ts)ax.set_title(&quot;Stock Market of AAPL&quot;)ax.set_xlabel(&quot;Date&quot;)ax.set_ylabel(&quot;Open Price&quot;)plt.show() ë§‰ëŒ€ ê·¸ë˜í”„Matplotlib12345678910111213141516171819202122import matplotlib.pyplot as pltimport numpy as npimport calendarmonth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450]fig, ax = plt.subplots(figsize=(10,6))barplots = ax.bar(month_list, sold_list)print(&quot;barplots :&quot;, barplots) # artists ë ˆì´ì–´ì— 12ê°œì˜ ë§‰ëŒ€ê°€ ì €ì¥ë¨for plot in barplots: print(plot) # print(plot.get_x()) # print(plot.get_y()) # print(plot.get_width()) # print(&quot;height:&quot;, plot.get_height()) height = plot.get_height() ax.text(plot.get_x() + plot.get_width()/2, height, height, ha = &#x27;center&#x27;, va = &#x27;bottom&#x27;)plt.xticks(month_list, calendar.month_name[1:13], rotation=30) # xì¶•plt.show() barplots : &lt;BarContainer object of 12 artists&gt; Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0) Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0) Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0) Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0) Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0) Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0) Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0) Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0) Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0) Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0) Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0) Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0) Seaborn123fig, ax = plt.subplots()sns.countplot(x=&quot;day&quot;, data=tips)plt.show() 1234print(tips[&#x27;day&#x27;].value_counts().index)print(tips[&#x27;day&#x27;].value_counts().values)print()print(tips[&#x27;day&#x27;].value_counts(ascending=True)) CategoricalIndex([&#39;Sat&#39;, &#39;Sun&#39;, &#39;Thur&#39;, &#39;Fri&#39;], categories=[&#39;Thur&#39;, &#39;Fri&#39;, &#39;Sat&#39;, &#39;Sun&#39;], ordered=False, dtype=&#39;category&#39;) [87 76 62 19] Fri 19 Thur 62 Sun 76 Sat 87 Name: day, dtype: int64 12345678910fig, ax = plt.subplots()ax = sns.countplot(x=&quot;day&quot;, data=tips, order=tips[&#x27;day&#x27;].value_counts().index, alpha=0.5)for plot in ax.patches: print(plot) height = plot.get_height() ax.text(plot.get_x() + plot.get_width()/2, height, height, ha = &#x27;center&#x27;, va = &#x27;bottom&#x27;)ax.set_ylim(-1, 100)plt.show() Rectangle(xy=(-0.4, 0), width=0.8, height=87, angle=0) Rectangle(xy=(0.6, 0), width=0.8, height=76, angle=0) Rectangle(xy=(1.6, 0), width=0.8, height=62, angle=0) Rectangle(xy=(2.6, 0), width=0.8, height=19, angle=0) ì‚°ì ë„Matplotlib123456789101112131415import seaborn as snstips = sns.load_dataset(&quot;tips&quot;)print(tips.info())x = tips[&#x27;total_bill&#x27;]y = tips[&#x27;tip&#x27;]fig, ax = plt.subplots(figsize=(10,6))ax.scatter(x,y)ax.set_title(&#x27;Scatter of tips&#x27;)ax.set_xlabel(&#x27;Total Bill&#x27;)ax.set_ylabel(&#x27;Tip&#x27;)plt.show() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 244 entries, 0 to 243 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 total_bill 244 non-null float64 1 tip 244 non-null float64 2 sex 244 non-null category 3 smoker 244 non-null category 4 day 244 non-null category 5 time 244 non-null category 6 size 244 non-null int64 dtypes: category(4), float64(2), int64(1) memory usage: 7.4 KB None 12345678910tips[&#x27;sex_color&#x27;] = tips[&#x27;sex&#x27;].map(&#123;&#x27;Male&#x27;:&#x27;#4663F5&#x27;, &#x27;Female&#x27;:&#x27;#FF5F2E&#x27;&#125;)fig, ax = plt.subplots(figsize=(10,6))for label, data in tips.groupby(&#x27;sex&#x27;): ax.scatter(data[&#x27;total_bill&#x27;], data[&#x27;tip&#x27;], label=label, color=data[&#x27;sex_color&#x27;], alpha=0.5) ax.set_xlabel(&#x27;Total Bill&#x27;) ax.set_ylabel(&#x27;Tip&#x27;)ax.legend()plt.show() Seaborn12345678910import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)print(tips.info())fig, ax = plt.subplots(figsize=(10,6))sns.scatterplot(x=&#x27;total_bill&#x27;, y=&#x27;tip&#x27;, hue=&#x27;sex&#x27;, data=tips)ax.legend()plt.show() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 244 entries, 0 to 243 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 total_bill 244 non-null float64 1 tip 244 non-null float64 2 sex 244 non-null category 3 smoker 244 non-null category 4 day 244 non-null category 5 time 244 non-null category 6 size 244 non-null int64 dtypes: category(4), float64(2), int64(1) memory usage: 7.4 KB None ë‘ ê°œì˜ ê·¸ë˜í”„ë¥¼ ë™ì‹œì— í‘œí˜„123456fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))sns.regplot(x=&#x27;total_bill&#x27;, y=&#x27;tip&#x27;, data=tips, ax=ax[0], fit_reg=True)ax[0].set_title(&quot;Scatterplot with Regression Line&quot;)sns.regplot(x=&#x27;total_bill&#x27;, y=&#x27;tip&#x27;, data=tips, ax=ax[1], fit_reg=False)ax[1].set_title(&quot;Scatterplot without Regression Line&quot;)plt.show() ì¢…í•© ì˜ˆì œ123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import matplotlib.pyplot as pltimport seaborn as snsimport numpy as npfrom matplotlib.ticker import (MultipleLocator, AutoMinorLocator, FuncFormatter)def major_formatter(x, pos): return &quot;$ %.2f&quot; % xformatter = FuncFormatter(major_formatter)tips = sns.load_dataset(&quot;tips&quot;)fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20,6))### ì™¼ìª½ ë§‰ëŒ€ ê·¸ë˜í”„ax0 = sns.barplot(x=&quot;day&quot;, y=&#x27;total_bill&#x27;, data=tips, ax=ax[0], ci=None, alpha=0.85)# í…ìŠ¤íŠ¸ ì…ë ¥for p in ax0.patches: height = np.round(p.get_height(), 2) ax0.text(p.get_x() + p.get_width()/2., height+1, height, ha = &#x27;center&#x27;, size=12)# ì¶• ë²”ìœ„ ë° ì œëª© ìˆ˜ì •ax0.set_ylim(-3, 30)ax0.set_title(&quot;Basic Bar Graph&quot;)### ì™¼ìª½ ë§‰ëŒ€ ê·¸ë˜í”„ax1 = sns.barplot(x=&quot;day&quot;, y=&quot;total_bill&quot;, data=tips, ax=ax[1], ci=None, color=&#x27;lightgray&#x27;, alpha=0.85, zorder=2)# total_bill í‰ê· ì´ ê°€ì¥ í° ìš”ì¼group_mean = tips.groupby([&#x27;day&#x27;])[&#x27;total_bill&#x27;].agg(&#x27;mean&#x27;)h_day = group_mean.sort_values(ascending=False).index[0] # sundayh_mean = group_mean.sort_values(ascending=False).values[0] # 21.41# ë§‰ëŒ€ë³„ ì˜µì…˜ ì„¤ì •for plot in ax1.patches: height = np.round(plot.get_height(), 2) # ê¸°ë³¸ ì„¤ì • fontweight = &quot;normal&quot; color = &quot;k&quot; # ì¡°ê±´ ì„¤ì • if h_mean == height: fontweight = &quot;bold&quot; color = &quot;darkred&quot; plot.set_facecolor(color) plot.set_edgecolor(&quot;black&quot;) # í…ìŠ¤íŠ¸ ì…ë ¥ ax1.text(plot.get_x() + plot.get_width()/2., height+1, height, ha =&#x27;center&#x27;, size=12, fontweight=fontweight, color=color)# spines ì œê±°ax1.spines[&#x27;top&#x27;].set_visible(False)ax1.spines[&#x27;left&#x27;].set_position((&quot;outward&quot;, 20))ax1.spines[&#x27;left&#x27;].set_visible(False)ax1.spines[&#x27;right&#x27;].set_visible(False)ax1.spines[&#x27;bottom&#x27;].set_visible(False)# ì¶• ë²”ìœ„ ë° ì œëª© ìˆ˜ì •ax1.set_ylim(-1, 30)ax1.set_title(&quot;Ideal Bar Graph&quot;, size=16)ax1.yaxis.set_major_locator(MultipleLocator(10))ax1.yaxis.set_major_formatter(formatter)ax1.yaxis.set_minor_locator(MultipleLocator(5))# ì¶• ë ˆì´ë¸” ìˆ˜ì •ax1.set_ylabel(&quot;Avg. Total Bill($)&quot;, fontsize=14)ax1.set_xlabel(&quot;Weekday&quot;, fontsize=14)# ê·¸ë¦¬ë“œax1.grid(axis=&quot;y&quot;, which=&quot;major&quot;, color=&quot;lightgray&quot;)ax1.grid(axis=&quot;y&quot;, which=&quot;minor&quot;, ls=&quot;:&quot;)# ì¶• ë²”ì£¼ ìˆ˜ì •for xtick in ax1.get_xticklabels(): if xtick.get_text() == h_day: xtick.set_color(&quot;darkred&quot;) xtick.set_fontweight(&quot;demibold&quot;)ax1.set_xticklabels([&#x27;Thursday&#x27;, &#x27;Friday&#x27;, &#x27;Saturday&#x27;, &#x27;Sunday&#x27;], size=12)plt.show()","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"visualization","slug":"visualization","permalink":"http://gonekng.github.io/tags/visualization/"},{"name":"matplotlib","slug":"matplotlib","permalink":"http://gonekng.github.io/tags/matplotlib/"},{"name":"seaborn","slug":"seaborn","permalink":"http://gonekng.github.io/tags/seaborn/"}],"author":"Jiwon Kang"},{"title":"10minutes to Pandas","slug":"Python/Tutorial/10m_to_pd","date":"2022-03-24T02:55:23.000Z","updated":"2022-10-05T05:39:54.218Z","comments":true,"path":"2022/03/24/Python/Tutorial/10m_to_pd/","link":"","permalink":"http://gonekng.github.io/2022/03/24/Python/Tutorial/10m_to_pd/","excerpt":"","text":"Import Library1234import numpy as npprint(&quot;numpy ver.&quot; + np.__version__)import pandas as pdprint(&quot;pandas ver.&quot; + pd.__version__) numpy ver.1.21.5 pandas ver.1.3.5 Object CreationCreating Series by passing a list of values, letting pandas create a default integer index 12s = pd.Series([1,3,5,np.nan, 6,8])print(s) 0 1.0 1 3.0 2 5.0 3 NaN 4 6.0 5 8.0 dtype: float64 Creation DataFrame by passing a NumPy array, with a datetime index and labeled columns 12345dates = pd.date_range(&quot;20130101&quot;, periods=6)print(dates)print()df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list(&quot;ABCD&quot;))print(df) DatetimeIndex([&#39;2013-01-01&#39;, &#39;2013-01-02&#39;, &#39;2013-01-03&#39;, &#39;2013-01-04&#39;, &#39;2013-01-05&#39;, &#39;2013-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) A B C D 2013-01-01 -0.818896 -0.409184 0.087447 -0.935887 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2013-01-04 -0.450437 0.501915 1.003776 0.691249 2013-01-05 1.633764 0.324234 -1.707570 1.163615 2013-01-06 0.282402 -0.922663 -1.641314 0.505433 by passing a dictionary of objects that can be converted into a series-like structure 1234567891011121314df2 = pd.DataFrame( &#123; &quot;A&quot;: 1.0, &quot;B&quot;: pd.Timestamp(&quot;20130102&quot;), &quot;C&quot;: pd.Series(1, index=list(range(4)), dtype=&quot;float32&quot;), &quot;D&quot;: np.array([3] * 4, dtype=&quot;int32&quot;), &quot;E&quot;: pd.Categorical([&quot;test&quot;, &quot;train&quot;, &quot;test&quot;, &quot;train&quot;]), &quot;F&quot;: &quot;foo&quot;, &#125;)print(df2)print()print(&quot;dtypes:&quot;)print(df2.dtypes) A B C D E F 0 1.0 2013-01-02 1.0 3 test foo 1 1.0 2013-01-02 1.0 3 train foo 2 1.0 2013-01-02 1.0 3 test foo 3 1.0 2013-01-02 1.0 3 train foo dtypes: A float64 B datetime64[ns] C float32 D int32 E category F object dtype: object 12# IPython# df2.&lt;TAB&gt; Viewing DataBasic Structure123print(&quot;Head 5:\\n&quot;, df.head())print()print(&quot;Tail 5:\\n&quot;, df.tail()) Head 5: A B C D 2013-01-01 -0.818896 -0.409184 0.087447 -0.935887 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2013-01-04 -0.450437 0.501915 1.003776 0.691249 2013-01-05 1.633764 0.324234 -1.707570 1.163615 Tail 5: A B C D 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2013-01-04 -0.450437 0.501915 1.003776 0.691249 2013-01-05 1.633764 0.324234 -1.707570 1.163615 2013-01-06 0.282402 -0.922663 -1.641314 0.505433 12print(&quot;Index :\\n&quot;, df.index)print(&quot;Columns:\\n&quot;, df.columns) Index : DatetimeIndex([&#39;2013-01-01&#39;, &#39;2013-01-02&#39;, &#39;2013-01-03&#39;, &#39;2013-01-04&#39;, &#39;2013-01-05&#39;, &#39;2013-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) Columns: Index([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], dtype=&#39;object&#39;) DataFrame to NumPy array This can be an expensive operation when your DataFrame has columns with different data types: NumPy arrays have one dtype for the entire array. Pandas DataFrames have one dtype per column. With heterogeneous data, the lowest common type will have to be used. For a mix of numeric and non-numeric types, the output array will have object dtype. 1df.values array([[-0.81889557, -0.40918379, 0.08744721, -0.93588677], [ 0.68154262, -1.39097644, 2.01310478, 0.64446846], [ 1.01791104, 0.03322364, -0.1039122 , 0.63445887], [-0.45043711, 0.50191541, 1.00377617, 0.69124864], [ 1.633764 , 0.32423439, -1.70757042, 1.16361464], [ 0.28240247, -0.92266305, -1.64131359, 0.50543323]]) 123# For df, our DataFrame of all floating-point values,# DataFrame.to_numpy() is fast and doesn&#x27;t require copying data:df.to_numpy() array([[-0.81889557, -0.40918379, 0.08744721, -0.93588677], [ 0.68154262, -1.39097644, 2.01310478, 0.64446846], [ 1.01791104, 0.03322364, -0.1039122 , 0.63445887], [-0.45043711, 0.50191541, 1.00377617, 0.69124864], [ 1.633764 , 0.32423439, -1.70757042, 1.16361464], [ 0.28240247, -0.92266305, -1.64131359, 0.50543323]]) 1df2.values array([[1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;test&#39;, &#39;foo&#39;], [1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;train&#39;, &#39;foo&#39;], [1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;test&#39;, &#39;foo&#39;], [1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;train&#39;, &#39;foo&#39;]], dtype=object) 123# For df2, the DataFrame with multiple dtypes,# DataFrame.to_numpy() is relatively expensive:df2.to_numpy() array([[1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;test&#39;, &#39;foo&#39;], [1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;train&#39;, &#39;foo&#39;], [1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;test&#39;, &#39;foo&#39;], [1.0, Timestamp(&#39;2013-01-02 00:00:00&#39;), 1.0, 3, &#39;train&#39;, &#39;foo&#39;]], dtype=object) Describe, Transpose, Sort1print(df.describe()) A B C D count 6.000000 6.000000 6.000000 6.000000 mean 0.391048 -0.310575 -0.058078 0.450556 std 0.917121 0.739319 1.460690 0.715967 min -0.818896 -1.390976 -1.707570 -0.935887 25% -0.267227 -0.794293 -1.256963 0.537690 50% 0.481973 -0.187980 -0.008232 0.639464 75% 0.933819 0.251482 0.774694 0.679554 max 1.633764 0.501915 2.013105 1.163615 1print(df.T) 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06 A -0.818896 0.681543 1.017911 -0.450437 1.633764 0.282402 B -0.409184 -1.390976 0.033224 0.501915 0.324234 -0.922663 C 0.087447 2.013105 -0.103912 1.003776 -1.707570 -1.641314 D -0.935887 0.644468 0.634459 0.691249 1.163615 0.505433 12345print(&quot;Sorted by axis 1:&quot;)print(df.sort_index(axis=1, ascending=False))print()print(&quot;Sorted by values B:&quot;)print(df.sort_values(by=&quot;B&quot;)) Sorted by axis 1: D C B A 2013-01-01 -0.935887 0.087447 -0.409184 -0.818896 2013-01-02 0.644468 2.013105 -1.390976 0.681543 2013-01-03 0.634459 -0.103912 0.033224 1.017911 2013-01-04 0.691249 1.003776 0.501915 -0.450437 2013-01-05 1.163615 -1.707570 0.324234 1.633764 2013-01-06 0.505433 -1.641314 -0.922663 0.282402 Sorted by values B: A B C D 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-06 0.282402 -0.922663 -1.641314 0.505433 2013-01-01 -0.818896 -0.409184 0.087447 -0.935887 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2013-01-05 1.633764 0.324234 -1.707570 1.163615 2013-01-04 -0.450437 0.501915 1.003776 0.691249 Selecting DataGetting12print(df[&quot;A&quot;])# print(df.A) 2013-01-01 -0.818896 2013-01-02 0.681543 2013-01-03 1.017911 2013-01-04 -0.450437 2013-01-05 1.633764 2013-01-06 0.282402 Freq: D, Name: A, dtype: float64 12print(df[:3])print(df[&quot;20130102&quot;:&quot;20130104&quot;]) A B C D 2013-01-01 -0.818896 -0.409184 0.087447 -0.935887 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 A B C D 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2013-01-04 -0.450437 0.501915 1.003776 0.691249 Selection by Label1print(df.loc[dates[0]]) A -0.818896 B -0.409184 C 0.087447 D -0.935887 Name: 2013-01-01 00:00:00, dtype: float64 1print(df.loc[&quot;20130102&quot;:&quot;20130104&quot;, [&quot;A&quot;,&quot;B&quot;]]) A B 2013-01-02 0.681543 -1.390976 2013-01-03 1.017911 0.033224 2013-01-04 -0.450437 0.501915 1print(df.loc[&quot;20130102&quot;, [&quot;A&quot;,&quot;B&quot;]]) A 0.681543 B -1.390976 Name: 2013-01-02 00:00:00, dtype: float64 12print(df.loc[dates[0], &quot;A&quot;])print(df.at[dates[0],&quot;A&quot;]) # equivalent to the prior method -0.818895566676464 -0.818895566676464 Selection by Position1print(df.iloc[3]) A -0.450437 B 0.501915 C 1.003776 D 0.691249 Name: 2013-01-04 00:00:00, dtype: float64 1print(df.iloc[3:5, 0:2]) A B 2013-01-04 -0.450437 0.501915 2013-01-05 1.633764 0.324234 1print(df.iloc[[1,2,5],[1,3]]) B D 2013-01-02 -1.390976 0.644468 2013-01-03 0.033224 0.634459 2013-01-06 -0.922663 0.505433 1print(df.iloc[1:3,:]) A B C D 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 1print(df.iloc[:,1:3]) B C 2013-01-01 -0.409184 0.087447 2013-01-02 -1.390976 2.013105 2013-01-03 0.033224 -0.103912 2013-01-04 0.501915 1.003776 2013-01-05 0.324234 -1.707570 2013-01-06 -0.922663 -1.641314 12print(df.iloc[1,1])print(df.iat[1,1]) # equivalent to the prior method -1.3909764417520816 -1.3909764417520816 Boolean Indexing1print(df[df[&quot;A&quot;]&gt;0]) A B C D 2013-01-02 0.681543 -1.390976 2.013105 0.644468 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2013-01-05 1.633764 0.324234 -1.707570 1.163615 2013-01-06 0.282402 -0.922663 -1.641314 0.505433 1print(df[df&gt;0]) A B C D 2013-01-01 NaN NaN 0.087447 NaN 2013-01-02 0.681543 NaN 2.013105 0.644468 2013-01-03 1.017911 0.033224 NaN 0.634459 2013-01-04 NaN 0.501915 1.003776 0.691249 2013-01-05 1.633764 0.324234 NaN 1.163615 2013-01-06 0.282402 NaN NaN 0.505433 12345df2 = df.copy()df2[&quot;E&quot;] = [&#x27;one&#x27;, &#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;, &#x27;four&#x27;, &#x27;three&#x27;]print(df2)print()print(df2[df2[&quot;E&quot;].isin([&quot;two&quot;, &quot;four&quot;])]) A B C D E 2013-01-01 -0.818896 -0.409184 0.087447 -0.935887 one 2013-01-02 0.681543 -1.390976 2.013105 0.644468 one 2013-01-03 1.017911 0.033224 -0.103912 0.634459 two 2013-01-04 -0.450437 0.501915 1.003776 0.691249 three 2013-01-05 1.633764 0.324234 -1.707570 1.163615 four 2013-01-06 0.282402 -0.922663 -1.641314 0.505433 three A B C D E 2013-01-03 1.017911 0.033224 -0.103912 0.634459 two 2013-01-05 1.633764 0.324234 -1.707570 1.163615 four Setting12345s1 = pd.Series([1,2,3,4,5,6], index = pd.date_range(&quot;20130102&quot;,periods=6))print(s1)print()df[&quot;F&quot;] = s1print(df) 2013-01-02 1 2013-01-03 2 2013-01-04 3 2013-01-05 4 2013-01-06 5 2013-01-07 6 Freq: D, dtype: int64 A B C D F 2013-01-01 -0.818896 -0.409184 0.087447 -0.935887 NaN 2013-01-02 0.681543 -1.390976 2.013105 0.644468 1.0 2013-01-03 1.017911 0.033224 -0.103912 0.634459 2.0 2013-01-04 -0.450437 0.501915 1.003776 0.691249 3.0 2013-01-05 1.633764 0.324234 -1.707570 1.163615 4.0 2013-01-06 0.282402 -0.922663 -1.641314 0.505433 5.0 1234df.at[dates[0], &quot;A&quot;] = 0 # setting values by labeldf.iat[0,1] = 0 # setting values by positiondf.loc[:, &quot;D&quot;] = np.array([5] * len(df)) # setting by assigning with a NumPy arrayprint(df) A B C D F 2013-01-01 0.000000 0.000000 0.087447 5 NaN 2013-01-02 0.681543 -1.390976 2.013105 5 1.0 2013-01-03 1.017911 0.033224 -0.103912 5 2.0 2013-01-04 -0.450437 0.501915 1.003776 5 3.0 2013-01-05 1.633764 0.324234 -1.707570 5 4.0 2013-01-06 0.282402 -0.922663 -1.641314 5 5.0 123df2 = df.copy()df2[df2&gt;0] = -df2 # setting values by booleanprint(df2) A B C D F 2013-01-01 0.000000 0.000000 -0.087447 -5 NaN 2013-01-02 -0.681543 -1.390976 -2.013105 -5 -1.0 2013-01-03 -1.017911 -0.033224 -0.103912 -5 -2.0 2013-01-04 -0.450437 -0.501915 -1.003776 -5 -3.0 2013-01-05 -1.633764 -0.324234 -1.707570 -5 -4.0 2013-01-06 -0.282402 -0.922663 -1.641314 -5 -5.0 Missing Data123df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&quot;E&quot;])df1.loc[dates[0] : dates[1], &quot;E&quot;] = 1print(df1) A B C D F E 2013-01-01 0.000000 0.000000 0.087447 5 NaN 1.0 2013-01-02 0.681543 -1.390976 2.013105 5 1.0 1.0 2013-01-03 1.017911 0.033224 -0.103912 5 2.0 NaN 2013-01-04 -0.450437 0.501915 1.003776 5 3.0 NaN 123print(df1.dropna(how=&quot;any&quot;)) # how=&quot;any&quot; (default) : where any NA values are presentprint()print(df1.dropna(how=&quot;all&quot;)) # how=&quot;all&quot; : where all values are NA A B C D F E 2013-01-02 0.681543 -1.390976 2.013105 5 1.0 1.0 A B C D F E 2013-01-01 0.000000 0.000000 0.087447 5 NaN 1.0 2013-01-02 0.681543 -1.390976 2.013105 5 1.0 1.0 2013-01-03 1.017911 0.033224 -0.103912 5 2.0 NaN 2013-01-04 -0.450437 0.501915 1.003776 5 3.0 NaN 123print(pd.isna(df1))print()print(df1.fillna(value=5)) A B C D F E 2013-01-01 False False False False True False 2013-01-02 False False False False False False 2013-01-03 False False False False False True 2013-01-04 False False False False False True A B C D F E 2013-01-01 0.000000 0.000000 0.087447 5 5.0 1.0 2013-01-02 0.681543 -1.390976 2.013105 5 1.0 1.0 2013-01-03 1.017911 0.033224 -0.103912 5 2.0 5.0 2013-01-04 -0.450437 0.501915 1.003776 5 3.0 5.0 OperationsStats12345print(&quot;axis 0 :&quot;)print(df.mean())print()print(&quot;axis 1 :&quot;)print(df.mean(1)) axis 0 : A 0.527531 B -0.242378 C -0.058078 D 5.000000 F 3.000000 dtype: float64 axis 1 : 2013-01-01 1.271862 2013-01-02 1.460734 2013-01-03 1.589444 2013-01-04 1.811051 2013-01-05 1.850086 2013-01-06 1.543685 Freq: D, dtype: float64 123456print(df)print()s = pd.Series([1, 3, 4, np.nan, 6, 8], index=dates).shift(2)print(s)print()print(df.sub(s, axis=0)) # equivalent to (dataframe - other) A B C D F 2013-01-01 0.000000 0.000000 0.087447 5 NaN 2013-01-02 0.681543 -1.390976 2.013105 5 1.0 2013-01-03 1.017911 0.033224 -0.103912 5 2.0 2013-01-04 -0.450437 0.501915 1.003776 5 3.0 2013-01-05 1.633764 0.324234 -1.707570 5 4.0 2013-01-06 0.282402 -0.922663 -1.641314 5 5.0 2013-01-01 NaN 2013-01-02 NaN 2013-01-03 1.0 2013-01-04 3.0 2013-01-05 4.0 2013-01-06 NaN Freq: D, dtype: float64 A B C D F 2013-01-01 NaN NaN NaN NaN NaN 2013-01-02 NaN NaN NaN NaN NaN 2013-01-03 0.017911 -0.966776 -1.103912 4.0 1.0 2013-01-04 -3.450437 -2.498085 -1.996224 2.0 0.0 2013-01-05 -2.366236 -3.675766 -5.707570 1.0 0.0 2013-01-06 NaN NaN NaN NaN NaN Apply1print(df.apply(np.cumsum)) A B C D F 2013-01-01 0.000000 0.000000 0.087447 5 NaN 2013-01-02 0.681543 -1.390976 2.100552 10 1.0 2013-01-03 1.699454 -1.357753 1.996640 15 3.0 2013-01-04 1.249017 -0.855837 3.000416 20 6.0 2013-01-05 2.882781 -0.531603 1.292846 25 10.0 2013-01-06 3.165183 -1.454266 -0.348468 30 15.0 1print(df.apply(lambda x: x.max() - x.min())) A 2.084201 B 1.892892 C 3.720675 D 0.000000 F 4.000000 dtype: float64 Histogramming1234s = pd.Series(np.random.randint(0, 7, size=10))print(s)print()print(s.value_counts()) 0 1 1 6 2 5 3 1 4 1 5 3 6 2 7 1 8 1 9 6 dtype: int64 1 5 6 2 5 1 3 1 2 1 dtype: int64 String Methods1234s = pd.Series([&quot;A&quot;,&quot;Aaba&quot;, np.nan, &quot;CABA&quot;, &quot;cat&quot;])print(s.str.lower())print()print(s.str.upper()) 0 a 1 aaba 2 NaN 3 caba 4 cat dtype: object 0 A 1 AABA 2 NaN 3 CABA 4 CAT dtype: object MergeConcat combining together Series and DataFrame objects 12df = pd.DataFrame(np.random.randn(10,4))print(df) 0 1 2 3 0 -0.146700 1.278642 1.837775 0.644873 1 -0.332040 1.597295 -0.681229 -1.238212 2 0.751823 1.117058 -0.453366 0.953989 3 0.074173 -1.043050 0.276312 0.926186 4 -0.090674 1.679349 2.130480 0.950658 5 0.483778 -0.330530 0.370747 0.569736 6 -0.603331 2.363939 -0.052191 0.186119 7 -2.002784 -1.237193 -1.876920 -0.876104 8 1.121755 -0.104830 -1.675228 1.250540 9 0.008456 -1.287063 0.070528 -0.642563 1234pieces = [df[:3], df[3:7], df[7:]]print(pieces)print()print(pd.concat(pieces)) # Concatenating objects together [ 0 1 2 3 0 -0.146700 1.278642 1.837775 0.644873 1 -0.332040 1.597295 -0.681229 -1.238212 2 0.751823 1.117058 -0.453366 0.953989, 0 1 2 3 3 0.074173 -1.043050 0.276312 0.926186 4 -0.090674 1.679349 2.130480 0.950658 5 0.483778 -0.330530 0.370747 0.569736 6 -0.603331 2.363939 -0.052191 0.186119, 0 1 2 3 7 -2.002784 -1.237193 -1.876920 -0.876104 8 1.121755 -0.104830 -1.675228 1.250540 9 0.008456 -1.287063 0.070528 -0.642563] 0 1 2 3 0 -0.146700 1.278642 1.837775 0.644873 1 -0.332040 1.597295 -0.681229 -1.238212 2 0.751823 1.117058 -0.453366 0.953989 3 0.074173 -1.043050 0.276312 0.926186 4 -0.090674 1.679349 2.130480 0.950658 5 0.483778 -0.330530 0.370747 0.569736 6 -0.603331 2.363939 -0.052191 0.186119 7 -2.002784 -1.237193 -1.876920 -0.876104 8 1.121755 -0.104830 -1.675228 1.250540 9 0.008456 -1.287063 0.070528 -0.642563 Join SQL style merging 1234567left = pd.DataFrame(&#123;&#x27;key&#x27;:[&#x27;foo&#x27;, &#x27;foo&#x27;], &#x27;lval&#x27;:[1, 2]&#125;)right = pd.DataFrame(&#123;&#x27;key&#x27;:[&#x27;foo&#x27;, &#x27;foo&#x27;], &#x27;rval&#x27;:[4, 5]&#125;)print(left)print()print(right)print()print(pd.merge(left, right, on=&#x27;key&#x27;)) key lval 0 foo 1 1 foo 2 key rval 0 foo 4 1 foo 5 key lval rval 0 foo 1 4 1 foo 1 5 2 foo 2 4 3 foo 2 5 1234567left = pd.DataFrame(&#123;&#x27;key&#x27;:[&#x27;foo&#x27;, &#x27;bar&#x27;], &#x27;lval&#x27;:[1, 2]&#125;)right = pd.DataFrame(&#123;&#x27;key&#x27;:[&#x27;foo&#x27;, &#x27;bar&#x27;], &#x27;rval&#x27;:[4, 5]&#125;)print(left)print()print(right)print()print(pd.merge(left, right, on=&#x27;key&#x27;)) key lval 0 foo 1 1 bar 2 key rval 0 foo 4 1 bar 5 key lval rval 0 foo 1 4 1 bar 2 5 Append12df = pd.DataFrame(np.random.randn(8, 4), columns=[&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;])print(df) A B C D 0 0.120201 -0.286267 -0.205740 1.107503 1 -0.818479 -0.059564 0.192151 1.920259 2 0.687467 -0.833330 -0.426913 0.852926 3 -1.103335 0.213012 1.003000 -0.648385 4 -0.576006 1.414470 0.851227 -0.277232 5 0.189853 0.311170 -0.448372 -0.201059 6 1.707547 0.099129 -1.332999 0.478148 7 1.153861 1.831233 0.125928 -1.330353 12s = df.iloc[3]print(df.append(s, ignore_index=True)) A B C D 0 0.120201 -0.286267 -0.205740 1.107503 1 -0.818479 -0.059564 0.192151 1.920259 2 0.687467 -0.833330 -0.426913 0.852926 3 -1.103335 0.213012 1.003000 -0.648385 4 -0.576006 1.414470 0.851227 -0.277232 5 0.189853 0.311170 -0.448372 -0.201059 6 1.707547 0.099129 -1.332999 0.478148 7 1.153861 1.831233 0.125928 -1.330353 8 -1.103335 0.213012 1.003000 -0.648385 Grouping Splitting the data into groups based on some criteria Applying a function to each group independently Combining the results into a data structure 123456789df = pd.DataFrame( &#123; &quot;A&quot;: [&quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;foo&quot;], &quot;B&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;two&quot;, &quot;two&quot;, &quot;one&quot;, &quot;three&quot;], &quot;C&quot;: np.random.randn(8), &quot;D&quot;: np.random.randn(8), &#125;)print(df) A B C D 0 foo one 0.031321 -0.238988 1 bar one -0.626332 -0.445851 2 foo two -1.448981 1.262838 3 bar three -0.424664 -0.639157 4 foo two 1.547849 2.378992 5 bar two -0.351304 -0.521492 6 foo one -1.903777 1.998802 7 foo three -0.613947 -0.422391 1print(df.groupby(&quot;A&quot;).sum()) C D A bar -1.402300 -1.606500 foo -2.387536 4.979252 1print(df.groupby([&quot;A&quot;,&quot;B&quot;]).sum()) C D A B bar one -0.626332 -0.445851 three -0.424664 -0.639157 two -0.351304 -0.521492 foo one -1.872457 1.759814 three -0.613947 -0.422391 two 0.098868 3.641830 1234df_min = df.groupby([&quot;A&quot;,&quot;B&quot;])[&quot;C&quot;].min()df_max = df.groupby([&quot;A&quot;,&quot;B&quot;])[&quot;C&quot;].max()print(pd.merge(df_min, df_max, on=[&#x27;A&#x27;,&quot;B&quot;], suffixes=(&#x27;_min&#x27;, &#x27;_max&#x27;))) C_min C_max A B bar one -0.626332 -0.626332 three -0.424664 -0.424664 two -0.351304 -0.351304 foo one -1.903777 0.031321 three -0.613947 -0.613947 two -1.448981 1.547849 ReshapingStack stack() : Compress a level in the DataFrameâ€™s columns: 1234567891011121314tuples = list( zip( *[ [&quot;bar&quot;, &quot;bar&quot;, &quot;baz&quot;, &quot;baz&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;qux&quot;, &quot;qux&quot;], [&quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;], ] ))index = pd.MultiIndex.from_tuples(tuples, names=[&quot;idx_1&quot;, &quot;idx_2&quot;])df = pd.DataFrame(np.random.randn(8,2), index=index, columns=[&quot;A&quot;,&quot;B&quot;])df2 = df[:4]print(df2) A B idx_1 idx_2 bar one -0.748802 0.560048 two -0.214015 -0.658540 baz one -1.968829 -0.806776 two -1.314742 -0.174498 12stacked = df2.stack()print(stacked) # level: idx_1 &gt; idx_2 &gt; columns idx_1 idx_2 bar one A -0.748802 B 0.560048 two A -0.214015 B -0.658540 baz one A -1.968829 B -0.806776 two A -1.314742 B -0.174498 dtype: float64 unstack() : the inverse operation of stack() 12345print(stacked.unstack()) # columns(last level) / default -1print()print(stacked.unstack(0)) # idx_1 print()print(stacked.unstack(1)) # idx_2 A B idx_1 idx_2 bar one -0.748802 0.560048 two -0.214015 -0.658540 baz one -1.968829 -0.806776 two -1.314742 -0.174498 idx_1 bar baz idx_2 one A -0.748802 -1.968829 B 0.560048 -0.806776 two A -0.214015 -1.314742 B -0.658540 -0.174498 idx_2 one two idx_1 bar A -0.748802 -0.214015 B 0.560048 -0.658540 baz A -1.968829 -1.314742 B -0.806776 -0.174498 Pivot Table12345678910df = pd.DataFrame( &#123; &quot;A&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;] * 3, &quot;B&quot;: [&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;] * 4, &quot;C&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;] * 2, &quot;D&quot;: np.random.randn(12), &quot;E&quot;: np.random.randn(12), &#125;)print(df) A B C D E 0 one aa foo 1.055556 -0.342298 1 one bb foo -0.463657 -0.004332 2 two cc foo 0.953746 0.690613 3 three aa bar -0.980697 0.498251 4 one bb bar -0.352120 -0.503475 5 one cc bar 0.298470 -1.316212 6 two aa foo 0.580929 0.483970 7 three bb foo 0.391527 0.200354 8 one cc foo -1.314898 -1.183403 9 one aa bar -0.058855 -0.004713 10 two bb bar -0.253133 1.255313 11 three cc bar 0.882602 0.561369 1print(pd.pivot_table(df, values=&quot;D&quot;, index=[&quot;A&quot;,&quot;B&quot;], columns=&quot;C&quot;)) C bar foo A B one aa -0.058855 1.055556 bb -0.352120 -0.463657 cc 0.298470 -1.314898 three aa -0.980697 NaN bb NaN 0.391527 cc 0.882602 NaN two aa NaN 0.580929 bb -0.253133 NaN cc NaN 0.953746 Time Series12345rng = pd.date_range(&quot;1/1/2022&quot;, periods=100, freq=&quot;S&quot;) # secondly frequencyts = pd.Series(np.random.randint(0,500,len(rng)), index=rng)print(ts.resample(&quot;5Min&quot;).first())print(ts.resample(&quot;5Min&quot;).last())print(ts.resample(&quot;5Min&quot;).sum()) 2022-01-01 192 Freq: 5T, dtype: int64 2022-01-01 304 Freq: 5T, dtype: int64 2022-01-01 26586 Freq: 5T, dtype: int64 123rng = pd.date_range(&quot;3/6/2021 00:00&quot;, periods=5, freq=&quot;D&quot;) # daily frequencyts = pd.Series(np.random.randn(len(rng)), rng)print(ts) 2021-03-06 -1.465806 2021-03-07 0.938092 2021-03-08 2.811226 2021-03-09 -0.186533 2021-03-10 -1.048929 Freq: D, dtype: float64 12345ts_utc = ts.tz_localize(&quot;UTC&quot;) # UTC timezoneprint(&quot;UTC :&quot;)print(ts_utc)print(&quot;\\nUS/Eastern :&quot;)print(ts_utc.tz_convert(&quot;US/Eastern&quot;)) # US/Eastern timezone UTC : 2021-03-06 00:00:00+00:00 -1.465806 2021-03-07 00:00:00+00:00 0.938092 2021-03-08 00:00:00+00:00 2.811226 2021-03-09 00:00:00+00:00 -0.186533 2021-03-10 00:00:00+00:00 -1.048929 Freq: D, dtype: float64 US/Eastern : 2021-03-05 19:00:00-05:00 -1.465806 2021-03-06 19:00:00-05:00 0.938092 2021-03-07 19:00:00-05:00 2.811226 2021-03-08 19:00:00-05:00 -0.186533 2021-03-09 19:00:00-05:00 -1.048929 Freq: D, dtype: float64 12345678rng = pd.date_range(&quot;1/1/2022&quot;, periods=5, freq=&quot;M&quot;)ts = pd.Series(np.random.randn(len(rng)), index=rng)print(ts) # DatetimeIndexprint()ps = ts.to_period()print(ps) # PeriodIndexprint()print(ps.to_timestamp()) 2022-01-31 0.438135 2022-02-28 -0.052516 2022-03-31 -1.491175 2022-04-30 0.708521 2022-05-31 -1.794057 Freq: M, dtype: float64 DatetimeIndex([&#39;2022-01-31&#39;, &#39;2022-02-28&#39;, &#39;2022-03-31&#39;, &#39;2022-04-30&#39;, &#39;2022-05-31&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;M&#39;) 2022-01 0.438135 2022-02 -0.052516 2022-03 -1.491175 2022-04 0.708521 2022-05 -1.794057 Freq: M, dtype: float64 PeriodIndex([&#39;2022-01&#39;, &#39;2022-02&#39;, &#39;2022-03&#39;, &#39;2022-04&#39;, &#39;2022-05&#39;], dtype=&#39;period[M]&#39;) 2022-01-01 0.438135 2022-02-01 -0.052516 2022-03-01 -1.491175 2022-04-01 0.708521 2022-05-01 -1.794057 Freq: MS, dtype: float64 12345678prng = pd.period_range(&quot;1990Q1&quot;, &quot;2000Q4&quot;, freq=&quot;Q-NOV&quot;) # quarterly frequencyts = pd.Series(np.random.randn(len(prng)), prng)print(ts.head())print()# month end &amp; hour startts.index = (prng.asfreq(&quot;M&quot;, &quot;e&quot;) + 1).asfreq(&quot;H&quot;, &quot;s&quot;) + 9print(ts.head()) 1990Q1 1.479314 1990Q2 0.799696 1990Q3 0.148978 1990Q4 -0.571086 1991Q1 1.908509 Freq: Q-NOV, dtype: float64 1990-03-01 09:00 1.479314 1990-06-01 09:00 0.799696 1990-09-01 09:00 0.148978 1990-12-01 09:00 -0.571086 1991-03-01 09:00 1.908509 Freq: H, dtype: float64 Categoricals1234df = pd.DataFrame(&#123;&quot;id&quot;: [1, 2, 3, 4, 5, 6], &quot;raw_grade&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;e&quot;]&#125;)print(df) id raw_grade 0 1 a 1 2 b 2 3 b 3 4 a 4 5 a 5 6 e 123456df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;)df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;] # rename categoriesdf[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories( [&quot;very bad&quot;, &quot;bad&quot;,&quot;medium&quot;,&quot;good&quot;,&quot;very good&quot;])df[&quot;grade&quot;] 0 very good 1 good 2 good 3 very good 4 very good 5 very bad Name: grade, dtype: category Categories (5, object): [&#39;very bad&#39;, &#39;bad&#39;, &#39;medium&#39;, &#39;good&#39;, &#39;very good&#39;] 1print(df.sort_values(by=&quot;grade&quot;).reset_index(drop=True)) id raw_grade grade 0 6 e very bad 1 2 b good 2 3 b good 3 1 a very good 4 4 a very good 5 5 a very good 1print(df.groupby(&quot;grade&quot;).size()) grade very bad 1 bad 0 medium 0 good 2 very good 3 dtype: int64 Plotting123456import matplotlib.pyplot as pltts = pd.Series(np.random.randn(1000), index=pd.date_range(&quot;1/1/2010&quot;, periods=1000))ts = ts.cumsum()ts.plot()plt.show() 12345df = pd.DataFrame(np.random.randn(1000,4), index=ts.index, columns=[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;])df = df.cumsum()df.plot()plt.legend(loc=&#x27;best&#x27;)plt.show() Getting data in&#x2F;outCSV1df.to_csv(&quot;foo.csv&quot;) 1print(pd.read_csv(&quot;foo.csv&quot;)) Unnamed: 0 A B C D 0 2010-01-01 0.015846 0.025822 0.443290 -0.724835 1 2010-01-02 -0.084776 0.330946 -0.669265 -0.949676 2 2010-01-03 1.325583 -0.697926 -0.204375 -1.145391 3 2010-01-04 2.293831 -2.097458 -1.260249 -0.555542 4 2010-01-05 1.334001 -2.392123 -2.659330 -0.325232 .. ... ... ... ... ... 995 2012-09-22 -7.868011 -59.520981 -49.220218 -54.072522 996 2012-09-23 -7.288884 -59.584693 -49.307716 -54.783148 997 2012-09-24 -6.835061 -59.508180 -49.608991 -55.780242 998 2012-09-25 -6.863802 -58.711503 -50.458917 -55.218363 999 2012-09-26 -7.075728 -59.524064 -49.924592 -55.653215 [1000 rows x 5 columns] HDF51df.to_hdf(&quot;foo.h5&quot;, &quot;df&quot;) 1print(pd.read_hdf(&quot;foo.h5&quot;, &quot;df&quot;)) A B C D 2010-01-01 0.015846 0.025822 0.443290 -0.724835 2010-01-02 -0.084776 0.330946 -0.669265 -0.949676 2010-01-03 1.325583 -0.697926 -0.204375 -1.145391 2010-01-04 2.293831 -2.097458 -1.260249 -0.555542 2010-01-05 1.334001 -2.392123 -2.659330 -0.325232 ... ... ... ... ... 2012-09-22 -7.868011 -59.520981 -49.220218 -54.072522 2012-09-23 -7.288884 -59.584693 -49.307716 -54.783148 2012-09-24 -6.835061 -59.508180 -49.608991 -55.780242 2012-09-25 -6.863802 -58.711503 -50.458917 -55.218363 2012-09-26 -7.075728 -59.524064 -49.924592 -55.653215 [1000 rows x 4 columns] Excel1df.to_excel(&quot;foo.xlsx&quot;, sheet_name=&quot;Sheet1&quot;) 1print(pd.read_excel(&quot;foo.xlsx&quot;, &quot;Sheet1&quot;, index_col=None, na_values=[&quot;NA&quot;])) Unnamed: 0 A B C D 0 2010-01-01 0.015846 0.025822 0.443290 -0.724835 1 2010-01-02 -0.084776 0.330946 -0.669265 -0.949676 2 2010-01-03 1.325583 -0.697926 -0.204375 -1.145391 3 2010-01-04 2.293831 -2.097458 -1.260249 -0.555542 4 2010-01-05 1.334001 -2.392123 -2.659330 -0.325232 .. ... ... ... ... ... 995 2012-09-22 -7.868011 -59.520981 -49.220218 -54.072522 996 2012-09-23 -7.288884 -59.584693 -49.307716 -54.783148 997 2012-09-24 -6.835061 -59.508180 -49.608991 -55.780242 998 2012-09-25 -6.863802 -58.711503 -50.458917 -55.218363 999 2012-09-26 -7.075728 -59.524064 -49.924592 -55.653215 [1000 rows x 5 columns]","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"pandas","slug":"pandas","permalink":"http://gonekng.github.io/tags/pandas/"}],"author":"Jiwon Kang"},{"title":"Pandas tutorial 2","slug":"Python/Tutorial/pd_tutorial_02","date":"2022-03-24T02:53:00.000Z","updated":"2022-10-05T05:39:54.741Z","comments":true,"path":"2022/03/24/Python/Tutorial/pd_tutorial_02/","link":"","permalink":"http://gonekng.github.io/2022/03/24/Python/Tutorial/pd_tutorial_02/","excerpt":"","text":"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°1234import numpy as npprint(&quot;numpy: ver.&quot;, np.__version__)import pandas as pdprint(&quot;pandas: ver.&quot;, pd.__version__) numpy: ver. 1.21.5 pandas: ver. 1.3.5 ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°12from google.colab import drivedrive.mount(&#x27;/content/drive&#x27;) Mounted at /content/drive 123DATA_PATH = &#x27;/content/drive/MyDrive/Colab Notebooks/Data/supermarket_sales.csv&#x27;sales = pd.read_csv(DATA_PATH)print(sales.head(3)) Invoice ID Branch City Customer type Gender \\ 0 750-67-8428 A Yangon Member Female 1 226-31-3081 C Naypyitaw Normal Female 2 631-41-3108 A Yangon Normal Male Product line Unit price Quantity Date Time Payment 0 Health and beauty 74.69 7 1/5/2019 13:08 Ewallet 1 Electronic accessories 15.28 5 3/8/2019 10:29 Cash 2 Home and lifestyle 46.33 7 3/3/2019 13:23 Credit card 1sales.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1000 entries, 0 to 999 Data columns (total 11 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Invoice ID 1000 non-null object 1 Branch 1000 non-null object 2 City 1000 non-null object 3 Customer type 1000 non-null object 4 Gender 1000 non-null object 5 Product line 1000 non-null object 6 Unit price 1000 non-null float64 7 Quantity 1000 non-null int64 8 Date 1000 non-null object 9 Time 1000 non-null object 10 Payment 1000 non-null object dtypes: float64(1), int64(1), object(9) memory usage: 86.1+ KB ë°ì´í„° ê·¸ë£¹í™” groupby() ë° ë‹¤ì–‘í•œ ì§‘ê³„í•¨ìˆ˜ í™œìš© 1sales.groupby(by=&quot;Product line&quot;)[&#x27;Quantity&#x27;].count() Product line Electronic accessories 170 Fashion accessories 178 Food and beverages 174 Health and beauty 152 Home and lifestyle 160 Sports and travel 166 Name: Quantity, dtype: int64 1sales.groupby(by=&quot;Product line&quot;)[&#x27;Quantity&#x27;].sum() Product line Electronic accessories 971 Fashion accessories 902 Food and beverages 952 Health and beauty 854 Home and lifestyle 911 Sports and travel 920 Name: Quantity, dtype: int64 12print(sales.groupby(by=[&quot;Branch&quot;,&quot;Customer type&quot;])[&#x27;Quantity&#x27;].sum())print(type(sales.groupby(by=[&quot;Branch&quot;,&quot;Customer type&quot;])[&#x27;Quantity&#x27;].sum())) # Series ê°ì²´ Branch Customer type A Member 964 Normal 895 B Member 924 Normal 896 C Member 897 Normal 934 Name: Quantity, dtype: int64 &lt;class &#39;pandas.core.series.Series&#39;&gt; 12print(sales.groupby(by=[&quot;Branch&quot;,&quot;Payment&quot;], as_index=False)[&#x27;Quantity&#x27;].sum())print(type(sales.groupby(by=[&quot;Branch&quot;,&quot;Payment&quot;], as_index=False)[&#x27;Quantity&#x27;].sum())) # DataFrmae ê°ì²´ Branch Payment Quantity 0 A Cash 572 1 A Credit card 580 2 A Ewallet 707 3 B Cash 628 4 B Credit card 599 5 B Ewallet 593 6 C Cash 696 7 C Credit card 543 8 C Ewallet 592 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; 12print(sales.groupby(by=[&quot;Branch&quot;, &quot;Payment&quot;])[&#x27;Unit price&#x27;].agg([&quot;max&quot;, &quot;min&quot;, &quot;mean&quot;]))print(type(sales.groupby(by=[&quot;Branch&quot;, &quot;Payment&quot;])[&#x27;Unit price&#x27;].agg([&quot;max&quot;, &quot;min&quot;, &quot;mean&quot;]))) # DataFrame ê°ì²´ max min mean Branch Payment A Cash 99.78 10.08 56.374636 Credit card 99.56 11.94 53.011635 Ewallet 99.83 10.13 54.849762 B Cash 99.69 11.85 56.758818 Credit card 99.96 10.59 56.838991 Ewallet 99.92 10.75 53.450973 C Cash 99.96 10.17 57.100081 Credit card 99.82 10.18 53.143061 Ewallet 99.79 10.16 59.238962 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; 12print(sales.groupby(by=[&quot;Branch&quot;, &quot;Payment&quot;])[&#x27;Unit price&#x27;].agg([&quot;max&quot;, &quot;min&quot;, &quot;mean&quot;]).reset_index())print(type(sales.groupby(by=[&quot;Branch&quot;, &quot;Payment&quot;])[&#x27;Unit price&#x27;].agg([&quot;max&quot;, &quot;min&quot;, &quot;mean&quot;]).reset_index())) Branch Payment max min mean 0 A Cash 99.78 10.08 56.374636 1 A Credit card 99.56 11.94 53.011635 2 A Ewallet 99.83 10.13 54.849762 3 B Cash 99.69 11.85 56.758818 4 B Credit card 99.96 10.59 56.838991 5 B Ewallet 99.92 10.75 53.450973 6 C Cash 99.96 10.17 57.100081 7 C Credit card 99.82 10.18 53.143061 8 C Ewallet 99.79 10.16 59.238962 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; ê²°ì¸¡ì¹˜ ì²˜ë¦¬ê²°ì¸¡ì¹˜ ë°ì´í„° ìƒì„±1234567dict_01 = &#123; &#x27;Score A&#x27; : [80, 90, np.nan, 80], &#x27;Score B&#x27; : [30, 45, np.nan, np.nan], &#x27;Score C&#x27; : [np.nan, 50, 80, 90]&#125;df = pd.DataFrame(dict_01)print(df) Score A Score B Score C 0 80.0 30.0 NaN 1 90.0 45.0 50.0 2 NaN NaN 80.0 3 80.0 NaN 90.0 123print(df.isnull())print(&quot;\\n&quot;)print(df.isnull().sum()) Score A Score B Score C 0 False False True 1 False False False 2 True True False 3 False True False Score A 1 Score B 2 Score C 1 dtype: int64 1234567dict_02 = &#123; &quot;Gender&quot; : [&quot;Male&quot;, &quot;Female&quot;, np.nan, &quot;Male&quot;], &quot;Salary&quot; : [30, 45, 90, 70]&#125;df2 = pd.DataFrame(dict_02)print(df2) Gender Salary 0 Male 30 1 Female 45 2 NaN 90 3 Male 70 123print(df.isnull())print(&quot;\\n&quot;)print(df.isnull().sum()) Score A Score B Score C 0 False False True 1 False False False 2 True True False 3 False True False Score A 1 Score B 2 Score C 1 dtype: int64 ê²°ì¸¡ì¹˜ ê°’ ëŒ€ì²´ ë¬¸ìì—´ íƒ€ì…ê³¼ ìˆ«ì íƒ€ì…ì˜ ì ‘ê·¼ ë°©ë²• ìƒì´ ë¬¸ìì—´ : ìµœë¹ˆê°’ ë“± ìˆ«ì : í‰ê· , ìµœëŒ€ê°’, ìµœì†Œê°’, ì¤‘ê°„ê°’ ë“± 1print(df.fillna(0)) # 0ìœ¼ë¡œ ëŒ€ì²´ Score A Score B Score C 0 80.0 30.0 0.0 1 90.0 45.0 50.0 2 0.0 0.0 80.0 3 80.0 0.0 90.0 Score A float64 Score B float64 Score C float64 dtype: object 12print(df.fillna(method=&quot;pad&quot;)) # ì• ë°ì´í„°ë¡œ ëŒ€ì²´# print(df.fillna(method=&quot;ffill&quot;)) : ë™ì¼í•œ ê²°ê³¼ Score A Score B Score C 0 80.0 30.0 NaN 1 90.0 45.0 50.0 2 90.0 45.0 80.0 3 80.0 45.0 90.0 Score A Score B Score C 0 80.0 30.0 NaN 1 90.0 45.0 50.0 2 90.0 45.0 80.0 3 80.0 45.0 90.0 12print(df.fillna(method=&quot;backfill&quot;)) # ë’¤ ë°ì´í„°ë¡œ ëŒ€ì²´# print(df.fillna(method=&quot;bfill&quot;)) : ë™ì¼í•œ ê²°ê³¼ Score A Score B Score C 0 80.0 30.0 50.0 1 90.0 45.0 50.0 2 80.0 NaN 80.0 3 80.0 NaN 90.0 1print(df2[&#x27;Gender&#x27;].fillna(&quot;Genderless&quot;)) # íŠ¹ì • ë¬¸ìì—´ë¡œ ëŒ€ì²´ 0 Male 1 Female 2 Genderless 3 Male Name: Gender, dtype: object ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰, ì—´ ì œê±°12345678dict_03 = &#123; &#x27;Score A&#x27; : [80, 90, np.nan, 80], &#x27;Score B&#x27; : [30, 45, np.nan, np.nan], &#x27;Score C&#x27; : [np.nan, 50, 80, 90], &#x27;Score D&#x27; : [50, 30, 80, 60]&#125;df3 = pd.DataFrame(dict_03)print(df3) Score A Score B Score C Score D 0 80.0 30.0 NaN 50 1 90.0 45.0 50.0 30 2 NaN NaN 80.0 80 3 80.0 NaN 90.0 60 123print(df3.dropna()) # axis: default 0print(&quot;\\n&quot;)print(df3.dropna(axis=1)) Score A Score B Score C Score D 1 90.0 45.0 50.0 30 Score D 0 50 1 30 2 80 3 60 ì´ìƒì¹˜ íƒì§€ ì¼ë°˜ì ìœ¼ë¡œ IQR(&#x3D; Q3 - Q1; ì‚¬ë¶„ìœ„ìˆ˜ë²”ìœ„)ë¥¼ í™œìš©í•˜ì—¬ íƒì§€ í•˜í•œ ê²½ê³„ê°’ : Q1 - IQR * 1.5 ìƒí•œ ê²½ê³„ê°’ : Q3 + IQR * 1.5 Box Plotìœ¼ë¡œë„ í™•ì¸ ê°€ëŠ¥ ì‹¤ë¬´ì—ì„œëŠ” ê° ë„ë©”ì¸(ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì—­)ë³„ë¡œ ê¸°ì¤€ ìƒì´ 1print(sales[[&#x27;Unit price&#x27;]].describe()) Unit price count 1000.000000 mean 55.672130 std 26.494628 min 10.080000 25% 32.875000 50% 55.230000 75% 77.935000 max 99.960000 1234567891011q1 = sales[&#x27;Unit price&#x27;].quantile(0.25)q3 = sales[&#x27;Unit price&#x27;].quantile(0.75)iqr = q3 - q1lim_q1 = q1 - 1.5 * IQRlim_q3 = q3 + 1.5 * IQRprint(tuple([lim_q1, lim_q3]))print(&quot;\\n&quot;)out_q1 = (sales[&#x27;Unit price&#x27;] &lt; lim_q1)out_q3 = (sales[&#x27;Unit price&#x27;] &gt; lim_q3)outliers = (sales[&#x27;Unit price&#x27;][out_q1 | out_q3])print(outliers) (-34.715, 145.525) Series([], Name: Unit price, dtype: float64) 12import matplotlib.pyplot as pltplt.boxplot(sales[&#x27;Unit price&#x27;]) &#123;&#39;boxes&#39;: [&lt;matplotlib.lines.Line2D at 0x7fefce5f93d0&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x7fefce5fe3d0&gt;, &lt;matplotlib.lines.Line2D at 0x7fefce5fe910&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fefce605410&gt;], &#39;means&#39;: [], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x7fefce5fee90&gt;], &#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x7fefce5f9910&gt;, &lt;matplotlib.lines.Line2D at 0x7fefce5f9e50&gt;]&#125;","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"pandas","slug":"pandas","permalink":"http://gonekng.github.io/tags/pandas/"}],"author":"Jiwon Kang"},{"title":"Pandas tutorial 1","slug":"Python/Tutorial/pd_tutorial_01","date":"2022-03-24T02:52:00.000Z","updated":"2022-10-05T05:39:54.625Z","comments":true,"path":"2022/03/24/Python/Tutorial/pd_tutorial_01/","link":"","permalink":"http://gonekng.github.io/2022/03/24/Python/Tutorial/pd_tutorial_01/","excerpt":"","text":"ë°ì´í„° ì „ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ì¤‘ë³µê°’ ì œê±° ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ì „ ë¬´ì‘ìœ„(MCAR) &#x2F; ë¬´ì‘ìœ„(MAR) &#x2F; ë¹„ë¬´ì‘ìœ„(NMAR) ì œê±°, ì¹˜í™˜, ëª¨ë¸ ê¸°ë°˜ ì²˜ë¦¬ ë“± ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬ ì‚­ì œ, ëŒ€ì²´, ë³€í™˜(ìŠ¤ì¼€ì¼ë§) ë“± Feature Engineering ì •ê·œí™”, í‘œì¤€í™”, ë¡œê·¸ë³€í™˜, ë²¡í„°í™” ë“± PCA, EFA ë“±ì„ í†µí•œ ì°¨ì› ì¶•ì†Œ Pandas ë¼ì´ë¸ŒëŸ¬ë¦¬Pandasì˜ ê¸°ë³¸ ìë£Œí˜• Series ê°ì²´, DataFrame ê°ì²´ Index: ìˆ«ì ë˜ëŠ” ë¬¸ì, ì¤‘ë³µX Series: Index &amp; Column 1ê°œ DataFrame: Index &amp; Column 2ê°œ ì´ìƒ ê° ê°ì²´ì— ë”°ë¼ ì‚¬ìš© ê°€ëŠ¥í•œ methodê°€ ìƒì´í•¨ Pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°12import pandas as pdprint(pd.__version__) 1.3.5 í…ŒìŠ¤íŠ¸12345# DataFrame ê°ì²´temp_dic = &#123;&#x27;col1&#x27; : [1, 2, 3], &#x27;col2&#x27; : [4, 5, 6]&#125;df = pd.DataFrame(temp_dic)print(df)print(type(df)) col1 col2 0 1 4 1 2 5 2 3 6 &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; 12345# Series ê°ì²´temp_dic = &#123;&#x27;a&#x27;:1, &#x27;b&#x27;:2, &#x27;c&#x27;:3&#125;ser = pd.Series(temp_dic)print(ser)print(type(ser)) a 1 b 2 c 3 dtype: int64 &lt;class &#39;pandas.core.series.Series&#39;&gt; êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ë™12from google.colab import drivedrive.mount(&#x27;/content/drive&#x27;) Mounted at /content/drive ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°123DATA_PATH = &#x27;/content/drive/MyDrive/Colab Notebooks/Data/Lemonade2016.csv&#x27;juice = pd.read_csv(DATA_PATH)print(juice) Date Location Lemon Orange Temperature Leaflets Price 0 7/1/2016 Park 97 67 70 90.0 0.25 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 5 7/6/2016 Beach 103 69 82 90.0 0.25 6 7/6/2016 Beach 103 69 82 90.0 0.25 7 7/7/2016 Beach 143 101 81 135.0 0.25 8 NaN Beach 123 86 82 113.0 0.25 9 7/9/2016 Beach 134 95 80 126.0 0.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 11 7/11/2016 Beach 162 120 83 135.0 0.25 12 7/12/2016 Beach 130 95 84 99.0 0.25 13 7/13/2016 Beach 109 75 77 99.0 0.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 16 7/16/2016 Beach 81 50 74 90.0 0.50 17 7/17/2016 Beach 115 76 77 126.0 0.50 18 7/18/2016 Park 131 92 81 122.0 0.50 19 7/19/2016 Park 122 85 78 113.0 0.50 20 7/20/2016 Park 71 42 70 NaN 0.50 21 7/21/2016 Park 83 50 77 90.0 0.50 22 7/22/2016 Park 112 75 80 108.0 0.50 23 7/23/2016 Park 120 82 81 117.0 0.50 24 7/24/2016 Park 121 82 82 117.0 0.50 25 7/25/2016 Park 156 113 84 135.0 0.50 26 7/26/2016 Park 176 129 83 158.0 0.35 27 7/27/2016 Park 104 68 80 99.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 12# ì „ì²´ì ì¸ êµ¬ì¡°, ê²°ì¸¡ì¹˜ ê°œìˆ˜, ë°ì´í„° íƒ€ì… íŒŒì•…juice.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB 123print(juice.head())print(&quot;-------------------------------------------------------------------&quot;)print(juice.tail()) Date Location Lemon Orange Temperature Leaflets Price 0 7/1/2016 Park 97 67 70 90.0 0.25 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 ------------------------------------------------------------------- Date Location Lemon Orange Temperature Leaflets Price 27 7/27/2016 Park 104 68 80 99.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 describe() : ê¸°ìˆ í†µê³„ëŸ‰ í™•ì¸ (intí˜•, floatí˜• ë³€ìˆ˜) value_counts() : ë²”ì£¼í˜• ë³€ìˆ˜ ë¹ˆë„ ìˆ˜ í™•ì¸ 12print(juice.describe())print(&quot;** type(juice.describe()) :&quot;, type(juice.describe())) # DataFrame ê°ì²´ë¡œ ë°˜í™˜ Lemon Orange Temperature Leaflets Price count 32.000000 32.000000 32.000000 31.000000 32.000000 mean 116.156250 80.000000 78.968750 108.548387 0.354687 std 25.823357 21.863211 4.067847 20.117718 0.113137 min 71.000000 42.000000 70.000000 68.000000 0.250000 25% 98.000000 66.750000 77.000000 90.000000 0.250000 50% 113.500000 76.500000 80.500000 108.000000 0.350000 75% 131.750000 95.000000 82.000000 124.000000 0.500000 max 176.000000 129.000000 84.000000 158.000000 0.500000 ** type(juice.describe()) : &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; 12print(juice[&#x27;Location&#x27;].value_counts())print(&quot;** type(juice.describe()) :&quot;, type(juice[&#x27;Location&#x27;].value_counts())) # Series ê°ì²´ë¡œ ë°˜í™˜ Beach 17 Park 15 Name: Location, dtype: int64 ** type(juice.describe()) : &lt;class &#39;pandas.core.series.Series&#39;&gt; ë°ì´í„° ë‹¤ë£¨ê¸°12juice[&#x27;Sold&#x27;] = 0juice.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 3 7/4/2016 Beach 134 99 76 98.0 0.25 0 4 7/5/2016 Beach 159 118 78 135.0 0.25 0 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-d7644e91-b826-4359-8387-1580b5266658 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-d7644e91-b826-4359-8387-1580b5266658&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12juice[&#x27;Sold&#x27;] = juice[&#x27;Lemon&#x27;] + juice[&#x27;Orange&#x27;]juice.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-2d21cec2-5539-4100-b9f5-ac71828a5d25 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-2d21cec2-5539-4100-b9f5-ac71828a5d25&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; ë§¤ì¶œì•¡(Revenue) &#x3D; ê°€ê²©(Price) * íŒë§¤ëŸ‰(Sold) 12juice[&#x27;Revenue&#x27;] = juice[&#x27;Price&#x27;] * juice[&#x27;Sold&#x27;]juice.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-506a14b7-9d00-4793-9a3f-5c54252c47b5 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-506a14b7-9d00-4793-9a3f-5c54252c47b5&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; í–‰ ë˜ëŠ” ì—´ ì œê±° : drop(axis&#x3D;0|1) axis&#x3D;0 : í–‰ ë°©í–¥(index) ì‹¤í–‰ axis&#x3D;1 : ì—´ ë°©í–¥(column) ì‹¤í–‰ 12juice_col_drop = juice.drop(&#x27;Sold&#x27;, axis=1)juice_col_drop.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 69.25 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-4ee85edb-efbb-47d3-84c6-8b0cab09eb0f button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-4ee85edb-efbb-47d3-84c6-8b0cab09eb0f&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12juice_ind_drop = juice.drop(2, axis=0)juice_ind_drop.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-8329c7e5-dc41-41e9-aa8f-d31cdc115b69 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-8329c7e5-dc41-41e9-aa8f-d31cdc115b69&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; ë°ì´í„° ì¸ë±ì‹±1juice[5:10] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-e5a46c70-33e1-4ae6-868e-0fbcf1b0c121 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-e5a46c70-33e1-4ae6-868e-0fbcf1b0c121&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; boolean ê°’ í™œìš© (ì¡°ê±´ì‹)12# Location ê°’ì´ Parkì¸ ê²½ìš°juice[juice[&#x27;Location&#x27;] == &#x27;Park&#x27;] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 20 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-6440b49e-9b42-4a3b-9edd-37f9b7d5b0a6 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-6440b49e-9b42-4a3b-9edd-37f9b7d5b0a6&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12# Leaflets ê°’ì´ 120 ì´ìƒì¸ ê²½ìš°juice[juice[&#x27;Leaflets&#x27;] &gt;= 120] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-92086f96-d263-4c70-85ec-af04ffb445c1 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-92086f96-d263-4c70-85ec-af04ffb445c1&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; iloc vs loc iloc : index ê¸°ë°˜, ì†ë„â†‘, ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•© syntax : df.iloc[row_index, column_index] loc : label or boolean(ì¡°ê±´ì‹) ê¸°ë°˜, ê°€ë…ì„±â†‘ syntax : df.loc[row_label, column_label] 12%%timejuice.iloc[0:3, 0:2] # í•´ë‹¹ ì¸ë±ìŠ¤ ë¯¸í¬í•¨ CPU times: user 514 Âµs, sys: 40 Âµs, total: 554 Âµs Wall time: 523 Âµs .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-219659e3-19a4-418f-84d6-7d01a8076e00 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-219659e3-19a4-418f-84d6-7d01a8076e00&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12%%timejuice.loc[0:2, [&quot;Date&quot;,&#x27;Location&#x27;]] # í•´ë‹¹ ë¼ë²¨ëª… í¬í•¨ CPU times: user 1.67 ms, sys: 0 ns, total: 1.67 ms Wall time: 5.19 ms .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-5e3530fd-7c31-4a6f-8a4f-dea8d6d42e78 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-5e3530fd-7c31-4a6f-8a4f-dea8d6d42e78&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1234# juice.iloc[juice[&#x27;Leaflets&#x27;] &gt;= 130, [&#x27;Date&#x27;, &#x27;Location&#x27;, &#x27;Leaflets&#x27;]]# Error: iLocation based boolean indexing on an integer type is not availablejuice.loc[juice[&#x27;Leaflets&#x27;] &gt;= 130, [&#x27;Date&#x27;, &#x27;Location&#x27;, &#x27;Leaflets&#x27;]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Leaflets 4 7/5/2016 Beach 135.0 7 7/7/2016 Beach 135.0 10 7/10/2016 Beach 131.0 11 7/11/2016 Beach 135.0 25 7/25/2016 Park 135.0 26 7/26/2016 Park 158.0 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-80998d16-2836-479c-9ea3-75efcac52299 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-80998d16-2836-479c-9ea3-75efcac52299&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; ë°ì´í„° ì •ë ¬ sort_values() í•¨ìˆ˜ 12# Revenue ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœjuice.sort_values(by=[&#x27;Revenue&#x27;]).head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-4d6ed323-d5df-47ed-893d-db57c2b39110 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-4d6ed323-d5df-47ed-893d-db57c2b39110&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12# Revenue ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœjuice.sort_values(by=[&#x27;Revenue&#x27;], ascending = False).head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-ecf0c228-c2c7-4d62-aa08-e194d9fd1e4e button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-ecf0c228-c2c7-4d62-aa08-e194d9fd1e4e&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 12# Price ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ, Temperature ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœjuice.sort_values(by=[&#x27;Price&#x27;, &#x27;Temperature&#x27;], ascending = [False, True]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 20 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-56042f49-547e-4908-99b7-0e79a9445a3d button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-56042f49-547e-4908-99b7-0e79a9445a3d&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 123# indexë¥¼ ìƒˆë¡œ ì§€ì •í•´ì„œ ìƒˆë¡œìš´ ê°ì²´ë¡œ ì €ì¥juice2 = juice.sort_values(by=[&#x27;Price&#x27;, &#x27;Temperature&#x27;], ascending = [False, True]).reset_index(drop=True)juice2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 0 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 1 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 2 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 3 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 4 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 5 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 6 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 7 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 8 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 9 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 10 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 11 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 12 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 13 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 14 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 15 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 16 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 17 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 18 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 19 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 20 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 21 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 22 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 23 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 24 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 25 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 26 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 27 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 28 NaN Beach 123 86 82 113.0 0.25 209 52.25 29 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 30 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 31 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-95b0ec19-306b-4312-a2fb-6c6bf238bb16 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-95b0ec19-306b-4312-a2fb-6c6bf238bb16&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; ë°ì´í„° ê·¸ë£¹í™” groupby() í•¨ìˆ˜ ê·¸ë£¹ë³„ ì§‘ê³„í•¨ìˆ˜ë¥¼ í†µí•´ í”¼ë²—í…Œì´ë¸” ìƒì„± 1juice.groupby(by=&#x27;Location&#x27;).count() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Date Lemon Orange Temperature Leaflets Price Sold Revenue Location Beach 16 17 17 17 17 17 17 17 Park 15 15 15 15 14 15 15 15 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-464f987e-371e-4805-8b50-ee52bdc321e8 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-464f987e-371e-4805-8b50-ee52bdc321e8&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt; 1234import numpy as np# Location ê·¸ë£¹ë³„ Lemon, Orange ë³€ìˆ˜ì— ëŒ€í•œ ì§‘ê³„í•¨ìˆ˜juice.groupby(by=&#x27;Location&#x27;)[[&#x27;Lemon&#x27;,&#x27;Orange&#x27;]].agg([max, min, sum, np.mean]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead tr th &#123; text-align: left; &#125; .dataframe thead tr:last-of-type th &#123; text-align: right; &#125; Lemon Orange max min sum mean max min sum mean Location Beach 162 76 2020 118.823529 120 47 1402 82.470588 Park 176 71 1697 113.133333 129 42 1158 77.200000 &lt;svg xmlns&#x3D;â€http://www.w3.org/2000/svg&quot; height&#x3D;â€24pxâ€viewBox&#x3D;â€0 0 24 24â€ width&#x3D;â€24pxâ€&gt; .colab-df-container { display:flex; flex-wrap:wrap; gap: 12px; } .colab-df-convert { background-color: #E8F0FE; border: none; border-radius: 50%; cursor: pointer; display: none; fill: #1967D2; height: 32px; padding: 0 0 0 0; width: 32px; } .colab-df-convert:hover { background-color: #E2EBFA; box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15); fill: #174EA6; } [theme=dark] .colab-df-convert { background-color: #3B4455; fill: #D2E3FC; } [theme=dark] .colab-df-convert:hover { background-color: #434B5C; box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15); filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3)); fill: #FFFFFF; } &lt;script&gt; const buttonEl = document.querySelector(&#39;#df-1d771570-530b-4471-945e-e1db8f8b3457 button.colab-df-convert&#39;); buttonEl.style.display = google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;; async function convertToInteractive(key) &#123; const element = document.querySelector(&#39;#df-1d771570-530b-4471-945e-e1db8f8b3457&#39;); const dataTable = await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;, [key], &#123;&#125;); if (!dataTable) return; const docLinkHtml = &#39;Like what you see? Visit the &#39; + &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39; + &#39; to learn more about interactive tables.&#39;; element.innerHTML = &#39;&#39;; dataTable[&#39;output_type&#39;] = &#39;display_data&#39;; await google.colab.output.renderOutput(dataTable, element); const docLink = document.createElement(&#39;div&#39;); docLink.innerHTML = docLinkHtml; element.appendChild(docLink); &#125; &lt;/script&gt; &lt;/div&gt;","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"pandas","slug":"pandas","permalink":"http://gonekng.github.io/tags/pandas/"}],"author":"Jiwon Kang"},{"title":"Numpy tutorial","slug":"Python/Tutorial/np_tutorial","date":"2022-03-24T02:51:00.000Z","updated":"2022-10-05T05:39:54.385Z","comments":true,"path":"2022/03/24/Python/Tutorial/np_tutorial/","link":"","permalink":"http://gonekng.github.io/2022/03/24/Python/Tutorial/np_tutorial/","excerpt":"","text":"íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜in R (ì½”ë“œì—ì„œ ì‹¤í–‰) install.package(â€œíŒ¨í‚¤ì§€ëª…â€) library(íŒ¨í‚¤ì§€ëª…) in Python (í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰) ë°©ë²•1. conda ì„¤ì¹˜ (ì£¼ ì‚¬ìš©ëª©ì : ë°ì´í„° ê³¼í•™) ì•„ë‚˜ì½˜ë‹¤ ì„¤ì¹˜ í›„ì— conda ì„¤ì¹˜ ê°€ëŠ¥ ë°©ë²•2. pip ì„¤ì¹˜ (ê°œë°œ, ë°ì´í„° ê³¼í•™, ê·¸ ì™¸) ì•„ë‚˜ì½˜ë‹¤ ì—†ì´ë„ pythonë§Œ ì„¤ì¹˜í•˜ë©´ ë¨ NumPy ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì´ì¬ì˜ ëŒ€í‘œì ì¸ ë°°ì—´ ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì´ì¬ ìˆ˜ì¹˜ ì—°ì‚°ê³¼ ê´€ë ¨ëœ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ê¸°ë³¸ scikit learn, TensorFlow, PyTorch ë“±ë“± .array, .reshape, .matlib ë“±ë“± ë‹¤ì–‘í•œ ë©”ì„œë“œ í™œìš© Numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°12import numpy as npprint(np.__version__) 1.21.5 NumPy ë°°ì—´ ìƒì„±ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì—´ë¡œ ë³€í™˜ NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥ 1234567temp = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]print(temp)print(type(temp))arr = np.array(temp)print(arr)print(type(arr)) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] &lt;class &#39;list&#39;&gt; [ 1 2 3 4 5 6 7 8 9 10] &lt;class &#39;numpy.ndarray&#39;&gt; NumPy ë°°ì—´ì—ë„ ì¸ë±ì‹±, ìŠ¬ë¼ì´ì‹± ë™ì¼í•˜ê²Œ ì ìš© 123print(arr[4])print(arr[3:7])print(arr[::2]) 5 [4 5 6 7] [1 3 5 7 9] NumPyë¥¼ í†µí•œ ê¸°ì´ˆ í†µê³„ í•¨ìˆ˜ ì‚¬ìš© 123456print(&quot;sum:&quot;, np.sum(arr))print(&quot;mean:&quot;, np.mean(arr))print(&quot;median:&quot;, np.median(arr))print(&quot;min:&quot;, np.min(arr))print(&quot;max:&quot;, np.max(arr))print(&quot;std:&quot;, np.std(arr)) sum: 55 mean: 5.5 median: 5.5 min: 1 max: 10 std: 2.8722813232690143 ì‚¬ì¹™ì—°ì‚°123456789math_scores = [90, 80, 88]english_scores = [80, 70, 90]total_scores = math_scores + english_scores # ë‹¨ìˆœí•œ ë¦¬ìŠ¤íŠ¸ ì—°ê²° ìˆ˜í–‰print(total_scores)math_arr = np.array(math_scores)english_arr = np.array(english_scores)total_arr = math_arr + english_arr # ê° ìš”ì†Œì˜ ë§ì…ˆ ìˆ˜í–‰print(total_arr) [90, 80, 88, 80, 70, 90] [170 150 178] 123456789arr1 = np.array([2, 5, 4])arr2 = np.array([4, 2, 3])# ì‚¬ì¹™ì—°ì‚°print(&quot;ë§ì…ˆ:&quot;, np.add(arr1, arr2))print(&quot;ëº„ì…ˆ:&quot;, np.subtract(arr1, arr2))print(&quot;ê³±ì…ˆ:&quot;, np.multiply(arr1, arr2))print(&quot;ë‚˜ëˆ—ì…ˆ:&quot;, np.divide(arr1, arr2))print(&quot;ê±°ë“­ì œê³±:&quot;, np.power(arr1, arr2)) ë§ì…ˆ: [6 7 7] ëº„ì…ˆ: [-2 3 1] ê³±ì…ˆ: [ 8 10 12] ë‚˜ëˆ—ì…ˆ: [0.5 2.5 1.33333333] ê±°ë“­ì œê³±: [16 25 64] ì†Œìˆ˜ì  ì²˜ë¦¬123456# ì†Œìˆ˜ì  ì ˆì‚­temp_arr = np.trunc([-1.23, 1.23])print(temp_arr)temp_arr = np.fix([-1.23, 1.23])print(temp_arr) [-1. 1.] [-1. 1.] 1234567891011121314# ì˜¬ë¦¼temp_arr = np.ceil([-1.23789, 1.23789])print(temp_arr)# ë‚´ë¦¼temp_arr = np.floor([-1.23789, 1.23789])print(temp_arr)# ë°˜ì˜¬ë¦¼temp_arr = np.around([-1.23789, 1.23789], 2)print(temp_arr)temp_arr = np.around([-1.23789, 1.23789], 4)print(temp_arr) [-1. 2.] [-2. 1.] [-1.24 1.24] [-1.2379 1.2379] ë°°ì—´ì˜ í˜•íƒœ ë° ì°¨ì› 0ì°¨ì›ë¶€í„° 3ì°¨ì›ê¹Œì§€ ìƒì„±í•˜ëŠ” ë°©ë²• .shape : axis ì¶• ê¸°ì¤€ìœ¼ë¡œ ë°°ì—´ì˜ í˜•íƒœ ë°˜í™˜ 123456# 0ì°¨ì› ë°°ì—´temp_arr = np.array(20)print(temp_arr)print(type(temp_arr))print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_arr.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_arr.ndim) 20 &lt;class &#39;numpy.ndarray&#39;&gt; ë°°ì—´ì˜ í˜•íƒœ: () ë°°ì—´ì˜ ì°¨ì›: 0 123456# 1ì°¨ì› ë°°ì—´temp_arr = np.array([1,2,3,5])print(temp_arr)print(type(temp_arr))print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_arr.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_arr.ndim) [1 2 3 5] &lt;class &#39;numpy.ndarray&#39;&gt; ë°°ì—´ì˜ í˜•íƒœ: (4,) ë°°ì—´ì˜ ì°¨ì›: 1 123456# 2ì°¨ì› ë°°ì—´temp_arr = np.array([[1,2,3,5],[4,5,1,6],[9,0,2,3]])print(temp_arr)print(type(temp_arr))print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_arr.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_arr.ndim) [[1 2 3 5] [4 5 1 6] [9 0 2 3]] &lt;class &#39;numpy.ndarray&#39;&gt; ë°°ì—´ì˜ í˜•íƒœ: (3, 4) ë°°ì—´ì˜ ì°¨ì›: 2 1234567# 3ì°¨ì› ë°°ì—´temp_arr = np.array([[[1,2,3,5],[4,5,1,6],[9,0,2,3]], [[1,1,2,3],[2,3,1,7],[4,9,5,6]]])print(temp_arr)print(type(temp_arr))print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_arr.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_arr.ndim) [[[1 2 3 5] [4 5 1 6] [9 0 2 3]] [[1 1 2 3] [2 3 1 7] [4 9 5 6]]] &lt;class &#39;numpy.ndarray&#39;&gt; ë°°ì—´ì˜ í˜•íƒœ: (2, 3, 4) ë°°ì—´ì˜ ì°¨ì›: 3 123456# parameterë¥¼ í™œìš©í•œ ë°°ì—´ì˜ ìµœì†Œ ì°¨ì› ëª…ì‹œtemp_arr = np.array([1,2,3,4], ndmin=2)print(temp_arr)print(type(temp_arr))print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_arr.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_arr.ndim) [[1 2 3 4]] &lt;class &#39;numpy.ndarray&#39;&gt; ë°°ì—´ì˜ í˜•íƒœ: (1, 4) ë°°ì—´ì˜ ì°¨ì›: 2 ë°°ì—´ì„ ìƒì„±í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ë²•12345temp_arr = np.arange(5) # [0:4]print(temp_arr)temp_arr = np.arange(1,11,3) # [1:11:3]print(temp_arr) [0 1 2 3 4] [ 1 4 7 10] 1234zero_arr = np.zeros((2,3)) # 0ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§„ ë°°ì—´print(zero_arr)print(type(zero_arr))print(&quot;ë°ì´í„° íƒ€ì…:&quot;, zero_arr.dtype) [[0. 0. 0.] [0. 0. 0.]] &lt;class &#39;numpy.ndarray&#39;&gt; ë°ì´í„° íƒ€ì…: float64 123456789temp_arr = np.ones((2,3)) # 1ë¡œë§Œ ì´ë£¨ì–´ì§„ ë°°ì—´print(temp_arr)print(type(temp_arr))print(&quot;ë°ì´í„° íƒ€ì…:&quot;, temp_arr.dtype)temp_arr = np.ones((2,3), dtype=&quot;int32&quot;) # ìì²´ì ì¸ ë°ì´í„° í˜•ë³€í™˜print(temp_arr)print(type(temp_arr))print(&quot;ë°ì´í„° íƒ€ì…:&quot;, temp_arr.dtype) [[1. 1. 1.] [1. 1. 1.]] &lt;class &#39;numpy.ndarray&#39;&gt; ë°ì´í„° íƒ€ì…: float64 [[1 1 1] [1 1 1]] &lt;class &#39;numpy.ndarray&#39;&gt; ë°ì´í„° íƒ€ì…: int32 12345678910111213141516temp_arr = np.ones((2,6))print(temp_arr)print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_arr.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_arr.ndim)print(&quot;\\n&quot;)temp_res = temp_arr.reshape(3,4)print(temp_res)print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_res.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_res.ndim)print(&quot;\\n&quot;)temp_res2 = temp_arr.reshape(2,2,3)print(temp_res2)print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_res2.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_res2.ndim) [[1 1 1 1 1 1] [1 1 1 1 1 1]] ë°°ì—´ì˜ í˜•íƒœ: (2, 6) ë°°ì—´ì˜ ì°¨ì›: 2 [[1 1 1 1] [1 1 1 1] [1 1 1 1]] ë°°ì—´ì˜ í˜•íƒœ: (3, 4) ë°°ì—´ì˜ ì°¨ì›: 2 [[[1 1 1] [1 1 1]] [[1 1 1] [1 1 1]]] ë°°ì—´ì˜ í˜•íƒœ: (2, 2, 3) ë°°ì—´ì˜ ì°¨ì›: 3 12345678temp_arr = np.ones((12,6))temp_res = temp_arr.reshape(3,-1)print(temp_res)print(&quot;ë°°ì—´ì˜ í˜•íƒœ:&quot;, temp_res.shape)print(&quot;ë°°ì—´ì˜ ì°¨ì›:&quot;, temp_res.ndim)# temp_res2 = temp_arr.reshape(5,-1)# ValueError: cannot reshape array of size 72 into shape (5,newaxis) [[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]] ë°°ì—´ì˜ í˜•íƒœ: (3, 24) ë°°ì—´ì˜ ì°¨ì›: 2 NumPy ì¡°ê±´ì‹ ì¡°ê±´ì‹ì´ í•˜ë‚˜ì¼ ë•Œ: np.where 12345temp_arr = np.arange(10)print(temp_arr)# 5ë³´ë‹¤ í° ê°’ì€ ê¸°ì¡´ ê°’ * 10print(np.where(temp_arr &gt; 5, temp_arr * 10, temp_arr)) [0 1 2 3 4 5 6 7 8 9] [ 0 1 2 3 4 5 60 70 80 90] 12345temp_arr = np.arange(21)print(temp_arr)# 10ë³´ë‹¤ ì‘ì€ ê°’ì€ ê¸°ì¡´ ê°’ * 10print(np.where(temp_arr &lt; 10, temp_arr * 10, temp_arr)) [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [ 0 10 20 30 40 50 60 70 80 90 10 11 12 13 14 15 16 17 18 19 20] ì¡°ê±´ì‹ì´ 2ê°œ ì´ìƒì¼ ë•Œ: np.select 1234567temp_arr = np.arange(10)print(temp_arr)# 5ë³´ë‹¤ í° ê°’ì€ ê¸°ì¡´ ê°’ * 2, 2ë³´ë‹¤ ì‘ì€ ê°’ì€ ê¸°ì¡´ ê°’ + 100condlist = [temp_arr &gt; 5, temp_arr &lt; 2] # The list of conditionschoicelist = [temp_arr * 2, temp_arr + 100] # The list of outputsnp.select(condlist, choicelist, default = temp_arr) [0 1 2 3 4 5 6 7 8 9] array([100, 101, 2, 3, 4, 5, 12, 14, 16, 18]) NumPy Broadcasting ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ë°°ì—´ì„ ê³„ì‚°í•  ë•Œì˜ ê¸°ë³¸ì ì¸ ê·œì¹™ url : https://numpy.org/doc/stable/user/basics.broadcasting.html?highlight=broadcasting 1","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"numpy","slug":"numpy","permalink":"http://gonekng.github.io/tags/numpy/"}],"author":"Jiwon Kang"},{"title":"Python Basic 4","slug":"Python/Basic/python_basic_4","date":"2022-03-22T08:31:40.000Z","updated":"2022-10-05T05:39:51.382Z","comments":true,"path":"2022/03/22/Python/Basic/python_basic_4/","link":"","permalink":"http://gonekng.github.io/2022/03/22/Python/Basic/python_basic_4/","excerpt":"","text":"í´ë˜ìŠ¤(Class) ëª©ì  : ì½”ë“œì˜ ê°„ê²°í™”, ì½”ë“œì˜ ì¬ì‚¬ìš©, ìœ ì§€ë³´ìˆ˜ ìš©ì´ ì—¬ëŸ¬ í´ë˜ìŠ¤ê°€ ëª¨ì—¬ì„œ í•˜ë‚˜ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ë¨ ì¥ê³  &#x2F; ì›¹ê°œë°œ &#x2F; ë¨¸ì‹ ëŸ¬ë‹ &#x2F; ì‹œê°í™” &#x2F; ì „ì²˜ë¦¬ í´ë˜ìŠ¤ëª…ì€ ëŒ€ë¬¸ìë¡œ ì‹œì‘í•´ì•¼ í•¨ 1234567891011121314151617class Person: # class attribute (ì„ íƒ) country = &quot;korean&quot; # instance attribute (í•„ìˆ˜) def __init__(self, name, age): self.name = name self.age = ageif __name__ == &quot;__main__&quot;: kim = Person(&quot;Kim&quot;, 30) lee = Person(&quot;Lee&quot;, 28) # access class attribute print(&quot;Kimì€ &#123;&#125;&quot;.format(kim.__class__.country)) print(&quot;LeeëŠ” &#123;&#125;&quot;.format(lee.__class__.country)) Kimì€ korean LeeëŠ” korean ì¸ìŠ¤í„´ìŠ¤ ë©”ì„œë“œ ìƒì„± list.append(), list.extend() 123456789101112131415161718192021class Person: # class attribute (ì„ íƒ) country = &quot;korean&quot; # instance attribute (í•„ìˆ˜) def __init__(self, name, age): self.name = name self.age = age # instance method ì •ì˜ def singing(self, songtitle): return &quot;&#123;&#125;: &#x27;&#123;&#125;&#x27; ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤.&quot;.format(self.name, songtitle)if __name__ == &quot;__main__&quot;: kim = Person(&quot;Kim&quot;, 30) lee = Person(&quot;Lee&quot;, 28) # call instance method print(kim.singing(&quot;creep&quot;)) print(lee.singing(&quot;peaches&quot;)) Kim: &#39;creep&#39; ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤. Lee: &#39;peaches&#39; ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤. í´ë˜ìŠ¤ ìƒì†12345678910111213141516171819202122232425262728293031323334353637383940class Parent: # init constructor def __init__(self, name, age): self.name = name self.age = age # instance method def whoAmI(self): print(&quot;I am Parent!&quot;) def singing(self, songtitle): return &quot;&#123;&#125;: &#x27;&#123;&#125;&#x27; ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤.&quot;.format(self.name, songtitle) def dancing(self): return &quot;&#123;&#125;: ì¶¤ì„ ì¶¥ë‹ˆë‹¤.&quot;.format(self.name)class Child(Parent): # instance attribute def __init__(self, name, age): super().__init__(name, age) # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ìƒì„±ì ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸° print(&quot;Child Class On.&quot;) # instance method def whoAmI(self): print(&quot;I am Child!&quot;) def studying(self, subject): return &quot;&#123;&#125; : &#123;&#125; ê³µë¶€ë¥¼ í•©ë‹ˆë‹¤.&quot;.format(self.name, subject)if __name__ == &quot;__main__&quot;: child_kim = Child(&quot;kim&quot;, 13) parent_kim = Parent(&quot;kim&quot;, 49) child_kim.whoAmI() parent_kim.whoAmI() print(parent_kim.dancing()) # print(parent_kim.studying()) -&gt; AttributeError ë°œìƒ print(child_kim.singing(&quot;fake love&quot;)) print(child_kim.studying(&quot;math&quot;)) Child Class On. I am Child! I am Parent! kim: ì¶¤ì„ ì¶¥ë‹ˆë‹¤. kim: &#39;fake love&#39; ë…¸ë˜ë¥¼ ë¶€ë¦…ë‹ˆë‹¤. kim : math ê³µë¶€ë¥¼ í•©ë‹ˆë‹¤. 123456789101112131415161718192021222324252627class TV: def __init__(self): # private variable (ì™¸ë¶€ ì ‘ê·¼ ë¶ˆê°€ëŠ¥) self.__maxprice = 500 def sell(self): print(&quot;Selling Price: &#123;&#125;&quot;.format(self.__maxprice)) # set method, get method def setMaxPrice(self, price): self.__maxprice = price print(&quot;Price Updated&quot;) def getMaxPrice(self): return self.__maxprice if __name__==&quot;__main__&quot;: tv = TV() tv.sell() # ê°•ì œë¡œ ê°’ì„ ë³€ê²½í•  ìˆ˜ ì—†ìŒ tv.__maxprice = 100 tv.sell() # ë³„ë„ì˜ methodë¥¼ í†µí•´ ë³€ê²½ ê°€ëŠ¥ tv.setMaxPrice(400) tv.sell() Selling Price: 500 Selling Price: 500 Price Updated Selling Price: 400 í´ë˜ìŠ¤ ë‚´ë¶€ ì¡°ê±´ë¬¸ init constructor 1234567891011121314151617181920212223242526272829303132class Employee: # init constructor def __init__(self, name, salary = 0): self.name = name # public variable (ì™¸ë¶€ ì ‘ê·¼ ê°€ëŠ¥) if salary &gt; 0: self.salary = salary else: self.salary = 0 print(&quot;ê¸‰ì—¬ëŠ” 0ì›ì´ ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.&quot;) def update_salary(self, amount): self.salary += amount def weekly_salary(self): return int(self.salary / 7)if __name__==&quot;__main__&quot;: emp1 = Employee(&quot;David&quot;, -50000) print(&quot;&#123;&#125;ì˜ ê¸‰ì—¬ëŠ” &#123;&#125;ì›ì…ë‹ˆë‹¤.&quot;.format(emp1.name, emp1.salary)) emp1.salary = emp1.salary + 1500 print(&quot;&#123;&#125;ì˜ ê¸‰ì—¬ëŠ” &#123;&#125;ì›ì…ë‹ˆë‹¤.&quot;.format(emp1.name, emp1.salary)) emp1.update_salary(3000) print(&quot;&#123;&#125;ì˜ ê¸‰ì—¬ëŠ” &#123;&#125;ì›ì…ë‹ˆë‹¤.&quot;.format(emp1.name, emp1.salary)) week_salary = emp1.weekly_salary() print(&quot;&#123;&#125;ì˜ ì£¼ ê¸‰ì—¬ëŠ” &#123;&#125;ì›ì…ë‹ˆë‹¤.&quot;.format(emp1.name, week_salary)) ê¸‰ì—¬ëŠ” 0ì›ì´ ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”. Davidì˜ ê¸‰ì—¬ëŠ” 0ì›ì…ë‹ˆë‹¤. Davidì˜ ê¸‰ì—¬ëŠ” 1500ì›ì…ë‹ˆë‹¤. Davidì˜ ê¸‰ì—¬ëŠ” 4500ì›ì…ë‹ˆë‹¤. Davidì˜ ì£¼ ê¸‰ì—¬ëŠ” 642ì›ì…ë‹ˆë‹¤. í´ë˜ìŠ¤ Docstring12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Person: &quot;&quot;&quot; ì‚¬ëŒì„ í‘œí˜„í•˜ëŠ” í´ë˜ìŠ¤ *** Attributes ---------- name: str Name of the person age: int Age of the person Methods ------- info(additional=&quot;&quot;): Prints the person&#x27;s name and age &quot;&quot;&quot; def __init__(self, name, age): &quot;&quot;&quot; Constructs all the neccessary attributes for the person object Parameters ---------- name: str Name of the person age: int Age of the person &quot;&quot;&quot; self.name = name self.age = age def info(self, additional=None): &quot;&quot;&quot; Prints the person&#x27;s information Parameters ---------- additional: str, optional more info to be diplayed (Default is None) / A, B, C Returns ------- None &quot;&quot;&quot; print(f&#x27;My name is &#123;self.name&#125;. I am &#123;self.age&#125; years old. &#x27; + additional)if __name__==&quot;__main__&quot;: print(Person.__doc__) person = Person(&quot;Jiwon&quot;, age = 27) person.info(&quot;I wanna be a data analyst.&quot;) ì‚¬ëŒì„ í‘œí˜„í•˜ëŠ” í´ë˜ìŠ¤ *** Attributes ---------- name: str Name of the person age: int Age of the person Methods ------- info(additional=&quot;&quot;): Prints the person&#39;s name and age My name is Jiwon. I am 27 years old. I wanna be a data analyst.","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"}],"author":"Jiwon Kang"},{"title":"Python Basic 3","slug":"Python/Basic/python_basic_3","date":"2022-03-22T08:31:10.000Z","updated":"2022-10-05T05:39:51.283Z","comments":true,"path":"2022/03/22/Python/Basic/python_basic_3/","link":"","permalink":"http://gonekng.github.io/2022/03/22/Python/Basic/python_basic_3/","excerpt":"","text":"ê¸°ì´ˆ ë¬¸ë²• ë¦¬ë·°ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë”•ì…”ë„ˆë¦¬1234567891011121314# ë¦¬ìŠ¤íŠ¸book_list = [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]print(book_list)# append, extend, insert, remove, pop, etc# íŠœí”Œbook_tuple = (&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;)print(book_tuple)# ìˆ˜ì •, ì‚­ì œ ë¶ˆê°€ëŠ¥# ë”•ì…”ë„ˆë¦¬book_dictionary = &#123;&quot;title&quot; : [&quot;A&quot;, &quot;B&quot;], &quot;year&quot; : [2011, 2002]&#125;print(book_dictionary)# keys(), values(), items(), get() [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] (&#39;A&#39;, &#39;B&#39;, &#39;C&#39;) &#123;&#39;title&#39;: [&#39;A&#39;, &#39;B&#39;], &#39;year&#39;: [2011, 2002]&#125; ì¡°ê±´ë¬¸ &amp; ë°˜ë³µë¬¸123456if True: print(&quot;ì½”ë“œ ì‹¤í–‰&quot;) # ë“¤ì—¬ì“°ê¸° ì£¼ì˜elif True: print(&quot;ì½”ë“œ ì‹¤í–‰&quot;)else: print(&quot;ì½”ë“œ ì‹¤í–‰&quot;) 12for i in range(3): print(i+1, &quot;ì•ˆë…•í•˜ì„¸ìš”&quot;) 1 ì•ˆë…•í•˜ì„¸ìš” 2 ì•ˆë…•í•˜ì„¸ìš” 3 ì•ˆë…•í•˜ì„¸ìš” 123456789101112131415161718book_list = [&quot;R&quot;, &quot;Python&quot;]for book in book_list: print(book, end=&quot; &quot;)print(&quot;\\n&quot;)strings01 = &quot;Hello&quot;for char in strings01: print(char, end=&quot; &quot;)num_tuple = (1, 2, 3, 4)for num in num_tuple: print(num, end=&quot; &quot;)print(&quot;\\n&quot;)num_dict = &#123;&quot;A&quot;:1, &quot;B&quot;:2&#125;for num in num_dict: print(num, end=&quot; &quot;) # key ê°’ print(num_dict[num], end=&quot; &quot;) # value ê°’ R Python H e l l o 1 2 3 4 A 1 B 2 ë°˜ë³µë¬¸ì˜ í•„ìš”ì„±123456789name_list = [&quot;ìš”êµ¬ë¥´íŠ¸&quot;, &quot;ìš°ìœ &quot;, &quot;ì½œë¼&quot;, &quot;ì‚¬ì´ë‹¤&quot;, &quot;ê³¼ì&quot;]price_list = [1000, 1500, 1200, 1200, 1000]quantity_list = [5, 3, 1, 2, 4]for i in range(len(name_list)): name = name_list[i] sales = price_list[i] * quantity_list[i] print(name + &quot;ì˜ ë§¤ì¶œì•¡ : &quot; + str(sales) + &quot;ì›&quot;) ìš”êµ¬ë¥´íŠ¸ì˜ ë§¤ì¶œì•¡ : 5000ì› ìš°ìœ ì˜ ë§¤ì¶œì•¡ : 4500ì› ì½œë¼ì˜ ë§¤ì¶œì•¡ : 1200ì› ì‚¬ì´ë‹¤ì˜ ë§¤ì¶œì•¡ : 2400ì› ê³¼ìì˜ ë§¤ì¶œì•¡ : 4000ì› while ì¡°ê±´ì‹ì´ ë“¤ì–´ê°„ ë°˜ë³µë¬¸ 1234count = 5while count &gt; 0: print(count, &quot;ì•ˆë…•í•˜ì„¸ìš”.&quot;) count = count - 1 5 ì•ˆë…•í•˜ì„¸ìš”. 4 ì•ˆë…•í•˜ì„¸ìš”. 3 ì•ˆë…•í•˜ì„¸ìš”. 2 ì•ˆë…•í•˜ì„¸ìš”. 1 ì•ˆë…•í•˜ì„¸ìš”. ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í•¸ì…˜ for-loop ë°˜ë³µë¬¸ì„ í•œ ì¤„ë¡œ ì²˜ë¦¬ 123456789letters = []for char in &quot;helloworld&quot;: letters.append(char)print(&quot;for-loop ë°˜ë³µë¬¸ ì‚¬ìš© :&quot;)print(&quot;\\t&quot;, letters)letters2 = [char for char in &quot;helloworld&quot;]print(&quot;ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í•¸ì…˜ ì‚¬ìš© :&quot;)print(&quot;\\t&quot;, letters2) for-loop ë°˜ë³µë¬¸ ì‚¬ìš© : [&#39;h&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39;w&#39;, &#39;o&#39;, &#39;r&#39;, &#39;l&#39;, &#39;d&#39;] ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í•¸ì…˜ ì‚¬ìš© : [&#39;h&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39;w&#39;, &#39;o&#39;, &#39;r&#39;, &#39;l&#39;, &#39;d&#39;] 1234567891011121314# ì¤‘ì²© ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œmy_list = [[10],[20,30]]print(my_list)# for-loop ì¤‘ì²© ë°˜ë³µë¬¸ ì‚¬ìš©flattened_list1 = []for value_list in my_list: for value in value_list: flattened_list1.append(value)print(&quot;ì¤‘ì²© ë°˜ë³µë¬¸ ì‚¬ìš© :&quot;, flattened_list1)# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í•¸ì…˜ ì‚¬ìš©flattened_list2 = [value for value_list in my_list for value in value_list]print(&quot;ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í•¸ì…˜ ì‚¬ìš© :&quot;, flattened_list2) [[10], [20, 30]] ì¤‘ì²© ë°˜ë³µë¬¸ ì‚¬ìš© : [10, 20, 30] ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í•¸ì…˜ ì‚¬ìš© : [10, 20, 30] ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜1234567891011121314151617181920def plus(a,b): c = a + b return cdef minus(a,b): c = a - b return cdef multiply(a,b): c = a * b return cdef divide(a,b): c = a / b return cprint(plus(1,5))print(minus(10,3))print(multiply(2,4))print(divide(8,2)) 6 7 8 4.0 basic.pyë¡œ ì €ì¥í•  ë•Œ ì˜ˆì‹œ 1!which python /usr/local/bin/python 12345678910111213# /usr/local/bin/python# -*- coding: utf-8 -*-def add(a, b): c = a + b return cif __name__ == &quot;__main__&quot;: a = 1 b = 2 c= add(a, b) print(c) 3 íŒŒì´ì¬ í•¨ìˆ˜ ì£¼ì„ ì²˜ë¦¬ Docstring(ë¬¸ì„œí™”) 1234567891011121314151617181920212223# /usr/local/bin/python# -*- coding: utf-8 -*-def temp(content, letter): &quot;&quot;&quot; content ì•ˆì— ìˆëŠ” ë¬¸ìë¥¼ ì„¸ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. Args: content(str) : íƒìƒ‰ ë¬¸ìì—´ letter(str) : ì°¾ì„ ë¬¸ìì—´ Returns: int &quot;&quot;&quot; print(&quot;í•¨ìˆ˜ í…ŒìŠ¤íŠ¸&quot;) cnt = len([char for char in content if char == letter]) return cntif __name__ == &quot;__main__&quot;: # help(temp) print(temp.__doc__) content ì•ˆì— ìˆëŠ” ë¬¸ìë¥¼ ì„¸ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. Args: content(str) : íƒìƒ‰ ë¬¸ìì—´ letter(str) : ì°¾ì„ ë¬¸ìì—´ Returns: int 12345678910111213141516171819202122232425262728def mean_and_median(value_list): &quot;&quot;&quot; ìˆ«ì ë¦¬ìŠ¤íŠ¸ ìš”ì†Œë“¤ì˜ í‰ê· ê³¼ ì¤‘ê°„ê°’ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜ Args: value_list (iterable of int / float) : A list of int numbers Returns: tuple(float, float) &quot;&quot;&quot; # í‰ê·  mean = sum(value_list) / len(value_list) # ì¤‘ê°„ê°’ midpoint = int(len(value_list) / 2) if len(value_list) % 2 == 0: median = (value_list[midpoint - 1] + value_list[midpoint]) / 2 else: median = value_list[midpoint] return mean, medianif __name__ == &quot;__main__&quot;: value_list = [1, 1, 2, 2, 3, 4, 5] avg, median = mean_and_median(value_list) print(&quot;avg:&quot;, avg) print(&quot;median:&quot;, median) avg: 2.5714285714285716 median: 2 12345678910111213141516171819202122232425262728293031def calculation(num1,num2): &quot;&quot;&quot; ë‘ ìˆ˜ì— ëŒ€í•œ ì‚¬ì¹™ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ Args: num1 : float number num2 : float number Returns: tuple(float, float, float, float) &quot;&quot;&quot; # ë§ì…ˆ plus_num = num1 + num2 # ëº„ì…ˆ minus_num = num1 - num2 # ê³±ì…ˆ multiply_num = num1 * num2 # ë‚˜ëˆ—ì…ˆ(ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ê¹Œì§€) divide_num = round(num1 / num2, 2) return plus_num, minus_num, multiply_num, divide_numif __name__ == &quot;__main__&quot;: num1 = 13 num2 = 7 plus, minus, multiply, divide = calculation(num1, num2) print(&quot;+ :&quot;, plus) print(&quot;- :&quot;, minus) print(&quot;* :&quot;, multiply) print(&quot;/ :&quot;, divide) + : 20 - : 6 * : 91 / : 1.86 ì´í„°ë ˆì´í„°, ì œë„ˆë ˆì´í„°, ë°ì½”ë ˆì´í„° ë³€ìˆ˜ëª… immutable or mutable, context manager","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"}],"author":"Jiwon Kang"},{"title":"Python Basic 2","slug":"Python/Basic/python_basic_2","date":"2022-03-22T08:30:50.000Z","updated":"2022-10-05T05:39:51.198Z","comments":true,"path":"2022/03/22/Python/Basic/python_basic_2/","link":"","permalink":"http://gonekng.github.io/2022/03/22/Python/Basic/python_basic_2/","excerpt":"","text":"ë¦¬ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ ë°ì´í„° íƒ€ì… ë°ì´í„°ì— ìˆœì„œê°€ ì¡´ì¬í•˜ë©°, ì¸ë±ì‹± ë° ìŠ¬ë¼ì´ì‹± ê°€ëŠ¥ ëŒ€ê´„í˜¸(â€˜[ê°’1, ê°’2, ê°’3]â€™)ë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ 12345678910111213a = [] # ë¹ˆ ë¦¬ìŠ¤íŠ¸a_func = list() # í•¨ìˆ˜ë¥¼ í†µí•´ ìƒì„±b = [1]c = [&#x27;apple&#x27;]d = [1,2,[&#x27;apple&#x27;]] # ë¦¬ìŠ¤íŠ¸ ì•ˆì— ë¦¬ìŠ¤íŠ¸print(a)print(a_func)print(b)print(c)print(d)print(type(d)) [] [] [1] [&#39;apple&#39;] [1, 2, [&#39;apple&#39;]] &lt;class &#39;list&#39;&gt; ë¦¬ìŠ¤íŠ¸ Indexing, Slicing12345678910a = [1,2,3,4,5,6,7,8,9,10]print(a)print(a[0])print(a[5])print(a[:5])print(a[8:])print(a[3:9:2])print(a[:-3:3])print(a[::-1]) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 1 6 [1, 2, 3, 4, 5] [9, 10] [4, 6, 8] [1, 4, 7] [10, 9, 8, 7, 6, 5, 4, 3, 2, 1] 1234a = [[&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;], 10]print(a[0])print(a[0][1])print(a[0][2][2]) [&#39;apple&#39;, &#39;banana&#39;, &#39;cherry&#39;] banana e ë¦¬ìŠ¤íŠ¸ ì—°ì‚°ì ì‚¬ìš©12345a = [&quot;john&quot;, &quot;evan&quot;]b = [&quot;alice&quot;, &quot;eva&quot;]c = a + b # ë¦¬ìŠ¤íŠ¸ê°€ í•˜ë‚˜ë¡œ í•©ì³ì§print(c) [&#39;john&#39;, &#39;evan&#39;, &#39;alice&#39;, &#39;eva&#39;] 1234c = a * 3d = b * 0print(&quot;a * 3 =&quot;, c) # ìˆ«ìë§Œí¼ ë°˜ë³µprint(&quot;b * 0 =&quot;, d) # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ a * 3 = [&#39;john&#39;, &#39;evan&#39;, &#39;john&#39;, &#39;evan&#39;, &#39;john&#39;, &#39;evan&#39;] b * 0 = [] ë¦¬ìŠ¤íŠ¸ ìˆ˜ì • ë° ì‚­ì œ123a = [0, 1, 2]a[1] = &#x27;b&#x27;print(a) [0, &#39;b&#39;, 2] ë¦¬ìŠ¤íŠ¸ ê°’ ì¶”ê°€123456a = [100,200,300]a.append(400)print(a)a.append([500,600]) # ë¦¬ìŠ¤íŠ¸ ìì²´ë¥¼ ìš”ì†Œë¡œ ì¶”ê°€print(a) [100, 200, 300, 400] [100, 200, 300, 400, [500, 600]] 123456a = [100,200,300]a.append(400)print(a)a.extend([500,600]) # ë¦¬ìŠ¤íŠ¸ì˜ ê°’ë“¤ì„ ìš”ì†Œë¡œ ì¶”ê°€print(a) [100, 200, 300, 400] [100, 200, 300, 400, 500, 600] 123a = [0,1,2]a.insert(1, 100) # ì›í•˜ëŠ” ìœ„ì¹˜ì— ì›í•˜ëŠ” ê°’ ì¶”ê°€print(a) [0, 100, 1, 2] ë¦¬ìŠ¤íŠ¸ ê°’ ì‚­ì œ1234a = [4,3,2,1,&quot;A&quot;]a.remove(1) # í•´ë‹¹ë˜ëŠ” ê°’ ì œê±° a.remove(&quot;A&quot;)print(a) [4, 3, 2] 123456a = [1,2,3,4,5,6,7,8,9,10]del a[1] # ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ì´ìš©í•˜ì—¬ ì œê±°print(a)del a[1:5]print(a) [1, 3, 4, 5, 6, 7, 8, 9, 10] [1, 7, 8, 9, 10] 1234567b = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;]x = b.pop(2)print(x)print(b)y = b.pop() # ì¸ë±ìŠ¤ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ë§ˆì§€ë§‰ ìš”ì†Œ ì¶”ì¶œ ë° ì œê±°print(y)print(b) c [&#39;a&#39;, &#39;b&#39;, &#39;d&#39;, &#39;e&#39;] e [&#39;a&#39;, &#39;b&#39;, &#39;d&#39;] ê·¸ ì™¸ ë©”ì„œë“œ12345a = [0,1,2,3]print(a)a.clear()print(a) [0, 1, 2, 3] [] 12a = [&quot;a&quot;,&quot;a&quot;,&quot;b&quot;,&quot;b&quot;]print(a.index(&quot;b&quot;)) # í•´ë‹¹ ìš”ì†Œê°€ ì²˜ìŒìœ¼ë¡œ ë“±ì¥í•˜ëŠ” ìœ„ì¹˜ 2 12345678a = [1,4,5,2,3]b = [1,4,5,2,3]a.sort() # ì˜¤ë¦„ì°¨ìˆœprint(a)b.sort(reverse=True) # ë‚´ë¦¼ì°¨ìˆœprint(b) [1, 2, 3, 4, 5] [5, 4, 3, 2, 1] 12345678c = [&#x27;d&#x27;,&#x27;bye&#x27;,&#x27;five&#x27;,&#x27;a&#x27;]d = [&#x27;d&#x27;,&#x27;bye&#x27;,&#x27;five&#x27;,&#x27;a&#x27;]c.sort()print(c)d.sort(reverse=True)print(d) [&#39;a&#39;, &#39;bye&#39;, &#39;d&#39;, &#39;five&#39;] [&#39;five&#39;, &#39;d&#39;, &#39;bye&#39;, &#39;a&#39;] íŠœí”Œ ë¦¬ìŠ¤íŠ¸ì™€ ë¹„ìŠ·í•œ í˜•íƒœë¡œ Indexing, Slicing ê°€ëŠ¥ ë¦¬ìŠ¤íŠ¸ì™€ ë‹¬ë¦¬ ìˆ˜ì • ë° ì‚­ì œê°€ ì•ˆ ë¨ ì†Œê´„í˜¸(â€˜(ê°’1, ê°’2, ê°’3)â€™)ë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ 123456789tuple1 = (0) # ëì— comma(,)ë¥¼ ë¶™ì´ì§€ ì•Šìœ¼ë©´ int ìë£Œí˜•tuple2 = (0,) # ëì— comma(,)ë¥¼ ë¶™ì—¬ì•¼ tuple ìë£Œí˜•tuple3 = 0, 1, 2print(tuple1)print(type(tuple1))print(tuple2)print(type(tuple2))print(tuple3)print(type(tuple3)) 0 &lt;class &#39;int&#39;&gt; (0,) &lt;class &#39;tuple&#39;&gt; (0, 1, 2) &lt;class &#39;tuple&#39;&gt; 123456789a = (0,1,2,3,&#x27;a&#x27;)print(type(a))# del a[4] : íŠœí”Œì—ì„œëŠ” ìˆ˜ì •, ì‚­ì œ ì•ˆ ë¨b = list(a)print(b)b[1] = &#x27;b&#x27;a = tuple(b)print(a) &lt;class &#39;tuple&#39;&gt; [0, 1, 2, 3, &#39;a&#39;] (0, &#39;b&#39;, 2, 3, &#39;a&#39;) íŠœí”Œ Indexing, Slicing1234567a = (0,1,2,3,&#x27;a&#x27;)print(type(a))print(a[1])print(a[-2])print(a[1:3])print(a[::2]) &lt;class &#39;tuple&#39;&gt; 1 3 (1, 2) (0, 2, &#39;a&#39;) íŠœí”Œ ì—°ì‚°ì ì‚¬ìš©123456t1 = (0,1,2)t2 = (&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)print(t1 + t2)print(t1 * 3)print(t1 * 0) (0, 1, 2, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;) (0, 1, 2, 0, 1, 2, 0, 1, 2) () ë”•ì…”ë„ˆë¦¬ Keyì™€ Valueë¡œ êµ¬ë¶„ë¨ ì¤‘ê´„í˜¸({â€˜í‚¤1â€™:â€™ê°’1â€™, â€˜í‚¤2â€™:â€™ê°’2â€™})ë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œí˜„ 12345678dict_01 = &#123;&#x27;teacher&#x27; : &#x27;evan&#x27;, &#x27;class&#x27; : &#x27;601í˜¸&#x27;, &#x27;open&#x27; : &#x27;2022-03-10&#x27;, &#x27;students&#x27; : 24, &#x27;names&#x27; : [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;R&#x27;, &#x27;Z&#x27;]&#125;print(dict_01[&#x27;teacher&#x27;])print(dict_01[&#x27;open&#x27;])print(dict_01[&#x27;names&#x27;]) evan 2022-03-10 [&#39;A&#39;, &#39;B&#39;, &#39;R&#39;, &#39;Z&#39;] 123print(dict_01.keys())print(type(dict_01.keys()))print(list(dict_01.keys())) # ë‹¤ì–‘í•œ ì—°ì‚°ê³¼ ë©”ì„œë“œë¥¼ ì ìš©í•  ìˆ˜ ìˆëŠ” ë¦¬ìŠ¤íŠ¸í˜•ìœ¼ë¡œ ë³€í™˜ dict_keys([&#39;teacher&#39;, &#39;class&#39;, &#39;open&#39;, &#39;students&#39;, &#39;names&#39;]) &lt;class &#39;dict_keys&#39;&gt; [&#39;teacher&#39;, &#39;class&#39;, &#39;open&#39;, &#39;students&#39;, &#39;names&#39;] 123print(dict_01.values())print(type(dict_01.values()))print(list(dict_01.values())) # ë‹¤ì–‘í•œ ì—°ì‚°ê³¼ ë©”ì„œë“œë¥¼ ì ìš©í•  ìˆ˜ ìˆëŠ” ë¦¬ìŠ¤íŠ¸í˜•ìœ¼ë¡œ ë³€í™˜ dict_values([&#39;evan&#39;, &#39;601í˜¸&#39;, &#39;2022-03-10&#39;, 24, [&#39;A&#39;, &#39;B&#39;, &#39;R&#39;, &#39;Z&#39;]]) &lt;class &#39;dict_values&#39;&gt; [&#39;evan&#39;, &#39;601í˜¸&#39;, &#39;2022-03-10&#39;, 24, [&#39;A&#39;, &#39;B&#39;, &#39;R&#39;, &#39;Z&#39;]] 1dict_01.items() # ê° keyì™€ valueê°€ íŠœí”Œ í˜•íƒœë¡œ ì¶œë ¥ë¨ dict_items([(&#39;teacher&#39;, &#39;evan&#39;), (&#39;class&#39;, &#39;601í˜¸&#39;), (&#39;open&#39;, &#39;2022-03-10&#39;), (&#39;students&#39;, 24), (&#39;names&#39;, [&#39;A&#39;, &#39;B&#39;, &#39;R&#39;, &#39;Z&#39;])]) 1234567print(dict_01.get(&quot;teacher&quot;))# print(dict_01[&#x27;ì„ ìƒë‹˜&#x27;])print(dict_01.get(&quot;ì„ ìƒë‹˜&quot;)) # keyê°€ ì—†ìœ¼ë©´ Noneì„ ë°˜í™˜print(dict_01.get(&quot;ì„ ìƒë‹˜&quot;, &quot;ì—†ìŒ&quot;)) # keyê°€ ì—†ì„ ë•Œ ëŒ€ì²´ê°’ ì§€ì • ê°€ëŠ¥print(dict_01.get(&quot;class&quot;))# ê·¸ëƒ¥ ê°’ì„ ì¶œë ¥í•´ë„ ë˜ì§€ë§Œ, get ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ keyê°€ ì—†ë”ë¼ë„ ì—ëŸ¬ ì—†ì´ ì¶œë ¥ ê°€ëŠ¥ evan None ì—†ìŒ 601í˜¸ ì¡°ê±´ë¬¸ &amp; ë°˜ë³µë¬¸ì¡°ê±´ë¬¸12345weather = &#x27;ë§‘ìŒ&#x27;if weather == &quot;ë¹„&quot;: print(&quot;ìš°ì‚°ì„ ê°€ì ¸ê°„ë‹¤.&quot;)else: print(&quot;ìš°ì‚°ì„ ê°€ì ¸ê°€ì§€ ì•ŠëŠ”ë‹¤.&quot;) ìš°ì‚°ì„ ê°€ì ¸ê°€ì§€ ì•ŠëŠ”ë‹¤. 1234567# 60ì  ì´ìƒ í•©ê²©score = int(input(&quot;ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹œì˜¤. : &quot;))if score &gt;= 60: print(&quot;í•©ê²©ì…ë‹ˆë‹¤.&quot;)else: print(&quot;ë¶ˆí•©ê²©ì…ë‹ˆë‹¤.&quot;) ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹œì˜¤. : 50 ë¶ˆí•©ê²©ì…ë‹ˆë‹¤. 12345678910111213141516# 90ì  ì´ìƒì€ A, 80ì  ì´ìƒì€ B, 70ì  ì´ìƒì€ C, ë‚˜ë¨¸ì§€ëŠ” Fscore = int(input(&quot;ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹œì˜¤. : &quot;))grade = &quot;&quot;if score &gt;= 90: grade = &quot;A&quot;elif score &gt;= 80: grade = &quot;B&quot;elif score &gt;= 70: grade = &quot;C&quot;elif score &gt;= 60: grade = &quot;D&quot;else: grade = &quot;F&quot; print(grade) ì ìˆ˜ë¥¼ ì…ë ¥í•˜ì‹œì˜¤. : 68 D ë°˜ë³µë¬¸12for i in range(4): print(i+1, &quot;ì•ˆë…•í•˜ì„¸ìš”!&quot;) 1 ì•ˆë…•í•˜ì„¸ìš”! 2 ì•ˆë…•í•˜ì„¸ìš”! 3 ì•ˆë…•í•˜ì„¸ìš”! 4 ì•ˆë…•í•˜ì„¸ìš”! 123456789count = range(5)print(count)for n in count: print(str(n+1) + &quot;ë²ˆì§¸&quot;) if (n+1) == 3: print(&quot;stop!&quot;) break print(&quot;shoot!&quot;) range(0, 5) 1ë²ˆì§¸ shoot! 2ë²ˆì§¸ shoot! 3ë²ˆì§¸ stop! 1234567a = &quot;hello&quot;for x in a: if x==&#x27;l&#x27;: break print(x) h e ë°˜ë³µë¬¸ ì‘ì„± ë°©ì‹ : zip, range, enumerate, len, etc 12345alphabets = [&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]# enumerateëŠ” ì¸ë±ìŠ¤ì™€ ê°’ì„ íŠœí”Œ í˜•íƒœë¡œ ë¬¶ì–´ì£¼ëŠ” ê°ì²´for i, value in enumerate(alphabets): print(i, value) 0 A 1 B 2 C","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"}],"author":"Jiwon Kang"},{"title":"Python Basic 1","slug":"Python/Basic/python_basic_1","date":"2022-03-22T08:30:00.000Z","updated":"2022-10-05T05:39:51.077Z","comments":true,"path":"2022/03/22/Python/Basic/python_basic_1/","link":"","permalink":"http://gonekng.github.io/2022/03/22/Python/Basic/python_basic_1/","excerpt":"","text":"Hello World1print(&quot;Hello, World!&quot;) Hello, World! ì£¼ì„ ì²˜ë¦¬ ì½”ë“œ ì‘ì—… ì‹œ, íŠ¹ì • ì½”ë“œì— ëŒ€í•´ ì„¤ëª… ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ ì‘ì„± ì‹œ, í´ë˜ìŠ¤ ì‘ì„± ì‹œ ì¤‘ìš” (ë„ì›€ë§ ì‘ì„±) 123456# í•œ ì¤„ ì£¼ì„ ì²˜ë¦¬&quot;&quot;&quot;ì—¬ëŸ¬ ì¤„ ì£¼ì„ ì²˜ë¦¬&quot;&quot;&quot;print(&quot;Hello, World!&quot;) Hello, World! ë³€ìˆ˜ (Scalar) ê°ì²´(OBject)ë¡œ êµ¬í˜„ì´ ë¨ í•˜ë‚˜ì˜ ìë£Œí˜•(Type)ì„ ê°€ì§„ë‹¤. í´ë˜ìŠ¤(Class)ë¡œ ì •ì˜ëœë‹¤. ë‹¤ì–‘í•œ í•¨ìˆ˜ë“¤ ì¡´ì¬ int int ì •ìˆ˜ë¥¼ í‘œí˜„í•˜ëŠ” ë° ì‚¬ìš© 12345num_int = 1num_int2 = 3print(num_int)print(num_int2)print(type(num_int)) 1 3 &lt;class &#39;int&#39;&gt; float ì‹¤ìˆ˜ë¥¼ í‘œí˜„í•˜ëŠ” ë° ì‚¬ìš© 123num_float = 0.2print(num_float)print(type(num_float)) 0.2 &lt;class &#39;float&#39;&gt; bool Trueì™€ Falseë¡œ ë‚˜íƒ€ë‚˜ëŠ” Boolean ê°’ì„ í‘œí˜„í•˜ëŠ” ë° ì‚¬ìš© 123bool_true = Trueprint(bool_true)print(type(bool_true)) True &lt;class &#39;bool&#39;&gt; None Nullì„ ë‚˜íƒ€ë‚´ëŠ” ìë£Œí˜•ìœ¼ë¡œ Noneì´ë¼ëŠ” í•œ ê°€ì§€ ê°’ë§Œ ê°€ì§„ë‹¤. 123none_x = Noneprint(none_x)print(type(none_x)) None &lt;class &#39;NoneType&#39;&gt; ì‚¬ì¹™ì—°ì‚°ì •ìˆ˜í˜• ì‚¬ì¹™ì—°ì‚°123456789a = 15 # intb = 2 # intprint(&#x27;a + b = &#x27;, a+b) # intprint(&#x27;a - b = &#x27;, a-b) # intprint(&#x27;a * b = &#x27;, a*b) # intprint(&#x27;a / b = &#x27;, a/b) # floatprint(&#x27;a // b = &#x27;, a//b) # intprint(&#x27;a % b = &#x27;, a%b) # intprint(&#x27;a ** b = &#x27;, a**b) # int a + b = 17 a - b = 13 a * b = 30 a / b = 7.5 a // b = 7 a % b = 1 a ** b = 225 ì‹¤ìˆ˜í˜• ì‚¬ì¹™ì—°ì‚°123456789a = 15.0 # floatb = 2.0 # floatprint(&#x27;a + b =&#x27;, a+b) # floatprint(&#x27;a - b =&#x27;, a-b) # floatprint(&#x27;a * b =&#x27;, a*b) # floatprint(&#x27;a / b =&#x27;, a/b) # floatprint(&#x27;a // b =&#x27;, a//b) # floatprint(&#x27;a % b =&#x27;, a%b) # floatprint(&#x27;a ** b =&#x27;, a**b) # float a + b = 17.0 a - b = 13.0 a * b = 30.0 a / b = 7.5 a // b = 7.0 a % b = 1.0 a ** b = 225.0 ë…¼ë¦¬í˜• ì—°ì‚°ì Boolí˜•ì€ Trueì™€ False ê°’ìœ¼ë¡œ ì •ì˜ AND, OR, NOT 123456789101112x = 5 &gt; 4print(&#x27;x =&#x27;, x)y = 3 &gt; 9print(&#x27;y =&#x27;, y)print(&#x27;x and x =&#x27;, x and x)print(&#x27;x and y =&#x27;, x and y)print(&#x27;y and x =&#x27;, y and x)print(&#x27;y and y =&#x27;, y and y)print(&#x27;x or x =&#x27;, x or x)print(&#x27;x or y =&#x27;, x or y)print(&#x27;y or x =&#x27;, y or x)print(&#x27;y or y =&#x27;, y or y) x = True y = False x and x = True x and y = False y and x = False y and y = False x or x = True x or y = True y or x = True y or y = False ë¹„êµ ì—°ì‚°ì ë¶€ë“±í˜¸ë¥¼ ì˜ë¯¸ ë¹„êµ ì—°ì‚°ìë¥¼ Trueì™€ False ê°’ì„ ë„ì¶œ ë…¼ë¦¬ &amp; ë¹„êµ ì—°ì‚°ì ì‘ìš©123var = input(&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :&quot;)print(var)print(type(var)) ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :24 24 &lt;class &#39;str&#39;&gt; 123var = int(input(&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :&quot;))print(var)print(type(var)) ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :92 92 &lt;class &#39;int&#39;&gt; 123456789num1 = int(input(&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :&quot;))num2 = int(input(&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :&quot;))num3 = int(input(&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :&quot;))num4 = int(input(&quot;ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :&quot;))var1 = num1 &gt;= num2 var2 = num3 &lt; num4print(var1 and var2)print(var1 or var2) ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :29 ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :15 ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :8 ìˆ«ìë¥¼ ì…ë ¥í•˜ì‹œì˜¤. :10 True True ë¬¸ìì—´ë¬¸ìì—´ ì…ë ¥ ë°©ë²• ë¬¸ìì—´ì„ ì…ë ¥í•˜ëŠ” 4ê°€ì§€ ë°©ë²• 1234print(&quot;Hello, World&quot;)print(&#x27;Hello, World&#x27;)print(&quot;&#x27;Hello, World&#x27;&quot;)print(&#x27;&quot;Hello, World&quot;&#x27;) Hello, World Hello, World &#39;Hello, World &quot;Hello, World&quot; ë¬¸ìì—´ì— ì‘ì€ë”°ì˜´í‘œ, í°ë”°ì˜´í‘œ í¬í•¨í•˜ëŠ” ë°©ë²• 123456789food = &quot;Python&#x27;s favorite food is perl&quot;print(food)say = &#x27;&quot;Python is very easy.&quot; he says.&#x27;print(say)food2 = &#x27;Python\\&#x27;s favorite food is perl&#x27;print(food2)say2 = &quot;\\&quot;Python is very easy.\\&quot; he says.&quot;print(say2) Python&#39;s favorite food is perl &quot;Python is very easy.&quot; he says. Python&#39;s favorite food is perl &quot;Python is very easy.&quot; he says. ë³€ìˆ˜ì— ì—¬ëŸ¬ ì¤„ì˜ ë¬¸ìì—´ ëŒ€ì… 12multiline = &quot;Life is too short.\\nYou need python.&quot;print(multiline) Life is too short. You need python. 12345multiline =&#x27;&#x27;&#x27;Life is too short.You need python&#x27;&#x27;&#x27;print(multiline) Life is too short. You need python String ì—°ì‚°ì ë§ì…ˆ ì—°ì‚°ì 1234str1 = &quot;Hello &quot;str2 = &quot;World! &quot;print(str1 + str2) Hello World! ê³±ì…ˆ ì—°ì‚°ì 12greeting = str1 + str2print(greeting * 3) Hello World! Hello World! Hello World! Indexing ë¬¸ìì—´ ì¸ë±ì‹±ì€ ë¬¸ìì—´ ì•ˆì—ì„œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ì—¬ íŠ¹ì • ë‹¨ì¼ë¬¸ì ì¶”ì¶œ 12345greeting = &quot;Hello Kaggle!&quot;print(greeting[0])print(greeting[6])print(greeting[len(greeting)-1])print(greeting[-1]) H K ! ! Slicing ë¬¸ìì—´ ìŠ¬ë¼ì´ì‹±ì€ ë¬¸ìì—´ ì•ˆì—ì„œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ê³  íŠ¹ì • ë¬¸ìì—´ ì¶”ì¶œ 1234567print(greeting[:])print(greeting[:5])print(greeting[6:])print(greeting[3:9])print(greeting[0:9:2])print(greeting[6:-1])print(greeting[::-1]) Hello Kaggle! Hello Kaggle! lo Kag HloKg Kaggle !elggaK olleH Formattingformat ì½”ë“œ1234567print(&quot;I eat %d apples.&quot; % 3) # ìˆ«ì ëŒ€ì…print(&quot;I eat %s apples.&quot; % &quot;five&quot;) # ë¬¸ìì—´ ëŒ€ì…num = 10day = &quot;three&quot;say = &quot;I ate %d apples, so I was sick for %s days.&quot; % (num, day)print(say) I eat 3 apples. I eat five apples. I ate 10 apples, so I was sick for three days. 123print(&quot;I have %s apples&quot; % 3)print(&quot;rate is %s&quot; % 3.234)print(&quot;Error is %d%%.&quot; % 98) # fomatting ì—°ì‚°ìì™€ %ë¥¼ í•¨ê»˜ ì“¸ ë•ŒëŠ” %% I have 3 apples rate is 3.234 Error is 98%. 123456print(&quot;%10s,Jane!&quot; % &quot;hi&quot;)print(&quot;%-10s,Jane!&quot; % &quot;hi&quot;)print(&quot;&#x27;%0.4f&#x27;&quot; % 3.42134234)print(&quot;&#x27;%10.4f&#x27;&quot; % 3.42134234)print(&quot;&#x27;%-10.4f&#x27;&quot; % 3.42134234) hi,Jane! hi ,Jane! &#39;3.4213&#39; &#39; 3.4213&#39; &#39;3.4213 &#39; format í•¨ìˆ˜12345678910print(&quot;I eat &#123;0&#125; apples.&quot;.format(7))print(&quot;I eat &#123;0&#125; apples.&quot;.format(&quot;five&quot;))num = 8day = 3print(&quot;I ate &#123;0&#125; apples.&quot;.format(num))print(&quot;I ate &#123;0&#125; apples, so I was sick for &#123;1&#125; days.&quot;.format(num, day))print(&quot;I ate &#123;num&#125; apples, so I was sick for &#123;day&#125; days.&quot;.format(num=6,day=2))print(&quot;I ate &#123;0&#125; apples, so I was sick for &#123;day&#125; days.&quot;.format(4,day=1)) I eat 7 apples. I eat five apples. I ate 8 apples. I ate 8 apples, so I was sick for 3 days. I ate 6 apples, so I was sick for 2 days. I ate 4 apples, so I was sick for 1 days. 123456print(&quot;&#x27;&#123;0:&lt;10&#125;&#x27;&quot;.format(&quot;hi&quot;))print(&quot;&#x27;&#123;0:^10&#125;&#x27;&quot;.format(&quot;hi&quot;))print(&quot;&#x27;&#123;0:&gt;10&#125;&#x27;&quot;.format(&quot;hi&quot;))print(&quot;&#x27;&#123;0:=^10&#125;&#x27;&quot;.format(&quot;hi&quot;))print(&quot;&#x27;&#123;0:!&lt;10&#125;&#x27;&quot;.format(&quot;hi&quot;)) &#39;hi &#39; &#39; hi &#39; &#39; hi&#39; &#39;====hi====&#39; &#39;hi!!!!!!!!&#39; 12345y = 3.42134234print(&quot;&#x27;&#123;0:0.4f&#125;&#x27;&quot;.format(y))print(&quot;&#x27;&#123;0:10.4f&#125;&#x27;&quot;.format(y))print(&quot;&#x27;&#123;0:^10.4f&#125;&#x27;&quot;.format(y))print(&quot;&#x27;&#123;0:&lt;10.4f&#125;&#x27;&quot;.format(y)) &#39;3.4213&#39; &#39; 3.4213&#39; &#39; 3.4213 &#39; &#39;3.4213 &#39; 123name1 = &quot;John&quot;name2 = &quot;Marry&quot;print(&quot;&#123;0&#125; &#123;&#123;and&#125;&#125; &#123;1&#125;&quot;.format(name1, name2)) John &#123;and&#125; Marry f ë¬¸ìì—´1234567name = &#x27;Sally&#x27;age = 29print(f&quot;My name is &#123;name&#125;, and I&#x27;m &#123;age&#125; years old.&quot;)print(f&quot;Next year, I&#x27;m going to be &#123;age+1&#125; years old.&quot;)d = &#123;&#x27;name&#x27;:&#x27;Sally&#x27;, &#x27;age&#x27;:29&#125;print(f&quot;My name is &#123;d[&#x27;name&#x27;]&#125;, and I&#x27;m &#123;d[&#x27;age&#x27;]&#125; years old.&quot;) # ë”•ì…”ë„ˆë¦¬ ìë£Œí˜• í™œìš© My name is Sally, and I&#39;m 29 years old. Next year, I&#39;m going to be 30 years old. My name is Sally, and I&#39;m 29 years old. 123456print(f&#x27;&#123;&quot;hi&quot;:&lt;10&#125;&#x27;)print(f&#x27;&#123;&quot;hi&quot;:^10&#125;&#x27;)print(f&#x27;&#123;&quot;hi&quot;:&gt;10&#125;&#x27;)print(f&#x27;&#123;&quot;hi&quot;:=^10&#125;&#x27;)print(f&#x27;&#123;&quot;hi&quot;:!&lt;10&#125;&#x27;) hi hi hi ====hi==== hi!!!!!!!! 12345y = 3.42134234print(f&#x27;&#123;y:0.4f&#125;&#x27;)print(f&#x27;&#123;y:10.4f&#125;&#x27;)print(f&#x27;&#123;y:^10.4f&#125;&#x27;)print(f&#x27;&#123;y:&lt;10.4f&#125;&#x27;) 3.4213 3.4213 3.4213 3.4213 123name1 = &quot;John&quot;name2 = &quot;Marry&quot;print(f&quot;&#123;name1&#125; &#123;&#123;and&#125;&#125; &#123;name2&#125;&quot;) John &#123;and&#125; Marry ë¬¸ìì—´ í•¨ìˆ˜12345678910# counta = &#x27;hobby&#x27;print(a.count(&#x27;b&#x27;))# find, indexa = &quot;Python is the best choice&quot;print(a.find(&quot;b&quot;))print(a.find(&quot;k&quot;)) # ì—†ìœ¼ë©´ -1 ë°˜í™˜print(a.index(&quot;t&quot;))# print(a.index(&quot;k&quot;)) # ì—†ìœ¼ë©´ ì—ëŸ¬ 2 14 -1 2 12345678910111213# joinprint(&quot;,&quot;.join(&#x27;abcdefg&#x27;))# upper, lowera = &quot;Hello&quot;print(a.upper())print(a.lower())# lstrip, rstrip, stripa = &quot; OK &quot;print(a.lstrip())print(a.rstrip())print(a.strip()) a,b,c,d,e,f,g HELLO hello OK OK OK 123456789# replacea = &quot;That&#x27;s right!&quot;print(a.replace(&#x27;right&#x27;, &#x27;wrong&#x27;))# splita = &quot;I Love You&quot;print(a.split()) # ê³µë°± ê¸°ì¤€b = &quot;a:b:c:d&quot;print(b.split(&#x27;:&#x27;)) # íŠ¹ì • êµ¬ë¶„ì ê¸°ì¤€ That&#39;s wrong! [&#39;I&#39;, &#39;Love&#39;, &#39;You&#39;] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]","categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"}],"tags":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"}],"author":"Jiwon Kang"},{"title":"R_markdown Sample","slug":"R/R_sample","date":"2022-03-18T01:02:35.000Z","updated":"2022-10-05T05:39:55.091Z","comments":true,"path":"2022/03/18/R/R_sample/","link":"","permalink":"http://gonekng.github.io/2022/03/18/R/R_sample/","excerpt":"","text":"ê°œìš” Rì—ì„œ ë§Œë“  sample íŒŒì¼ githubì— ì—…ë¡œë“œ R MarkdownThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: 1summary(cars) 1234567## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 Including PlotsYou can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.","categories":[{"name":"r","slug":"r","permalink":"http://gonekng.github.io/categories/r/"}],"tags":[{"name":"r","slug":"r","permalink":"http://gonekng.github.io/tags/r/"}],"author":"Jiwon Kang"},{"title":"Hexo ë¸”ë¡œê·¸ ìƒì„±","slug":"hexo/hexo_blog","date":"2022-03-17T02:14:21.000Z","updated":"2022-11-16T09:54:09.424Z","comments":true,"path":"2022/03/17/hexo/hexo_blog/","link":"","permalink":"http://gonekng.github.io/2022/03/17/hexo/hexo_blog/","excerpt":"","text":"Hexo ì„¤ì¹˜ node.js ì„¤ì¹˜ ì˜µì…˜ - Chocolateyë„ í•¨ê»˜ ì„¤ì¹˜ ë°”íƒ•í™”ë©´ git bashì— ì…ë ¥ node -v : ë²„ì „ í™•ì¸ npm install -g hexo-cli : hexo command line ì„¤ì¹˜ hexo init myblog : ë°”íƒ•í™”ë©´ì— myblog í´ë” ìƒì„± myblog í´ë” ìœ„ì¹˜ì—ì„œ Git Bash ì—´ê³  hexo server ì…ë ¥ ì¶œë ¥ë˜ëŠ” ë§í¬ë¡œ ì´ë™í•˜ì—¬ hexo ì„œë²„ê°€ ì˜ ì—´ë¦¬ëŠ”ì§€ í™•ì¸ ê¹ƒí—ˆë¸Œ ë ˆí¬ì§€í† ë¦¬ ìƒì„± ê¹ƒí—ˆë¸Œ ë¡œê·¸ì¸ í›„ profile - new repositories - new í´ë¦­ Repository ì´ë¦„ì€ myblogë¡œ ì§€ì • (ë¡œì»¬ì— ìƒì„±í•œ í´ë” ì´ë¦„ìœ¼ë¡œ ì§€ì •í•´ì•¼í•¨) ë³„ë„ì˜ ì˜µì…˜ ì—†ì´ Creating repository í´ë¦­ myblog í´ë” ìœ„ì¹˜ì—ì„œ Git Bash ì—´ê³  ì•„ë˜ ì½”ë“œ í•œ ì¤„ì”© ì…ë ¥ 12345671 echo &quot;# myblog&quot; &gt;&gt; README.md2 git init3 git add README.md4 git commit -m &quot;first commit&quot;5 git branch -M main6 git remote add origin https://github.com/[ê¹ƒí—ˆë¸Œì•„ì´ë””]/myblog.git7 git push -u origin main í•´ë‹¹ ë ˆí¬ì§€í† ë¦¬ì— README.md íŒŒì¼ ìƒì„± ìƒˆë¡œìš´ git ì €ì¥ì†Œë¥¼ í•´ë‹¹ ë¡œì»¬ í´ë”ì— ì´ˆê¸°í™” README.md íŒŒì¼ì„ gitì— ì¶”ê°€ gitì— ì¶”ê°€ëœ ëª¨ë“  ë‚´ìš© ì»¤ë°‹ (ì»¤ë°‹ ë©”ì‹œì§€ëŠ” ììœ ë¡­ê²Œ ì§€ì • ê°€ëŠ¥) ì‚¬ìš©ì ì—ëŸ¬ ë°œìƒ ì‹œ ì•„ë˜ ì½”ë“œ ì…ë ¥ 12git config --global user.email â€œ[ì´ë©”ì¼ì£¼ì†Œ]â€git config --global user.name â€œ[ê¹ƒí—ˆë¸Œì•„ì´ë””]â€ git ë¸Œëœì¹˜ë¥¼ mainìœ¼ë¡œ ë³€ê²½ git ì´ˆê¸°í™” ì‹œ ê¸°ë³¸ê°’ì€ masterì´ë‚˜, ëŒ€ë¶€ë¶„ì˜ í”„ë¡œì íŠ¸ì—ì„œ mainì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì´ˆê¸°ì— ë³€ê²½í•´ì£¼ëŠ” ê²ƒì´ ì¢‹ìŒ í•´ë‹¹ ë¡œì»¬ í´ë”ì— ê¹ƒí—ˆë¸Œ ë ˆí¬ì§€í† ë¦¬ë¥¼ ì—°ê²° ì»¤ë°‹í•œ ë‚´ìš© í‘¸ì‹œ ì´ˆê¸° ì„¸íŒ… ì´í›„ì—ëŠ” add, commit, push ëª…ë ¹ì–´ë§Œ ì…ë ¥ ê¹ƒí—ˆë¸Œì—ì„œ ìƒˆë¡œê³ ì¹¨ í›„ ì—…ë¡œë“œëœ README.md íŒŒì¼ í™•ì¸ Hexo ë¸”ë¡œê·¸ ìƒì„± ê¹ƒí—ˆë¸Œì—ì„œ ìƒˆë¡œìš´ Repository ìƒì„± (ì´ë¦„ : [ê¹ƒí—ˆë¸Œì•„ì´ë””].github.io) myblog í´ë” ìœ„ì¹˜ì—ì„œ Git Bash ì—´ê³  ì•„ë˜ ì½”ë“œ ì…ë ¥ 123$ npm install$ npm install hexo-server --save$ npm install hexo-deployer-git --save ë¸”ë¡œê·¸ í´ë” ì•ˆì— ì‡ëŠ” _config.yml íŒŒì¼ ë‚´ìš© ìˆ˜ì • title, subtitle, author ë“± ì„¸ë¶€ì‚¬í•­ ì…ë ¥ ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ì—°ê²° : urlì— ê¹ƒí—ˆë¸Œ ë¸”ë¡œê·¸ ì£¼ì†Œ ì…ë ¥ (ex. https://[ê¹ƒí—ˆë¸Œì•„ì´ë””].github.io) ë°°í¬ ê´€ë ¨ ì„¤ì • : ë§¨ ì•„ë˜ deployì— ë‹¤ìŒê³¼ ê°™ì´ ì…ë ¥ 1234deploy: type: git repo: https://github.com/[ê¹ƒí—ˆë¸Œì•„ì´ë””]/[ê¹ƒí—ˆë¸Œì•„ì´ë””].github.io.git branch: main myblog í´ë” ìœ„ì¹˜ì—ì„œ Git Bash ì—´ê³  hexo generate --deploy ì…ë ¥ Deploy doneì´ë¼ëŠ” ë©”ì‹œì§€ê°€ ì¶œë ¥ë˜ë©´ ë°°í¬ ì™„ë£Œëœ ê²ƒ ê²Œì‹œê¸€ ì¶”ê°€ ë˜ëŠ” ìˆ˜ì •í•  ë•Œë§ˆë‹¤ ìœ„ì˜ ì½”ë“œ ì…ë ¥ ë¸”ë¡œê·¸ í…Œë§ˆ ë³€ê²½ https://hexo.io/themes/ ì—ì„œ í…Œë§ˆ ì •í•´ì„œ í•´ë‹¹ í…Œë§ˆì˜ Githubìœ¼ë¡œ ì´ë™ TIP : ìµœê·¼ì—ë„ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸ npm install hexo-theme-[í…Œë§ˆëª…] ì…ë ¥ hexo config theme [í…Œë§ˆëª…] ì…ë ¥ hexo server ì…ë ¥ ì´ë•Œ ì—ëŸ¬ê°€ ë°œìƒí•˜ëŠ” ê²½ìš° npm install --save bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3 ì…ë ¥ hexo clean ì„ í†µí•´ ì •ë¦¬í•œ í›„ hexo generate --deploy ë¡œ ë¸”ë¡œê·¸ì— ë°°í¬ R ë§ˆí¬ë‹¤ìš´ ì—…ë¡œë“œ R ë§ˆí¬ë‹¤ìš´ ì†ŒìŠ¤ì—ì„œ ê°œìš” ë¶€ë¶„ ìˆ˜ì • 123output: html_document: keep_md: true Rì—ì„œ Knit ë²„íŠ¼ í´ë¦­í•˜ë©´ í•´ë‹¹ ë””ë ‰í† ë¦¬ì— md íŒŒì¼ ìƒì„±ë¨ myblog&#x2F;source&#x2F;_posts ê²½ë¡œì— í•´ë‹¹ íŒŒì¼ ë³µì‚¬ í›„ ë‚´ìš© ìˆ˜ì • R ë””ë ‰í† ë¦¬ì— ìˆëŠ” blog_files í´ë”ë¥¼ myblog&#x2F;source&#x2F;images ê²½ë¡œì— ë³µì‚¬ í›„ md íŒŒì¼ì— ìˆëŠ” ì´ë¯¸ì§€ ë§í¬ ìˆ˜ì • ë° ë°°í¬ Google Colab ì—…ë¡œë“œ google colab &gt; íŒŒì¼ &gt; ë‹¤ìš´ë¡œë“œ &gt; .ipynb ë‹¤ìš´ë¡œë“œ Jupiter Labì—ì„œ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ ì—´ê³  File &gt; Save and Export Notebook As &gt; Markdown ìƒì„±ëœ md íŒŒì¼ ë° ì´ë¯¸ì§€ë¥¼ ë¸”ë¡œê·¸ í´ë”ë¡œ ë³µì‚¬ í›„ ë°°í¬","categories":[{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://gonekng.github.io/tags/github/"}],"author":"Jiwon Kang"},{"title":"R_basic_statistics","slug":"R/R_basic_stat","date":"2022-03-15T07:42:09.000Z","updated":"2022-10-05T05:39:54.984Z","comments":true,"path":"2022/03/15/R/R_basic_stat/","link":"","permalink":"http://gonekng.github.io/2022/03/15/R/R_basic_stat/","excerpt":"","text":"í†µê³„ ë¶„ì„ ê°œìš” ê¸°ìˆ í†µê³„(discriptive Statistics) : í‰ê· , ìµœì†Ÿê°’, ìµœëŒ“ê°’, ì¤‘ì•™ê°’ ë“± ë°ì´í„°ì˜ íŠ¹ì§•ì„ ì„œìˆ í•˜ëŠ” ê²ƒ ì¶”ë¡ í†µê³„(inferential Statistics) : ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ íŒŒì•…í•˜ì—¬ ë³€ìˆ˜ ê°„ ì¸ê³¼ê´€ê³„ë‚˜ ìƒˆë¡œìš´ ì‚¬ì‹¤ì„ ë°í˜€ë‚´ëŠ” ê²ƒ í‰ê·  ì°¨ì´ ê²€ì • : ì§‘ë‹¨ë³„ í‰ê· ì˜ ì°¨ì´ê°€ ì‹¤ì œë¡œ ìˆëŠ”ê°€ë¥¼ ê²€ì •í•˜ëŠ” ê²ƒ êµì°¨ë¶„ì„ : ë²”ì£¼í˜• ë³€ìˆ˜ë¡œ êµ¬ì„±ëœ ì§‘ë‹¨ë“¤ì˜ ê´€ë ¨ì„±ì„ ê²€ì •í•˜ëŠ” ê²ƒ ìƒê´€ê´€ê³„ë¶„ì„ : ë³€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„(correlation)ë¥¼ ì•Œì•„ë³´ëŠ” ê²ƒ ìƒê´€ê´€ê³„ëŠ” í•œ ë³€ìˆ˜ê°€ ë³€í™”í•˜ë©´ ë‹¤ë¥¸ ë³€ìˆ˜ë„ ë³€í™”í•˜ëŠ” ê´€ê³„ë¥¼ ì˜ë¯¸ ìƒê´€ê³„ìˆ˜(r) : ë³€í™”ì˜ ê°•ë„ì™€ ë°©í–¥ì„ ë‚˜íƒ€ë‚´ëŠ” ê³„ìˆ˜ (-1 &lt;&#x3D; r &lt;&#x3D; 1) ìˆ˜ì¹˜ê°€ í´ìˆ˜ë¡ ì˜í–¥ì„ ì£¼ëŠ” ê°•ë„ê°€ í¬ë©°, â€˜+â€™ëŠ” ì •ì˜ ê´€ê³„, â€˜-â€˜ëŠ” ì—­ì˜ ê´€ê³„ íšŒê·€ë¶„ì„ : ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ ê°„ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒ ë…ë¦½ë³€ìˆ˜ : ì˜í–¥ì„ ì£¼ëŠ” ë³€ìˆ˜ &#x2F; ì¢…ì†ë³€ìˆ˜ : ì˜í–¥ì„ ë°›ëŠ” ë³€ìˆ˜ ë‹¨ìˆœíšŒê·€ë¶„ì„ : ì¢…ì†ë³€ìˆ˜ 1ê°œ, ë…ë¦½ë³€ìˆ˜ 1ê°œ (y &#x3D; a + b*x) ë‹¤ì¤‘íšŒê·€ë¶„ì„ : ì¢…ì†ë³€ìˆ˜ 1ê°œ, ë…ë¦½ë³€ìˆ˜ 2ê°œ ì´ìƒ (y &#x3D; a + b1x1 + b2x2 +â€¦) í†µê³„ ê²€ì • ê°€ì„¤(hypothesis) ì–´ë–¤ í˜„ìƒì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ì„œ ê°€ì •í•˜ëŠ” ëª…ì œ ê·€ë¬´ê°€ì„¤(H0) : ì²˜ìŒë¶€í„° ê¸°ê°ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ê°€ì„¤ (ì˜ê°€ì„¤) ëŒ€ë¦½ê°€ì„¤(H1) : ê·€ë¬´ê°€ì„¤ì´ ê¸°ê°ë  ê²½ìš° ë°›ì•„ë“¤ì—¬ì§€ëŠ” ê°€ì„¤ ìœ ì˜ìˆ˜ì¤€(significance level, pê°’) ê·€ë¬´ê°€ì„¤ì´ ë§ëŠ”ë°ë„ ëŒ€ë¦½ê°€ì„¤ì„ ì±„íƒí•  í™•ë¥  (ì œ1ì¢… ì˜¤ë¥˜ì˜ ìµœëŒ€ í—ˆìš© ë²”ìœ„) ê°€ì„¤ ê²€ì •ì—ì„œ ì¸ì •í•˜ëŠ” ìœ ì˜ìˆ˜ì¤€ : 5%, 1%, 0.1% ì‹ ë¢°ìˆ˜ì¤€(confidence level) : ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë²”ìœ„ (1-ìœ ì˜ìˆ˜ì¤€) ì²™ë„(scale) ëª…ëª©ì²™ë„ : ì¸¡ì •ëŒ€ìƒì˜ íŠ¹ì„±ì´ë‚˜ ë²”ì£¼ë¥¼ êµ¬ë¶„í•˜ëŠ” ì²™ë„ ë“±ë²ˆí˜¸, ì„±ë³„, ì¸ì¢…, ì§€ì—­ ë“± ì‚°ìˆ  ì—°ì‚°ì„ í•  ìˆ˜ ì—†ìŒ ì„œì—´ì²™ë„ : ì¸¡ì •ëŒ€ìƒì˜ ë“±ê¸‰ìˆœìœ„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì²™ë„ ê³„ê¸‰, ì‚¬íšŒê³„ì¸µ, ìê²©ë“±ê¸‰ ë“± ì‚°ìˆ  ì—°ì‚°ì„ í•  ìˆ˜ ì—†ìŒ ì²™ë„ ê°„ì˜ ê±°ë¦¬ë‚˜ ê°„ê²©ì„ ë‚˜íƒ€ë‚´ì§€ëŠ” ì•ŠìŒ ë“±ê°„ì²™ë„ : ì¸¡ì •ëŒ€ìƒì„ ì¼ì •í•œ ê°„ê²©ìœ¼ë¡œ êµ¬ë¶„í•œ ì²™ë„ ì˜¨ë„, í•™ë ¥, ì‹œí—˜ì ìˆ˜ ë“± ì„œì—´ ë¿ë§Œ ì•„ë‹ˆë¼ ê±°ë¦¬ì™€ ê°„ê²©ë„ í‘œí˜„ ê°€ëŠ¥ ë§ì…ˆ, ëº„ì…ˆì„ í•  ìˆ˜ ìˆìŒ ë¹„ìœ¨ì²™ë„ : ì¸¡ì •ëŒ€ìƒì„ ë¹„ìœ¨ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ì²™ë„ ì—°ë ¹, í‚¤, ë¬´ê²Œ ë“± ì‚¬ì¹™ì—°ì‚°ì„ ëª¨ë‘ í•  ìˆ˜ ìˆìŒ í†µê³„ ë¶„ì„ ì‚¬ë¡€1. ë‘ ì§‘ë‹¨ì˜ í‰ê·  ì°¨ì´ ê²€ì • - ë…ë¦½í‘œë³¸ tê²€ì •(t.test()) ë…ë¦½ë³€ìˆ˜ëŠ” ëª…ëª©ì²™ë„, ì¢…ì†ë³€ìˆ˜ëŠ” ë“±ê°„ì²™ë„ ë˜ëŠ” ë¹„ìœ¨ì²™ë„ì´ì–´ì•¼ í•¨ ê·€ë¬´ê°€ì„¤ : autoì™€ manualì˜ ctyí‰ê· ì€ ì°¨ì´ê°€ ì—†ë‹¤. 12mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;)str(mpg1) 123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer : chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 1t.test(data=mpg1, cty~trans) 1234567891011## ## Welch Two Sample t-test## ## data : cty by trans## t = -4.5375, df = 132.32, p-value = 1.263e-05## alternative hypothesis : true difference in means between group auto and group manual is not equal to 0## 95 percent confidence interval:## -3.887311 -1.527033## sample estimates:## mean in group auto mean in group manual ## 15.96815 18.67532 &gt;&gt; p-value &#x3D; 1.263e-05, ê·€ë¬´ê°€ì„¤ ê¸°ê°(ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆìŒ)2. êµì°¨ë¶„ì„ - ì¹´ì´ì œê³± ê²€ì •(chisq.test()) ê·€ë¬´ê°€ì„¤ : transì— ë”°ë¼ drvì˜ ì°¨ì´ê°€ ì—†ë‹¤. 12mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;)str(mpg1) 123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer : chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 1table(mpg1$trans, mpg1$drv) 1234## ## 4 f r## auto 75 65 17## manual 28 41 8 1prop.table(table(mpg1$trans, mpg1$drv),1) 1234## ## 4 f r## auto 0.4777070 0.4140127 0.1082803## manual 0.3636364 0.5324675 0.1038961 1chisq.test(mpg1$trans, mpg1$drv) 12345## ## Pearson&#x27;s Chi-squared test## ## data : mpg1$trans and mpg1$drv## X-squared = 3.1368, df = 2, p-value = 0.2084 &gt;&gt; p-value &#x3D; 0.2084, ê·€ë¬´ê°€ì„¤ ì±„íƒ(ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ìŒ)3) ìƒê´€ê´€ê³„ë¶„ì„ - cor.test()- ê·€ë¬´ê°€ì„¤ : ctyì™€ hwyëŠ” ìƒê´€ê´€ê³„ê°€ ì—†ë‹¤. 12mpg1 &lt;- read.csv(&quot;mpg1.csv&quot;)str(mpg1) 123456## &#x27;data.frame&#x27;: 234 obs. of 5 variables:## $ manufacturer : chr &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; &quot;audi&quot; ...## $ trans : chr &quot;auto&quot; &quot;manual&quot; &quot;manual&quot; &quot;auto&quot; ...## $ drv : chr &quot;f&quot; &quot;f&quot; &quot;f&quot; &quot;f&quot; ...## $ cty : int 18 21 20 21 16 18 18 18 16 20 ...## $ hwy : int 29 29 31 30 26 26 27 26 25 28 ... 1cor.test(mpg1$cty, mpg1$hwy) 1234567891011## ## Pearson&#x27;s product-moment correlation## ## data : mpg1$cty and mpg1$hwy## t = 49.585, df = 232, p-value &lt; 2.2e-16## alternative hypothesis : true correlation is not equal to 0## 95 percent confidence interval:## 0.9433129 0.9657663## sample estimates:## cor ## 0.9559159 &gt;&gt; p-value &lt; 2.2e-16, ê·€ë¬´ê°€ì„¤ ê¸°ê°(ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìƒê´€ê´€ê³„ê°€ ìˆìŒ)&gt;&gt; ìƒê´€ê³„ìˆ˜ r &#x3D; 0.9559159 (ë§¤ìš° ë†’ì€ ìƒê´€ê´€ê³„)4. ë‹¨ìˆœíšŒê·€ë¶„ì„ - lm() ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ê°€ ëª¨ë‘ ë“±ê°„ì²™ë„ ë˜ëŠ” ë¹„ìœ¨ì²™ë„ì´ì–´ì•¼ í•¨ ê·€ë¬´ê°€ì„¤ : dispëŠ” mpgì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤. 12RA &lt;- lm(data=mtcars, mpg~disp)summary(RA) 123456789101112131415161718## ## Call:## lm(formula = mpg ~ disp, data = mtcars)## ## Residuals:## Min 1Q Median 3Q Max ## -4.8922 -2.2022 -0.9631 1.6272 7.2305 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 29.599855 1.229720 24.070 &lt; 2e-16 ***## disp -0.041215 0.004712 -8.747 9.38e-10 ***## ---## Signif. codes : 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error : 3.251 on 30 degrees of freedom## Multiple R-squared : 0.7183, Adjusted R-squared : 0.709 ## F-statistic : 76.51 on 1 and 30 DF, p-value : 9.38e-10 12plot(data=mtcars, mpg~disp)abline(RA, col=&quot;red&quot;) &gt;&gt; p-value &#x3D; 9.38e-10, ê·€ë¬´ê°€ì„¤ ê¸°ê°(ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ íšŒê·€ëª¨í˜•ì´ ì í•©í•¨)&gt;&gt; ì ˆí¸(Intercept) &#x3D; 29.599855 (ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜í•¨)&gt;&gt; íšŒê·€ê³„ìˆ˜(Estimate) &#x3D; -0.041215 (ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜í•¨)&gt;&gt; íšŒê·€ì‹ : mpg &#x3D; 29.599855 - 0.041215 * disp&gt;&gt; ìˆ˜ì •ëœ ê²°ì •ê³„ìˆ˜(Adjusted R-Squared) &#x3D; .7095. ë‹¤ì¤‘íšŒê·€ë¶„ì„ - lm()12RA &lt;- lm(data=mtcars, mpg~disp+hp+wt)summary(RA) 1234567891011121314151617181920## ## Call:## lm(formula = mpg ~ disp + hp + wt, data = mtcars)## ## Residuals:## Min 1Q Median 3Q Max ## -3.891 -1.640 -0.172 1.061 5.861 ## ## Coefficients:## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.105505 2.110815 17.579 &lt; 2e-16 ***## disp -0.000937 0.010350 -0.091 0.92851 ## hp -0.031157 0.011436 -2.724 0.01097 * ## wt -3.800891 1.066191 -3.565 0.00133 ** ## ---## Signif. codes : 0 &#x27;***&#x27; 0.001 &#x27;**&#x27; 0.01 &#x27;*&#x27; 0.05 &#x27;.&#x27; 0.1 &#x27; &#x27; 1## ## Residual standard error : 2.639 on 28 degrees of freedom## Multiple R-squared : 0.8268, Adjusted R-squared : 0.8083 ## F-statistic : 44.57 on 3 and 28 DF, p-value : 8.65e-11 &gt;&gt; p-value &#x3D; 8.65e-11, ê·€ë¬´ê°€ì„¤ ê¸°ê°(ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ íšŒê·€ëª¨í˜•ì´ ì í•©í•¨)&gt;&gt; ì ˆí¸(Intercept) &#x3D; 29.599855 (ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜í•¨)&gt;&gt; distì˜ ê³„ìˆ˜ &#x3D; -0.000937 (ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ)&gt;&gt; hpì˜ ê³„ìˆ˜ &#x3D; -0.031157 (ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜í•¨)&gt;&gt; wtì˜ ê³„ìˆ˜ &#x3D; -3.800891 (ìœ ì˜ìˆ˜ì¤€ .05ì—ì„œ ìœ ì˜í•¨)&gt;&gt; íšŒê·€ì‹ : mpg &#x3D; 29.599855 - 0.000937 * disp - 0.031157 * hp - 3.800891 * wt&gt;&gt; ìˆ˜ì •ëœ ê²°ì •ê³„ìˆ˜(Adjusted R-Squared) &#x3D; .8083","categories":[{"name":"r","slug":"r","permalink":"http://gonekng.github.io/categories/r/"}],"tags":[{"name":"r","slug":"r","permalink":"http://gonekng.github.io/tags/r/"},{"name":"statistic","slug":"statistic","permalink":"http://gonekng.github.io/tags/statistic/"}],"author":"Jiwon Kang"}],"categories":[{"name":"python","slug":"python","permalink":"http://gonekng.github.io/categories/python/"},{"name":"django","slug":"python/django","permalink":"http://gonekng.github.io/categories/python/django/"},{"name":"pandas","slug":"python/pandas","permalink":"http://gonekng.github.io/categories/python/pandas/"},{"name":"streamlit","slug":"python/streamlit","permalink":"http://gonekng.github.io/categories/python/streamlit/"},{"name":"setting","slug":"python/setting","permalink":"http://gonekng.github.io/categories/python/setting/"},{"name":"ML","slug":"python/ML","permalink":"http://gonekng.github.io/categories/python/ML/"},{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/categories/%EC%B7%A8%EC%A4%80/"},{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/categories/sql/"},{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/categories/hexo/"},{"name":"coding test","slug":"python/coding-test","permalink":"http://gonekng.github.io/categories/python/coding-test/"},{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/categories/setting/"},{"name":"development","slug":"development","permalink":"http://gonekng.github.io/categories/development/"},{"name":"crawling","slug":"python/crawling","permalink":"http://gonekng.github.io/categories/python/crawling/"},{"name":"tutorial","slug":"python/tutorial","permalink":"http://gonekng.github.io/categories/python/tutorial/"},{"name":"r","slug":"r","permalink":"http://gonekng.github.io/categories/r/"}],"tags":[{"name":"development","slug":"development","permalink":"http://gonekng.github.io/tags/development/"},{"name":"python","slug":"python","permalink":"http://gonekng.github.io/tags/python/"},{"name":"django","slug":"django","permalink":"http://gonekng.github.io/tags/django/"},{"name":"pandas","slug":"pandas","permalink":"http://gonekng.github.io/tags/pandas/"},{"name":"streamlit","slug":"streamlit","permalink":"http://gonekng.github.io/tags/streamlit/"},{"name":"sqlite","slug":"sqlite","permalink":"http://gonekng.github.io/tags/sqlite/"},{"name":"git","slug":"git","permalink":"http://gonekng.github.io/tags/git/"},{"name":"machine learning","slug":"machine-learning","permalink":"http://gonekng.github.io/tags/machine-learning/"},{"name":"scikit-learn","slug":"scikit-learn","permalink":"http://gonekng.github.io/tags/scikit-learn/"},{"name":"ì·¨ì¤€","slug":"ì·¨ì¤€","permalink":"http://gonekng.github.io/tags/%EC%B7%A8%EC%A4%80/"},{"name":"ë©´ì ‘","slug":"ë©´ì ‘","permalink":"http://gonekng.github.io/tags/%EB%A9%B4%EC%A0%91/"},{"name":"ìì†Œì„œ","slug":"ìì†Œì„œ","permalink":"http://gonekng.github.io/tags/%EC%9E%90%EC%86%8C%EC%84%9C/"},{"name":"sql","slug":"sql","permalink":"http://gonekng.github.io/tags/sql/"},{"name":"oracle","slug":"oracle","permalink":"http://gonekng.github.io/tags/oracle/"},{"name":"hexo","slug":"hexo","permalink":"http://gonekng.github.io/tags/hexo/"},{"name":"hueman","slug":"hueman","permalink":"http://gonekng.github.io/tags/hueman/"},{"name":"disqus","slug":"disqus","permalink":"http://gonekng.github.io/tags/disqus/"},{"name":"programmers","slug":"programmers","permalink":"http://gonekng.github.io/tags/programmers/"},{"name":"setting","slug":"setting","permalink":"http://gonekng.github.io/tags/setting/"},{"name":"windows11","slug":"windows11","permalink":"http://gonekng.github.io/tags/windows11/"},{"name":"vscode","slug":"vscode","permalink":"http://gonekng.github.io/tags/vscode/"},{"name":"github","slug":"github","permalink":"http://gonekng.github.io/tags/github/"},{"name":"crawling","slug":"crawling","permalink":"http://gonekng.github.io/tags/crawling/"},{"name":"BeautifulSoup","slug":"BeautifulSoup","permalink":"http://gonekng.github.io/tags/BeautifulSoup/"},{"name":"data engineering","slug":"data-engineering","permalink":"http://gonekng.github.io/tags/data-engineering/"},{"name":"wsl2","slug":"wsl2","permalink":"http://gonekng.github.io/tags/wsl2/"},{"name":"spark","slug":"spark","permalink":"http://gonekng.github.io/tags/spark/"},{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://gonekng.github.io/tags/elasticsearch/"},{"name":"kibana","slug":"kibana","permalink":"http://gonekng.github.io/tags/kibana/"},{"name":"apache","slug":"apache","permalink":"http://gonekng.github.io/tags/apache/"},{"name":"airflow","slug":"airflow","permalink":"http://gonekng.github.io/tags/airflow/"},{"name":"google colab","slug":"google-colab","permalink":"http://gonekng.github.io/tags/google-colab/"},{"name":"pipeline","slug":"pipeline","permalink":"http://gonekng.github.io/tags/pipeline/"},{"name":"visualization","slug":"visualization","permalink":"http://gonekng.github.io/tags/visualization/"},{"name":"matplotlib","slug":"matplotlib","permalink":"http://gonekng.github.io/tags/matplotlib/"},{"name":"seaborn","slug":"seaborn","permalink":"http://gonekng.github.io/tags/seaborn/"},{"name":"numpy","slug":"numpy","permalink":"http://gonekng.github.io/tags/numpy/"},{"name":"r","slug":"r","permalink":"http://gonekng.github.io/tags/r/"},{"name":"statistic","slug":"statistic","permalink":"http://gonekng.github.io/tags/statistic/"}]}